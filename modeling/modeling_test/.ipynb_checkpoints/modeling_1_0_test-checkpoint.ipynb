{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "grateful-touch",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn\n",
    "from pandas import DataFrame\n",
    "from tqdm import tqdm\n",
    "from imblearn.under_sampling import RandomUnderSampler #アンダーサンプリング用\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "# 機械学習用\n",
    "from sklearn.cluster import KMeans #クラスタリング用\n",
    "from sklearn.ensemble import RandomForestClassifier#ランダムフォレスト\n",
    "from copy import deepcopy as cp\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "import time\n",
    "import datetime\n",
    "import os #ディレクトリ作成用\n",
    "import xgboost as xgb\n",
    "import sys\n",
    "#自作のモジュールのインポート\n",
    "import module.master as master\n",
    "import module.graph as graph\n",
    "import module.trans_text_code as trans\n",
    "import module.data_making as making\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sustained-palace",
   "metadata": {},
   "source": [
    "# 新規関数案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "activated-iceland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef trans_date_type(df):\\n    df['date']=pd.to_datetime(df['date'])#日付が文字列なのでdateを日付型に変換\\n    df['year']=df['date'].dt.year\\n    df=df.drop('date',axis=1)\\n    return df\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dateのカラムを年だけに変換するやつ\n",
    "\"\"\"\n",
    "def trans_date_type(df):\n",
    "    df['date']=pd.to_datetime(df['date'])#日付が文字列なのでdateを日付型に変換\n",
    "    df['year']=df['date'].dt.year\n",
    "    df=df.drop('date',axis=1)\n",
    "    return df\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sexual-lotus",
   "metadata": {},
   "source": [
    "# 学習パート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "selected-lying",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>result_com</th>\n",
       "      <th>result_com_num</th>\n",
       "      <th>result_com_per</th>\n",
       "      <th>gain_mean</th>\n",
       "      <th>gain_median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>406</td>\n",
       "      <td>9.650582</td>\n",
       "      <td>914.162562</td>\n",
       "      <td>720.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>256</td>\n",
       "      <td>6.085096</td>\n",
       "      <td>1064.179688</td>\n",
       "      <td>795.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>188</td>\n",
       "      <td>4.468743</td>\n",
       "      <td>1447.819149</td>\n",
       "      <td>1095.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>119</td>\n",
       "      <td>2.828619</td>\n",
       "      <td>2351.008403</td>\n",
       "      <td>1560.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>305</td>\n",
       "      <td>7.249822</td>\n",
       "      <td>1211.081967</td>\n",
       "      <td>1010.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>245</td>\n",
       "      <td>5.823627</td>\n",
       "      <td>1341.061224</td>\n",
       "      <td>1070.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>175</td>\n",
       "      <td>4.159734</td>\n",
       "      <td>1633.657143</td>\n",
       "      <td>1180.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>107</td>\n",
       "      <td>2.543380</td>\n",
       "      <td>2097.383178</td>\n",
       "      <td>1290.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>168</td>\n",
       "      <td>3.993344</td>\n",
       "      <td>1749.880952</td>\n",
       "      <td>1265.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>155</td>\n",
       "      <td>3.684336</td>\n",
       "      <td>2124.322581</td>\n",
       "      <td>1470.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>91</td>\n",
       "      <td>2.163062</td>\n",
       "      <td>2456.373626</td>\n",
       "      <td>1950.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>69</td>\n",
       "      <td>1.640124</td>\n",
       "      <td>2987.391304</td>\n",
       "      <td>2180.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>101</td>\n",
       "      <td>2.400761</td>\n",
       "      <td>3406.237624</td>\n",
       "      <td>2310.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>92</td>\n",
       "      <td>2.186831</td>\n",
       "      <td>3623.586957</td>\n",
       "      <td>2280.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>79</td>\n",
       "      <td>1.877823</td>\n",
       "      <td>5122.278481</td>\n",
       "      <td>3720.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>53</td>\n",
       "      <td>1.259805</td>\n",
       "      <td>5543.396226</td>\n",
       "      <td>3760.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>85</td>\n",
       "      <td>2.020442</td>\n",
       "      <td>4653.411765</td>\n",
       "      <td>2370.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>72</td>\n",
       "      <td>1.711433</td>\n",
       "      <td>4151.527778</td>\n",
       "      <td>2775.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>42</td>\n",
       "      <td>0.998336</td>\n",
       "      <td>5952.380952</td>\n",
       "      <td>3620.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>27</td>\n",
       "      <td>0.641787</td>\n",
       "      <td>7835.185185</td>\n",
       "      <td>5000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>87</td>\n",
       "      <td>2.067982</td>\n",
       "      <td>3991.839080</td>\n",
       "      <td>2870.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>66</td>\n",
       "      <td>1.568814</td>\n",
       "      <td>4090.606061</td>\n",
       "      <td>2955.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>49</td>\n",
       "      <td>1.164725</td>\n",
       "      <td>5364.081633</td>\n",
       "      <td>2750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>46</td>\n",
       "      <td>1.093416</td>\n",
       "      <td>5361.086957</td>\n",
       "      <td>3875.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>32</td>\n",
       "      <td>0.760637</td>\n",
       "      <td>6171.875000</td>\n",
       "      <td>4770.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>17</td>\n",
       "      <td>0.404088</td>\n",
       "      <td>10790.588235</td>\n",
       "      <td>7750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>21</td>\n",
       "      <td>0.499168</td>\n",
       "      <td>14490.476190</td>\n",
       "      <td>6650.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>17</td>\n",
       "      <td>0.404088</td>\n",
       "      <td>19015.882353</td>\n",
       "      <td>12440.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    result_com  result_com_num  result_com_per     gain_mean  gain_median\n",
       "0            1             406        9.650582    914.162562        720.0\n",
       "1            2             256        6.085096   1064.179688        795.0\n",
       "2            3             188        4.468743   1447.819149       1095.0\n",
       "3            4             119        2.828619   2351.008403       1560.0\n",
       "4            5             305        7.249822   1211.081967       1010.0\n",
       "5            6             245        5.823627   1341.061224       1070.0\n",
       "6            7             175        4.159734   1633.657143       1180.0\n",
       "7            8             107        2.543380   2097.383178       1290.0\n",
       "8            9             168        3.993344   1749.880952       1265.0\n",
       "9           10             155        3.684336   2124.322581       1470.0\n",
       "10          11              91        2.163062   2456.373626       1950.0\n",
       "11          12              69        1.640124   2987.391304       2180.0\n",
       "12          13             101        2.400761   3406.237624       2310.0\n",
       "13          14              92        2.186831   3623.586957       2280.0\n",
       "14          15              79        1.877823   5122.278481       3720.0\n",
       "15          16              53        1.259805   5543.396226       3760.0\n",
       "16          17              85        2.020442   4653.411765       2370.0\n",
       "17          18              72        1.711433   4151.527778       2775.0\n",
       "18          19              42        0.998336   5952.380952       3620.0\n",
       "19          20              27        0.641787   7835.185185       5000.0\n",
       "20          21              87        2.067982   3991.839080       2870.0\n",
       "21          22              66        1.568814   4090.606061       2955.0\n",
       "22          23              49        1.164725   5364.081633       2750.0\n",
       "23          24              46        1.093416   5361.086957       3875.0\n",
       "24          25              32        0.760637   6171.875000       4770.0\n",
       "25          26              17        0.404088  10790.588235       7750.0\n",
       "26          27              21        0.499168  14490.476190       6650.0\n",
       "27          28              17        0.404088  19015.882353      12440.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#place_master=master.get_place_master()\n",
    "#for place in place_master.items():\n",
    "\n",
    "pd.set_option('display.width',400)#勝手に改行コードを入れられるのを防ぐ\n",
    "place_name='tokuyama'#今回は徳山を例にしていったんXGboostバージョンを作る。\n",
    "\n",
    "################################################========================================================================================================================\n",
    "################################################========================================================================================================================\n",
    "################################################========================================================================================================================\n",
    "################################################========================================================================================================================\n",
    "result_filepath=\"../../..//bot_database/{place_name}/{place_name}_train/train_{place_name}.csv\".format(place_name=place_name)#作成したデータの書き込み先#使用するデータの読み込み\n",
    "result_base_df=pd.read_csv(result_filepath)\n",
    "result_base_df=result_base_df.drop([\"Unnamed: 0\"],axis=1)\n",
    "result_df=making.data_making_1_0(result_base_df)\n",
    "\n",
    "\n",
    "#学習データの切り分け\n",
    "valid_df = result_df[(result_df['year']==2019) | ((result_df['year']==2020) )]#2019,2020のデータを検証用データに。\n",
    "train_df =  result_df[(result_df['year']!=2019) & ((result_df['year']!=2020) )]#そのほかを学習データに\n",
    "#学習データを切り分けたらyearはいらないから削除する\n",
    "valid_df=valid_df.drop(['year'],axis=1)\n",
    "train_df=train_df.drop(['year'],axis=1)\n",
    "\n",
    "train_money=pd.Series(train_df['money'])\n",
    "valid_money=pd.Series(valid_df['money'])\n",
    "\n",
    "#x,yへの切り分け\n",
    "#出現数の分布\n",
    "result_com_s=valid_df['result_com'].value_counts()\n",
    "result_com_s=result_com_s.sort_index()\n",
    "gain_mean=valid_df.groupby('result_com')['money'].mean()\n",
    "gain_mean=gain_mean.sort_index()\n",
    "\n",
    "gain_median=valid_df.groupby('result_com')['money'].median()\n",
    "gain_median=gain_median.sort_index()\n",
    "result_com_df=pd.DataFrame({'result_com':result_com_s.index,\n",
    "                            'result_com_num':result_com_s.values,\n",
    "                            'result_com_per':result_com_s.values/sum(result_com_s.values)*100,\n",
    "                            'gain_mean':gain_mean.values,\n",
    "                            'gain_median':gain_median.values,})\n",
    "result_com_df=result_com_df.iloc[0:28]#探索的に探すにも最後のほうは役にモデルなのはわかっているため\n",
    "result_com_df\n",
    "#result_com_df=result_com_df.set_index('result_com')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "descending-dress",
   "metadata": {},
   "source": [
    "# 学習パートは関数化する。（trainのデータを渡したら勝手に探索をし始める。）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assumed-pressure",
   "metadata": {},
   "outputs": [],
   "source": [
    "def making_model_score(place_name,df):#学習データと場所名を渡せば探索を初めて、指定のディレクトリにスコアをまとめたcsvを出力する。\n",
    "    model_score_df=pd.DataFrame(columns=['target_com','depth','target_per','総収益', '投資金額','出現数','購買予測数','利益率','購買的中率','的中数'])#スコアを格納するdf\n",
    "    for result_com_number in result_com_df['result_com'].values:\n",
    "        print(result_com_number)\n",
    "        result_com=result_com_number\n",
    "        #result_comごとの閾値の決定========================================================================\n",
    "\n",
    "        gain_th=10#利益率の閾値\n",
    "        result_s=result_com_df[result_com_df['result_com']==result_com]\n",
    "        buy_accuracy_th=result_s['result_com_per'].values[0]*1.1#買ったうちの的中率の閾値\n",
    "        num_tp_th=result_s['result_com_num'].values[0]*0.2#あたった回数の閾値(出現回数の20%が的中)\n",
    "        #===============================================================================\n",
    "        #学習データのラベル変換==========================================================\n",
    "        result_train_df=train_df.copy() \n",
    "        result_arr=[0]*len(result_train_df)\n",
    "        i=0\n",
    "        for result in result_train_df['result_com']:\n",
    "            if ((result==result_com)):\n",
    "                result_arr[i]=1\n",
    "            else:\n",
    "                result_arr[i]=0\n",
    "            i+=1\n",
    "        result_train_df['result_com']=result_arr\n",
    "        result_valid_df=valid_df.copy() \n",
    "        result_arr=[0]*len(result_valid_df)\n",
    "        i=0\n",
    "        for result in result_valid_df['result_com']:\n",
    "            if ((result==result_com)):\n",
    "                result_arr[i]=1\n",
    "            else:\n",
    "                result_arr[i]=0\n",
    "            i+=1\n",
    "\n",
    "        result_valid_df['result_com']=result_arr\n",
    "\n",
    "        result_train_df['money']=train_money\n",
    "        result_valid_df['money']=valid_money\n",
    "        #学習データラベル変換終わり============================================\n",
    "\n",
    "        for_arr=np.arange(1,55,1)\n",
    "        #for_arr=np.arange(1,100,1)\n",
    "        accuracy_arr=[0]*len(for_arr)\n",
    "        target_per_arr=[0]*len(for_arr)\n",
    "        pred_0=[0]*len(for_arr)\n",
    "        gain_arr=[0]*len(for_arr)\n",
    "        model_gain_arr=[0]*len(result_valid_df)\n",
    "        valid_gain_arr=valid_money.values\n",
    "        #depths_arr=[4,5,6,7,8]\n",
    "        depths_arr=[5,6,8]\n",
    "        for depth in depths_arr:\n",
    "            for sum_target_per in tqdm(for_arr):\n",
    "\n",
    "                index=sum_target_per-1\n",
    "                #target_per=50+sum_target_per\n",
    "                target_per=85+sum_target_per\n",
    "                target_per_arr[index]=target_per\n",
    "\n",
    "                #モデルの評価指標値を格納するseries======================\n",
    "                model_score_s=pd.Series(index=['target_com','depth','target_per','総収益', '投資金額','出現数','購買予測数','利益率','購買的中率','的中数'])\n",
    "                model_score_s['target_com']=result_com#目標としているresult_comラベル番号\n",
    "                model_score_s['depth']=depth#ハイパーパラメータ＿木の深さ\n",
    "                model_score_s['target_per']=target_per#学習データ_1に対してどの程度の0のデータを持たせるか。\n",
    "                #======================\n",
    "                #trainの[0]に対して、target_perの割合の量[1]を持った学習データの作成\n",
    "                # 一層目の判別機のtrainデータ　:terget_result_df\n",
    "                target_df=result_train_df#ベースのデータフレームをコピー\n",
    "                target_df=target_df.sample(frac=1, random_state=1)#シャッフル、時系列の偏りを無くす\n",
    "                target_1_df=target_df[target_df['result_com']==1]\n",
    "                len_1=len(target_1_df)\n",
    "                target_0_df=target_df[target_df['result_com']==0]\n",
    "                len_0=len(target_0_df)\n",
    "                target_0_df=target_0_df.iloc[(len_0-int(len_1*(target_per/100))):len_0]#1に対する目標の割合ぶん0の結果だったレースを抽出（後ろから抽出）\n",
    "                target_train_df=pd.concat([target_1_df, target_0_df])\n",
    "                #学習＆予測ぱーと========================================================================\n",
    "                #==========================================================================================================================================\n",
    "                #データの切り分け\n",
    "                target_x_train=target_train_df.drop('money',axis=1)\n",
    "                target_x_train=target_x_train.drop('result_com',axis=1)\n",
    "                target_x_valid=result_valid_df.drop('money',axis=1)\n",
    "                target_x_valid=target_x_valid.drop('result_com',axis=1)\n",
    "                \n",
    "                target_y_train=target_train_df['result_com']\n",
    "                target_y_valid=result_valid_df['result_com']\n",
    "                train_x, test_x, train_y, test_y = train_test_split(iris_data, iris_target, test_size=0.2, shuffle=True)\n",
    "                \n",
    "                #XGboostのデータ型に変換する\n",
    "                train = xgb.DMatrix(target_x_train, label=target_y_train)\n",
    "                valid = xgb.DMatrix(target_x_valid, label=target_y_valid)\n",
    "                \n",
    "                param = {'max_depth': depth, \n",
    "                         'eta': 1,\n",
    "                         'objective': 'binary:hinge',\n",
    "                         'num_class': 3}\n",
    "                num_round = 10\n",
    "                bst = xgb.train(param, dtrain, num_round)\n",
    "                #RF = RandomForestClassifier(random_state=1,n_estimators=1000,max_depth=depth)\n",
    "                #RF = RF.fit(target_x_train,target_y_train)\n",
    "                # 未知データに対する予測値\n",
    "                #predict_y_valid = RF.predict(target_x_valid)\n",
    "                \n",
    "                #==========================================================================================================================================\n",
    "                #==========================================================================================================================================\n",
    "                #==========================================================================================================================================\n",
    "                #==========================================================================================================================================\n",
    "                #[1]の正答率を見る\n",
    "                pred_valid_df=pd.DataFrame({'pred':predict_y_valid\n",
    "                                          , 'valid':target_y_valid})\n",
    "                num_1=len(pred_valid_df[pred_valid_df['valid']==1])\n",
    "                count=0\n",
    "                #追加　配当金の情報も考慮する。\n",
    "                gain_index=0\n",
    "                model_gain_arr=[0]*len(result_valid_df)\n",
    "                for _, s in pred_valid_df.iterrows():\n",
    "                    if ((s['pred']==1) and (s['valid']==1)):\n",
    "                        count+=1#的中回数\n",
    "                        model_gain_arr[gain_index]=valid_gain_arr[gain_index]\n",
    "                    gain_index+=1\n",
    "                #print('test accyracy: {}'.format((count/num_1)*100))\n",
    "                gain_arr[index]=sum(model_gain_arr)\n",
    "                accuracy_arr[index]=(count/num_1)*100\n",
    "                try:\n",
    "                    pred_0[index]=pred_valid_df['pred'].value_counts()[0]\n",
    "                except:\n",
    "                    pred_0[index]=0\n",
    "                #scoreのseriesに情報書き込み==================\n",
    "                model_score_s['総収益']=sum(model_gain_arr)\n",
    "                model_score_s['投資金額']=100*sum(predict_y_valid)\n",
    "                model_score_s['出現数']=sum(target_y_valid)\n",
    "                model_score_s['購買予測数']=sum(predict_y_valid)\n",
    "                model_score_s['利益率']=(model_score_s['総収益']/model_score_s['投資金額'])*100\n",
    "                model_score_s['購買的中率']=(count/sum(predict_y_valid))*100\n",
    "                model_score_s['的中数']=count\n",
    "                model_score_df=model_score_df.append(model_score_s,ignore_index=True)\n",
    "\n",
    "    #モデルの「スコアを保存        \n",
    "    model_score_df.to_csv('{}_model_score.csv'.format(place), encoding='utf_8_sig')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "whole-nicaragua",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-37-59c023c27799>:61: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  model_score_s=pd.Series(index=['target_com','depth','target_per','総収益', '投資金額','出現数','購買予測数','利益率','購買的中率','的中数'])\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Must have at least 1 validation dataset for early stopping.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-59c023c27799>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m                 }\n\u001b[1;32m--> 105\u001b[1;33m         \u001b[0mbst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_boost_round\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m         \u001b[1;31m#RF = RandomForestClassifier(random_state=1,n_estimators=1000,max_depth=depth)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m         \u001b[1;31m#RF = RF.fit(target_x_train,target_y_train)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\takuma\\nabepy\\env\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m    225\u001b[0m     \u001b[0mBooster\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtrained\u001b[0m \u001b[0mbooster\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m     \"\"\"\n\u001b[1;32m--> 227\u001b[1;33m     bst = _train_internal(params, dtrain,\n\u001b[0m\u001b[0;32m    228\u001b[0m                           \u001b[0mnum_boost_round\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_boost_round\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m                           \u001b[0mevals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\takuma\\nabepy\\env\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks, evals_result, maximize, verbose_eval, early_stopping_rounds)\u001b[0m\n\u001b[0;32m    108\u001b[0m         \u001b[0mnboost\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m         \u001b[1;31m# check evaluation result.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 110\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mafter_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    111\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m         \u001b[1;31m# do checkpoint after evaluation, in case evaluation also updates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\takuma\\nabepy\\env\\lib\\site-packages\\xgboost\\callback.py\u001b[0m in \u001b[0;36mafter_iteration\u001b[1;34m(self, model, epoch, dtrain, evals)\u001b[0m\n\u001b[0;32m    426\u001b[0m             \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m':'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_history\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 428\u001b[1;33m         ret = any(c.after_iteration(model, epoch, self.history)\n\u001b[0m\u001b[0;32m    429\u001b[0m                   for c in self.callbacks)\n\u001b[0;32m    430\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\takuma\\nabepy\\env\\lib\\site-packages\\xgboost\\callback.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    426\u001b[0m             \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m':'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_history\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 428\u001b[1;33m         ret = any(c.after_iteration(model, epoch, self.history)\n\u001b[0m\u001b[0;32m    429\u001b[0m                   for c in self.callbacks)\n\u001b[0;32m    430\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\takuma\\nabepy\\env\\lib\\site-packages\\xgboost\\callback.py\u001b[0m in \u001b[0;36mafter_iteration\u001b[1;34m(self, model, epoch, evals_log)\u001b[0m\n\u001b[0;32m    540\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mafter_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mBooster\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevals_log\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    541\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'Must have at least 1 validation dataset for early stopping.'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m         \u001b[1;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevals_log\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[0mdata_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: Must have at least 1 validation dataset for early stopping."
     ]
    }
   ],
   "source": [
    "\n",
    "model_score_df=pd.DataFrame(columns=['target_com','depth','target_per','総収益', '投資金額','出現数','購買予測数','利益率','購買的中率','的中数'])#スコアを格納するdf\n",
    "\n",
    "\n",
    "\n",
    "#print(result_com_number)\n",
    "#result_com=result_com_number\n",
    "result_com=1\n",
    "#result_comごとの閾値の決定========================================================================\n",
    "\n",
    "gain_th=10#利益率の閾値\n",
    "result_s=result_com_df[result_com_df['result_com']==result_com]\n",
    "buy_accuracy_th=result_s['result_com_per'].values[0]*1.1#買ったうちの的中率の閾値\n",
    "num_tp_th=result_s['result_com_num'].values[0]*0.2#あたった回数の閾値(出現回数の20%が的中)\n",
    "#===============================================================================\n",
    "#学習データのラベル変換==========================================================\n",
    "result_train_df=train_df.copy() \n",
    "result_arr=[0]*len(result_train_df)\n",
    "i=0\n",
    "for result in result_train_df['result_com']:\n",
    "    if ((result==result_com)):\n",
    "        result_arr[i]=1\n",
    "    else:\n",
    "        result_arr[i]=0\n",
    "    i+=1\n",
    "result_train_df['result_com']=result_arr\n",
    "result_valid_df=valid_df.copy() \n",
    "result_arr=[0]*len(result_valid_df)\n",
    "i=0\n",
    "for result in result_valid_df['result_com']:\n",
    "    if ((result==result_com)):\n",
    "        result_arr[i]=1\n",
    "    else:\n",
    "        result_arr[i]=0\n",
    "    i+=1\n",
    "\n",
    "result_valid_df['result_com']=result_arr\n",
    "\n",
    "result_train_df['money']=train_money\n",
    "result_valid_df['money']=valid_money\n",
    "#学習データラベル変換終わり============================================\n",
    "\n",
    "for_arr=np.arange(1,60)\n",
    "#for_arr=np.arange(1,100,1)\n",
    "accuracy_arr=[0]*len(for_arr)\n",
    "target_per_arr=[0]*len(for_arr)\n",
    "pred_0=[0]*len(for_arr)\n",
    "gain_arr=[0]*len(for_arr)\n",
    "model_gain_arr=[0]*len(result_valid_df)\n",
    "valid_gain_arr=valid_money.values\n",
    "#depths_arr=[4,5,6,7,8]\n",
    "depths_arr=[5,6,8]\n",
    "for depth in depths_arr:\n",
    "    for sum_target_per in for_arr:\n",
    "\n",
    "        index=sum_target_per-1\n",
    "        #target_per=50+sum_target_per\n",
    "        target_per=80+sum_target_per\n",
    "        target_per_arr[index]=target_per\n",
    "\n",
    "        #モデルの評価指標値を格納するseries======================\n",
    "        model_score_s=pd.Series(index=['target_com','depth','target_per','総収益', '投資金額','出現数','購買予測数','利益率','購買的中率','的中数'])\n",
    "        model_score_s['target_com']=result_com#目標としているresult_comラベル番号\n",
    "        model_score_s['depth']=depth#ハイパーパラメータ＿木の深さ\n",
    "        model_score_s['target_per']=target_per#学習データ_1に対してどの程度の0のデータを持たせるか。\n",
    "        #======================\n",
    "        #trainの[0]に対して、target_perの割合の量[1]を持った学習データの作成\n",
    "        # 一層目の判別機のtrainデータ　:terget_result_df\n",
    "        target_df=result_train_df#ベースのデータフレームをコピー\n",
    "        target_df=target_df.sample(frac=1, random_state=1)#シャッフル、時系列の偏りを無くす\n",
    "        target_1_df=target_df[target_df['result_com']==1]\n",
    "        len_1=len(target_1_df)\n",
    "        target_0_df=target_df[target_df['result_com']==0]\n",
    "        len_0=len(target_0_df)\n",
    "        target_0_df=target_0_df.iloc[(len_0-int(len_1*(target_per/100))):len_0]#1に対する目標の割合ぶん0の結果だったレースを抽出（後ろから抽出）\n",
    "        target_train_df=pd.concat([target_1_df, target_0_df])\n",
    "        #学習＆予測ぱーと========================================================================\n",
    "        #==========================================================================================================================================\n",
    "        #データの切り分け\n",
    "        target_x_train=target_train_df.drop('money',axis=1)\n",
    "        target_x_train=target_x_train.drop('result_com',axis=1)\n",
    "        target_y_train=target_train_df['result_com']\n",
    "        \n",
    "        target_x_valid=result_valid_df.drop('money',axis=1)\n",
    "        target_x_valid=target_x_valid.drop('result_com',axis=1)\n",
    "        target_y_valid=result_valid_df['result_com']\n",
    "        train_x, valid_x, train_y, valid_y = train_test_split(train_x, train_y, test_size=0.2, shuffle=True)\n",
    "        \n",
    "        #XGboostのデータ型に変換する\n",
    "        train = xgb.DMatrix(target_x_train, label=target_y_train)\n",
    "        valid = xgb.DMatrix(target_x_valid, label=target_y_valid)\n",
    "\n",
    "        param = {'max_depth': depth, #パラメータの設定\n",
    "                 'eta': 0.2,\n",
    "                 #'objective': 'binary:logistic',\n",
    "                 'objective': 'binary:hinge',\n",
    "                 'eval_metric': 'logloss',\n",
    "                 'subsample':0.8,\n",
    "                 'nthread':10,\n",
    "                 #'nthread':10\n",
    "                 #'n_estimators':1000\n",
    "                 'gpu_id':0,\n",
    "                 'tree_method':'gpu_hist'\n",
    "\n",
    "\n",
    "                }\n",
    "        bst = xgb.train(param, train,num_boost_round=1000,early_stopping_rounds=100)\n",
    "        #RF = RandomForestClassifier(random_state=1,n_estimators=1000,max_depth=depth)\n",
    "        #RF = RF.fit(target_x_train,target_y_train)\n",
    "        \n",
    "        \n",
    "        # 未知データに対する予測値\n",
    "        #predict_y_valid = RF.predict(target_x_valid)\n",
    "        predict_y_valid=bst.predict(valid)\n",
    "\n",
    "        #==========================================================================================================================================\n",
    "        #==========================================================================================================================================\n",
    "        #==========================================================================================================================================\n",
    "        #==========================================================================================================================================\n",
    "        \n",
    "        #[1]の正答率を見る\n",
    "        pred_valid_df=pd.DataFrame({'pred':predict_y_valid\n",
    "                                  , 'valid':target_y_valid})\n",
    "        num_1=len(pred_valid_df[pred_valid_df['valid']==1])\n",
    "        count=0\n",
    "        #追加　配当金の情報も考慮する。\n",
    "        gain_index=0\n",
    "        model_gain_arr=[0]*len(result_valid_df)\n",
    "        for _, s in pred_valid_df.iterrows():\n",
    "            if ((s['pred']==1) and (s['valid']==1)):\n",
    "                count+=1#的中回数\n",
    "                model_gain_arr[gain_index]=valid_gain_arr[gain_index]\n",
    "            gain_index+=1\n",
    "        #print('test accyracy: {}'.format((count/num_1)*100))\n",
    "        gain_arr[index]=sum(model_gain_arr)\n",
    "        accuracy_arr[index]=(count/num_1)*100\n",
    "        try:\n",
    "            pred_0[index]=pred_valid_df['pred'].value_counts()[0]\n",
    "        except:\n",
    "            pred_0[index]=0\n",
    "        #scoreのseriesに情報書き込み==================\n",
    "        model_score_s['総収益']=sum(model_gain_arr)\n",
    "        model_score_s['投資金額']=100*sum(predict_y_valid)\n",
    "        model_score_s['出現数']=sum(target_y_valid)\n",
    "        model_score_s['購買予測数']=sum(predict_y_valid)\n",
    "        model_score_s['利益率']=(model_score_s['総収益']/model_score_s['投資金額'])*100\n",
    "        model_score_s['購買的中率']=(count/sum(predict_y_valid))*100\n",
    "        model_score_s['的中数']=count\n",
    "        model_score_df=model_score_df.append(model_score_s,ignore_index=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "discrete-helen",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
       "       0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_y_valid[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "experienced-trash",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_score_df.to_csv('excample.csv',encoding='utf_8_sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fitting-singapore",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>racer_1_rank</th>\n",
       "      <th>racer_1_age</th>\n",
       "      <th>racer_1_doub</th>\n",
       "      <th>racer_1_ave_st</th>\n",
       "      <th>racer_2_rank</th>\n",
       "      <th>racer_2_age</th>\n",
       "      <th>racer_2_doub</th>\n",
       "      <th>racer_2_ave_st</th>\n",
       "      <th>racer_3_rank</th>\n",
       "      <th>racer_3_age</th>\n",
       "      <th>...</th>\n",
       "      <th>racer_6_bo_90</th>\n",
       "      <th>racer_6_bo_91</th>\n",
       "      <th>racer_6_bo_92</th>\n",
       "      <th>racer_6_bo_93</th>\n",
       "      <th>racer_6_bo_94</th>\n",
       "      <th>racer_6_bo_95</th>\n",
       "      <th>racer_6_bo_96</th>\n",
       "      <th>racer_6_bo_97</th>\n",
       "      <th>racer_6_bo_98</th>\n",
       "      <th>racer_6_bo_99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14797</th>\n",
       "      <td>3</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.387</td>\n",
       "      <td>0.17</td>\n",
       "      <td>2</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.297</td>\n",
       "      <td>0.17</td>\n",
       "      <td>2</td>\n",
       "      <td>36.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14798</th>\n",
       "      <td>4</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.442</td>\n",
       "      <td>0.18</td>\n",
       "      <td>4</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.468</td>\n",
       "      <td>0.16</td>\n",
       "      <td>4</td>\n",
       "      <td>32.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14799</th>\n",
       "      <td>3</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.448</td>\n",
       "      <td>0.18</td>\n",
       "      <td>2</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.17</td>\n",
       "      <td>2</td>\n",
       "      <td>36.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14800</th>\n",
       "      <td>4</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.630</td>\n",
       "      <td>0.16</td>\n",
       "      <td>2</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.295</td>\n",
       "      <td>0.19</td>\n",
       "      <td>2</td>\n",
       "      <td>28.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14801</th>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.20</td>\n",
       "      <td>4</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.15</td>\n",
       "      <td>2</td>\n",
       "      <td>27.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19298</th>\n",
       "      <td>3</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.416</td>\n",
       "      <td>0.14</td>\n",
       "      <td>2</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.17</td>\n",
       "      <td>2</td>\n",
       "      <td>63.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19299</th>\n",
       "      <td>2</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.18</td>\n",
       "      <td>4</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.14</td>\n",
       "      <td>2</td>\n",
       "      <td>60.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19300</th>\n",
       "      <td>4</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.17</td>\n",
       "      <td>3</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.386</td>\n",
       "      <td>0.17</td>\n",
       "      <td>3</td>\n",
       "      <td>36.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19301</th>\n",
       "      <td>4</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.435</td>\n",
       "      <td>0.15</td>\n",
       "      <td>2</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.16</td>\n",
       "      <td>3</td>\n",
       "      <td>38.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19302</th>\n",
       "      <td>4</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.12</td>\n",
       "      <td>4</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.428</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2</td>\n",
       "      <td>47.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4506 rows × 1236 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       racer_1_rank  racer_1_age  racer_1_doub  racer_1_ave_st  racer_2_rank  racer_2_age  racer_2_doub  racer_2_ave_st  racer_3_rank  racer_3_age  ...  racer_6_bo_90  racer_6_bo_91  racer_6_bo_92  racer_6_bo_93  racer_6_bo_94  racer_6_bo_95  racer_6_bo_96  racer_6_bo_97  racer_6_bo_98  racer_6_bo_99\n",
       "14797             3         31.0         0.387            0.17             2         27.0         0.297            0.17             2         36.0  ...              0              0              0              0              0              0              0              0              0              0\n",
       "14798             4         25.0         0.442            0.18             4         27.0         0.468            0.16             4         32.0  ...              0              0              0              0              0              0              0              0              0              0\n",
       "14799             3         33.0         0.448            0.18             2         26.0         0.193            0.17             2         36.0  ...              0              0              0              0              0              0              0              0              0              0\n",
       "14800             4         30.0         0.630            0.16             2         30.0         0.295            0.19             2         28.0  ...              0              0              0              0              0              0              0              0              0              0\n",
       "14801             1         27.0         0.111            0.20             4         31.0         0.400            0.15             2         27.0  ...              0              0              0              0              0              0              0              0              0              0\n",
       "...             ...          ...           ...             ...           ...          ...           ...             ...           ...          ...  ...            ...            ...            ...            ...            ...            ...            ...            ...            ...            ...\n",
       "19298             3         33.0         0.416            0.14             2         35.0         0.179            0.17             2         63.0  ...              0              0              0              0              0              0              0              0              0              0\n",
       "19299             2         35.0         0.259            0.18             4         33.0         0.485            0.14             2         60.0  ...              0              0              0              0              0              0              0              0              0              0\n",
       "19300             4         24.0         0.500            0.17             3         46.0         0.386            0.17             3         36.0  ...              0              0              0              0              0              0              0              0              0              0\n",
       "19301             4         35.0         0.435            0.15             2         47.0         0.215            0.16             3         38.0  ...              0              0              0              0              0              0              0              0              0              0\n",
       "19302             4         45.0         0.675            0.12             4         39.0         0.428            0.13             2         47.0  ...              0              0              0              0              0              0              0              0              0              0\n",
       "\n",
       "[4506 rows x 1236 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_x_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "further-singapore",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
