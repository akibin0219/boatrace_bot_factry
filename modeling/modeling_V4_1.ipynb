{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "terminal-northeast",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn\n",
    "from pandas import DataFrame\n",
    "from tqdm import tqdm\n",
    "from imblearn.under_sampling import RandomUnderSampler #アンダーサンプリング用\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "# 機械学習用\n",
    "from sklearn.cluster import KMeans #クラスタリング用\n",
    "from sklearn.ensemble import RandomForestClassifier#ランダムフォレスト\n",
    "from copy import deepcopy as cp\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import time\n",
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import os #ディレクトリ作成用\n",
    "import xgboost as xgb\n",
    "import sys\n",
    "#自作のモジュールのインポート\n",
    "sys.path.append(\"..\")\n",
    "import module.master as master\n",
    "import module.modeling_scores as modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "younger-germany",
   "metadata": {},
   "source": [
    "### モデルのスコア保存のための箱作り"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "minus-oklahoma",
   "metadata": {},
   "outputs": [],
   "source": [
    "version='V4_1'#バージョン\n",
    "\n",
    "place_master=master.get_place_master()\n",
    "for place in place_master.items():\n",
    "    #print(place[0],place[1],'\\n')\n",
    "    place_name=place[1]\n",
    "    dir_path = \"../../bot_database/{place_name}/model_score_{place_name}/\".format(place_name=place_name)#作成したデータの書き込み先#使用するデータの読み込み\n",
    "    if os.path.exists(dir_path)==False:\n",
    "        os.makedirs(dir_path)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "\n",
    "#V4_系列の特殊処理\n",
    "for place in place_master.items():\n",
    "    #print(place[0],place[1],'\\n')\n",
    "    place_name=place[1]\n",
    "    dir_path = \"../../bot_database/{place_name}/model_score_{place_name}/v4_score/{version}/\".format(place_name=place_name,version=version)#作成したデータの書き込み先#使用するデータの読み込み\n",
    "    if os.path.exists(dir_path)==False:\n",
    "        os.makedirs(dir_path)\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medium-nightmare",
   "metadata": {},
   "source": [
    "# 機能のテスト"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "included-salvation",
   "metadata": {},
   "source": [
    "### 今回使用していく関数を作る"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "integrated-consumer",
   "metadata": {},
   "source": [
    "## 実行する関数内で使用されている関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "pretty-tragedy",
   "metadata": {
    "code_folding": [
     0,
     80
    ]
   },
   "outputs": [],
   "source": [
    "def get_event_info(result_base_df):\n",
    "    df=result_base_df.copy()\n",
    "    df['date']=pd.to_datetime(df['date'])#日付が文字列なのでdateを日付型に変換\n",
    "    df['year']=df['date'].dt.year\n",
    "    df['month']=df['date'].dt.month\n",
    "    df['day']=df['date'].dt.day\n",
    "\n",
    "    num_date=1\n",
    "    num_date_arr=[]\n",
    "    last_race_date=df['date'].values[0]#前レースの日付(処理開始時用にtarainのデータの一番初めのdateを仮に入力しておく)\n",
    "    for index,row in df.iterrows():\n",
    "        today_date=row['date']\n",
    "        if today_date==last_race_date:#同じ日のレースだったらおなじレース日を配列に追加、次の日の日付を出力（ほぼ無操作みたいなもん）\n",
    "            next_date=row['date'] + datetime.timedelta(days=1)#次の日\n",
    "            num_date_arr.append(num_date)\n",
    "        else:#日にちが変わった時\n",
    "            if today_date==next_date:#想定していた日付（次の日のレース）だったら,レース日を一日足して、そのレース日番号を加算\n",
    "                num_date+=1\n",
    "                num_date_arr.append(num_date)\n",
    "                last_race_date=row['date']#前回レース日を上書き\n",
    "                #next_date=train_df[train_df['date']==row['date'] + datetime.timedelta(days=1)]#次の日\n",
    "                next_date=row['date'] + datetime.timedelta(days=1)#次の日\n",
    "                #print(next_date)\n",
    "            else:#想定していた日付でない(違う大会になった)場合はレース日をリセット\n",
    "                num_date=1\n",
    "                num_date_arr.append(num_date)\n",
    "                last_race_date=row['date']#前回レース日を上書き\n",
    "                #next_date=train_df[train_df['date']==row['date'] + datetime.timedelta(days=1)]#次の日\n",
    "                next_date=row['date'] + datetime.timedelta(days=1)#次の日\n",
    "    df['num_date']=num_date_arr\n",
    "\n",
    "    range_races=0#大会中の取得できたレースの数\n",
    "    range_date=1#大会の開催日数\n",
    "    range_date_arr=[]\n",
    "    range_date_arr_2=[]#for文中で繰り返し上書きさせる用の配列\n",
    "    last_race_date=df['date'].values[0]#前レースの日付(処理開始時用にtrainのデータの一番初めのdateを仮に入力しておく)\n",
    "    for index,row in df.iterrows():\n",
    "        today_date=row['date']\n",
    "        if today_date==last_race_date:#同じ日のレースだったらおなじレース日を配列に追加、次の日の日付を出力（ほぼ無操作みたいなもん）\n",
    "            range_races+=1\n",
    "            next_date=row['date'] + datetime.timedelta(days=1)#次の日\n",
    "            #num_date_arr.append(num_date)\n",
    "        else:#日にちが変わった時\n",
    "            if today_date==next_date:#想定していた日付（次の日のレース）だったら,レース日を一日足して終了\n",
    "                range_date+=1\n",
    "                range_races+=1\n",
    "                last_race_date=row['date']#前回レース日を上書き\n",
    "                #next_date=train_df[train_df['date']==row['date'] + datetime.timedelta(days=1)]#次の日\n",
    "                next_date=row['date'] + datetime.timedelta(days=1)#次の日次の日\n",
    "            else:#想定していた日付でない(違う大会になった)場合は現在のrange_dateをもとに前の大会のレースに大会開催日数を持たせる。\n",
    "\n",
    "                range_date_arr_2=[range_date]*range_races\n",
    "                for num in range_date_arr_2:\n",
    "                    range_date_arr.append(num)\n",
    "                range_races=1#大会中の取得できたレースの数\n",
    "                range_date=1#大会の開催日数\n",
    "                last_race_date=row['date']#前回レース日を上書き\n",
    "                #next_date=train_df[train_df['date']==row['date'] + datetime.timedelta(days=1)]#次の日\n",
    "                next_date=row['date'] + datetime.timedelta(days=1)#次の日\n",
    "    range_date_arr_2=[range_date]*range_races#最後の日は日付の変わり絵が発生しないので特別処理\n",
    "    for num in range_date_arr_2:\n",
    "        range_date_arr.append(num)\n",
    "    df['range_date']=range_date_arr\n",
    "\n",
    "    #四半期カラムの作成\n",
    "    df['season']=df['month']\n",
    "    df['season']=df['season'].replace([3,4,5],'sp')#春\n",
    "    df['season']=df['season'].replace([6,7,8],'su')#夏\n",
    "    df['season']=df['season'].replace([9,10,11],'au')#秋\n",
    "    df['season']=df['season'].replace([12,1,2],'wi')#冬\n",
    "    #df=df.drop('date',axis=1)\n",
    "    return df\n",
    "\n",
    "def pred_th_trans(pred_df,th):\n",
    "    #引数として予測結果のdeと、変換したい閾値を渡す。\n",
    "    trans_df=pred_df.copy()\n",
    "    trans_df.loc[trans_df['pred_proba'] >= th, 'pred'] = 1\n",
    "    trans_df.loc[~(trans_df['pred_proba']  >=  th), 'pred'] = 0\n",
    "    return trans_df\n",
    "\n",
    "def calc_monthly_analysis(pred_df):#予測に加えて，配当，開催情報が結合されたdfを渡すことで月ごと関連の分析を行ってくれる関数\n",
    "    cols=['month','use','get','income','income_per','num_hit','buy_hit_per','mean_income','median_income']\n",
    "    monthly_analysis_df= pd.DataFrame(columns=cols)#月別収益結果の入る箱\n",
    "    months=pred_df['month'].value_counts(sort=False).index\n",
    "    for month in months:\n",
    "        monthly_df=pred_df[pred_df['month']==month].copy()\n",
    "        use_m=100*monthly_df['pred'].sum()\n",
    "        get_m=monthly_df['gain'].sum()\n",
    "        income=get_m-use_m\n",
    "        income_per=(get_m/use_m)*100\n",
    "        \n",
    "        \n",
    "        num_hit=monthly_df['hit_flag'].sum()\n",
    "        num_pred=pred_df['pred'].sum()\n",
    "        buy_hit_per=(num_hit/num_pred)*100\n",
    "        if num_hit==0:#警告文削除用\n",
    "            mean_income=0\n",
    "            median_income=0\n",
    "        else:\n",
    "            mean_income=monthly_df[monthly_df['hit_flag']==1][\"gain\"].mean()#１回の的中あたりの平均配当\n",
    "            median_income=monthly_df[monthly_df['hit_flag']==1][\"gain\"].median()#１回の的中あたりの中央配当\n",
    "        \n",
    "        append_arr=[month,use_m,get_m,income,income_per,num_hit,buy_hit_per,mean_income,median_income]\n",
    "        append_s=pd.Series(append_arr,index=cols)\n",
    "        monthly_analysis_df=monthly_analysis_df.append(append_s, ignore_index=True)\n",
    "    return monthly_analysis_df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "partial-unknown",
   "metadata": {},
   "source": [
    "### 実行する関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "afraid-improvement",
   "metadata": {
    "code_folding": [
     0,
     122
    ]
   },
   "outputs": [],
   "source": [
    "def data_making_clustar_section_has_final(df,now_ym,range_test_m,range_final_m):#モデル関連に使用するdfの作成関数(クラスタリングあり、モータ番号、艇番号なし)（加工関数）\n",
    "    #V4系列で使用する加工関数，年と月の情報を使って直近のデータを使って性能検証を行う（区間を使ってデータを作っている）\n",
    "    #validデータを作成するバージョンなので実装する際はこれをそのまま使わず，final_test部分の処理は消してくだちい\n",
    "    #yearが使わないと思うけど一応残してあるから邪魔だと思ったら消して下さい\n",
    "    result_df=df\n",
    "    result_df=result_df.drop([\"racer_1_ID\",\"racer_2_ID\",\"racer_3_ID\",\"racer_4_ID\",\"racer_5_ID\",\"racer_6_ID\",],axis=1)#IDはいらないので削除\n",
    "    result_df=result_df.replace(0.0000,{\"racer_1_ave_st_time\":0.22}).copy()#新人のave_st_timeを0.22に\n",
    "    result_df=result_df.replace(0.0000,{\"racer_2_ave_st_time\":0.22}).copy()\n",
    "    result_df=result_df.replace(0.0000,{\"racer_3_ave_st_time\":0.22}).copy()\n",
    "    result_df=result_df.replace(0.0000,{\"racer_4_ave_st_time\":0.22}).copy()\n",
    "    result_df=result_df.replace(0.0000,{\"racer_5_ave_st_time\":0.22}).copy()\n",
    "    result_df=result_df.replace(0.0000,{\"racer_6_ave_st_time\":0.22}).copy()\n",
    "    result_df=result_df.replace(0.0000,{\"racer_1_doub_win\":0.02}).copy()#新人の着に絡む確率ave_st_timeを0.02に(新人の半期の偏差から導出)\n",
    "    result_df=result_df.replace(0.0000,{\"racer_2_doub_win\":0.02}).copy()\n",
    "    result_df=result_df.replace(0.0000,{\"racer_3_doub_win\":0.02}).copy()\n",
    "    result_df=result_df.replace(0.0000,{\"racer_4_doub_win\":0.02}).copy()\n",
    "    result_df=result_df.replace(0.0000,{\"racer_5_doub_win\":0.02}).copy()\n",
    "    result_df=result_df.replace(0.0000,{\"racer_6_doub_win\":0.02}).copy()\n",
    "\n",
    "    #result_base_df=result_df.copy()\n",
    "    #result_base_df=get_event_info(result_base_df)#開催の情報について付与する関数(年月日に加えて，何日間の開催かどうかも教えてくれる)\n",
    "\n",
    "    #ダミー変数化\n",
    "    result_df_dummie=result_df.copy()\n",
    "    race_dummie_df=pd.get_dummies(result_df_dummie['number_race'])#number_raceをダミー化\n",
    "    for column, val in race_dummie_df.iteritems():\n",
    "        result_df_dummie['race_{}'.format(int(column))]=val\n",
    "    result_df_dummie=result_df_dummie.drop('number_race',axis=1).copy()\n",
    "\n",
    "    cols=list(result_df_dummie.columns)\n",
    "    male_cols=[s for s in cols if 'male' in s]#性別を示すカラムを取り出す\n",
    "\n",
    "    #===========================新規、性別の取り出し機能が良くなかったため作り直す\n",
    "    empty_arr=[0]*len(result_df_dummie)\n",
    "    for col in male_cols:\n",
    "        for number in np.arange(0,2,1):\n",
    "              result_df_dummie['{}_{}'.format(col,int(number))]=empty_arr.copy()\n",
    "        male_dummie_df=pd.get_dummies(result_df_dummie[col]).copy()#性別をダミー化\n",
    "        for column, val in male_dummie_df.iteritems():\n",
    "              result_df_dummie['{}_{}'.format(col,int(column))]=val.copy()\n",
    "        result_df_dummie=result_df_dummie.drop('{}'.format(col),axis=1).copy()\n",
    "\n",
    "    cols=list(result_df_dummie.columns)\n",
    "\n",
    "\n",
    "\n",
    "    moter_cols=[s for s in cols if '_mo' in s]#モーター番号を示すカラムを取り出す\n",
    "    boat_cols=[s for s in cols if '_bo' in s]#ボート番号を示すカラムを取り出す\n",
    "\n",
    "    #boat、moterの情報は使わない、\n",
    "    numbers=np.arange(1, 100, 1)\n",
    "    empty_arr=[0]*len(result_df_dummie)\n",
    "    for col in moter_cols:\n",
    "        result_df_dummie=result_df_dummie.drop('{}'.format(col),axis=1).copy()\n",
    "    for col in boat_cols:\n",
    "        result_df_dummie=result_df_dummie.drop('{}'.format(col),axis=1).copy()\n",
    "\n",
    "    #クラスタリング\n",
    "    #分けてみるクラスタの数は[3,5,7,9]の4個\n",
    "    #cluster_target_df　　trainのデータからリザルトと配当金を取り除いたもの\n",
    "    #学習データのdateを年に変換\n",
    "    result_df_dummie['date']=pd.to_datetime(result_df_dummie['date'])#日付が文字列なのでdateを日付型に変換\n",
    "    result_df_dummie['year']=result_df_dummie['date'].dt.year\n",
    "    \n",
    "    #==========================================================================\n",
    "    #result_df_dummie=result_df_dummie[result_df_dummie['year']!=2020].copy()#2020のデータを完全に切り離す。\n",
    "    #==========================================================================\n",
    "    #クラアスタリング用の学習、予測用のデータの切り分け\n",
    "    #年，月，日とかの取得\n",
    "    #now_ym:開始の月\n",
    "    test_st_date = now_ym - relativedelta(months=range_test_m)#テストデータに使用する区間を決める\n",
    "    final_test_en_date = now_ym + relativedelta(months=range_final_m)#最終テストの終了日\n",
    "    \n",
    "    clustar_final_test_df=result_df_dummie[(result_df_dummie['date']>=now_ym) & (result_df_dummie['date']<final_test_en_date) ].copy()#今の日付以降を最終チェックデータ(予測のターゲット)に。\n",
    "    clustar_test_df = result_df_dummie[(result_df_dummie['date']<now_ym) & ((result_df_dummie['date']>=test_st_date) )].copy()#今日に日より前の，指定した区間でのテストデータ\n",
    "    clustar_train_df =  result_df_dummie[(result_df_dummie['date']<test_st_date)].copy()#そのほかを学習データに\n",
    "    result_df_dummie=result_df_dummie[result_df_dummie['date']<final_test_en_date]\n",
    "    #年の情報だけ切り分けに使ったからここで消す。\n",
    "    clustar_final_test_df=clustar_final_test_df.drop('date',axis=1).copy()\n",
    "    clustar_test_df=clustar_test_df.drop('date',axis=1).copy()\n",
    "    clustar_train_df=clustar_train_df.drop('date',axis=1).copy()\n",
    "\n",
    "    #クラスタリングに邪魔だから消したいけど、後々使うものはいったんよけておく\n",
    "    result=result_df_dummie['result_com'].values.copy()#\n",
    "    money=result_df_dummie['money'].values.copy()#\n",
    "    years=result_df_dummie['year'].values.copy()#\n",
    "    dates=result_df_dummie['date'].values.copy()#\n",
    "    \n",
    "    #安全なところに移したら削除する\n",
    "    result_df_dummie=result_df_dummie.drop('result_com',axis=1)\n",
    "    result_df_dummie=result_df_dummie.drop('money',axis=1)\n",
    "    result_df_dummie=result_df_dummie.drop('year',axis=1)\n",
    "    #esult_df_dummie=result_df_dummie.drop('date',axis=1)\n",
    "    \n",
    "    \n",
    "\n",
    "    target_num_cluster=[3,5,7,9]#分けるクラスタ数によってモデルの名前を変える\n",
    "    for num_cluster in target_num_cluster:\n",
    "        Km = KMeans(random_state=7,n_clusters=num_cluster).fit(clustar_train_df)#rondom_stateはラッキーセブン\n",
    "        #final_test_pred =Km.predict(clustar_final_test_df)#rondom_stateはラッキーセブン\n",
    "        final_test_pred =Km.predict(clustar_final_test_df)#rondom_stateはラッキーセブン\n",
    "        test_pred =Km.predict(clustar_test_df)#rondom_stateはラッキーセブン\n",
    "        train_pred = Km.predict(clustar_train_df)#rondom_stateはラッキーセブン\n",
    "        #Km=========================実査に使うときはこれのモデルを会場ごとに保存して使用。\n",
    "        #clustar_final_test_df['num={}'.format(num_cluster)]=final_test_pred\n",
    "        clustar_final_test_df['num={}'.format(num_cluster)]=final_test_pred\n",
    "        clustar_test_df['num={}'.format(num_cluster)]=test_pred\n",
    "        clustar_train_df['num={}'.format(num_cluster)]=train_pred\n",
    "\n",
    "    #結合して元の形に戻す。\n",
    "    #clustar_df=pd.concat([clustar_train_df, clustar_test_df,clustar_final_test_df]).copy()\n",
    "#     clustar_final_test_df['check']='final'#確認用\n",
    "#     clustar_test_df['check']='test'#確認用\n",
    "#     clustar_train_df['check']='train'#確認用\n",
    "    clustar_df=pd.concat([clustar_train_df, clustar_test_df,clustar_final_test_df]).copy()\n",
    "    clustar_df['year']=years\n",
    "    clustar_df['date']=dates\n",
    "    clustar_df['money']=money\n",
    "    clustar_df['result_com']=result\n",
    "    model_df=clustar_df.copy()\n",
    "    return model_df\n",
    "\n",
    "def model_score_XGboost_th_section_has_final(version,place_name,result_df,now_ym,range_test_m,range_final_m):#XGboostの出力を確率のやつを使用したバージョン、閾値の探索も行う。\n",
    "    print(place_name)\n",
    "    #result_dfは加工関数にて分けられたものを渡す。\n",
    "    model_score_df=pd.DataFrame(columns=['target_com','depth','target_per','threshold','total_get_test', 'total_use_test','num_com_test','num_pred_test','gain_test','gain_std_test','num_hit_test','buy_hit_per_test','buy_hit_per_std_test','plus_month_num_test','diff_mea_med_test','total_get_final', 'total_use_final','num_com_final','num_pred_final','gain_final','gain_std_final','num_hit_final','buy_hit_per_final','buy_hit_per_std_final','plus_month_num_final','diff_mea_med_final'])#スコアを格納するdf\n",
    "\n",
    "    #学習データの切り分け\n",
    "    #年，月，日とかの取得\n",
    "    #now_ym:開始の月\n",
    "    test_st_date = now_ym - relativedelta(months=range_test_m)#テストデータに使用する区間を決める\n",
    "    final_test_en_date = now_ym + relativedelta(months=range_final_m)#最終テストの終了日\n",
    "    #以下学習データ\n",
    "    final_test_df=result_df[(result_df['date']>=now_ym) & (result_df['date']<final_test_en_date) ].copy()#今の日付以降を最終チェックデータ(予測のターゲット)に。\n",
    "    test_df = result_df[(result_df['date']<now_ym) & ((result_df['date']>=test_st_date) )].copy()#今日に日より前の，指定した区間でのテストデータ\n",
    "    train_df =  result_df[(result_df['date']<test_st_date)].copy()#そのほかを学習データに\n",
    "\n",
    "    #V4ではdateは性能評価用のdf作成時に使用するので別でとっておく(最終的にtransしたpredのdfに結合する)\n",
    "    final_test_dates=final_test_df['date'].values\n",
    "    test_dates=test_df['date'].values\n",
    "    train_dates=train_df['date'].values\n",
    "\n",
    "    #学習データを切り分けたらyearはいらないから削除する\n",
    "    final_test_df=final_test_df.drop(['year'],axis=1)\n",
    "    test_df=test_df.drop(['year'],axis=1)\n",
    "    train_df=train_df.drop(['year'],axis=1)\n",
    "    final_test_df=final_test_df.drop(['date'],axis=1)\n",
    "    test_df=test_df.drop(['date'],axis=1)\n",
    "    train_df=train_df.drop(['date'],axis=1)\n",
    "\n",
    "    train_money=pd.Series(train_df['money'])\n",
    "    test_money=pd.Series(test_df['money'])\n",
    "    final_test_money=pd.Series(final_test_df['money'])\n",
    "    test_gain_arr=test_money.values\n",
    "    final_test_gain_arr=final_test_money.values\n",
    "    #x,yへの切り分け\n",
    "    #出現数の分布\n",
    "    result_com_s=test_df['result_com'].value_counts()\n",
    "    result_com_s=result_com_s.sort_index()\n",
    "    gain_mean=test_df.groupby('result_com')['money'].mean()\n",
    "    gain_mean=gain_mean.sort_index()\n",
    "\n",
    "    gain_median=test_df.groupby('result_com')['money'].median()\n",
    "    gain_median=gain_median.sort_index()\n",
    "    result_com_df=pd.DataFrame({'result_com':result_com_s.index,\n",
    "                                'result_com_num':result_com_s.values,\n",
    "                                'result_com_per':result_com_s.values/sum(result_com_s.values)*100,\n",
    "                                'gain_mean':gain_mean.values,\n",
    "                                'gain_median':gain_median.values,})\n",
    "    result_com_df=result_com_df.iloc[0:28]#探索的に探すにも最後のほうは役にモデルなのはわかっているため\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    for result_com_number in tqdm(result_com_df['result_com'].values):\n",
    "        #print(result_com_number)\n",
    "        result_com=result_com_number\n",
    "        #result_comごとの閾値の決定========================================================================\n",
    "\n",
    "        gain_th=10#利益率の閾値\n",
    "        result_s=result_com_df[result_com_df['result_com']==result_com]\n",
    "        buy_accuracy_th=result_s['result_com_per'].values[0]*1.1#買ったうちの的中率の閾値\n",
    "        num_tp_th=result_s['result_com_num'].values[0]*0.2#あたった回数の閾値(出現回数の20%が的中)\n",
    "        #===============================================================================\n",
    "        #学習データのラベル変換==========================================================\n",
    "        result_train_df=train_df.copy()\n",
    "        result_arr=[0]*len(result_train_df)\n",
    "        i=0\n",
    "        for result in result_train_df['result_com']:\n",
    "            if ((result==result_com)):\n",
    "                result_arr[i]=1\n",
    "            else:\n",
    "                result_arr[i]=0\n",
    "            i+=1\n",
    "        result_train_df['result_com']=result_arr\n",
    "\n",
    "        target_test_df=test_df.copy()\n",
    "        result_arr=[0]*len(target_test_df)\n",
    "        i=0\n",
    "        for result in target_test_df['result_com']:\n",
    "            if ((result==result_com)):\n",
    "                result_arr[i]=1\n",
    "            else:\n",
    "                result_arr[i]=0\n",
    "            i+=1\n",
    "        target_test_df['result_com']=result_arr\n",
    "\n",
    "        target_final_test_df=final_test_df.copy()\n",
    "        result_arr=[0]*len(target_final_test_df)\n",
    "        i=0\n",
    "        for result in target_final_test_df['result_com']:\n",
    "            if ((result==result_com)):\n",
    "                result_arr[i]=1\n",
    "            else:\n",
    "                result_arr[i]=0\n",
    "            i+=1\n",
    "        target_final_test_df['result_com']=result_arr\n",
    "\n",
    "        result_train_df['money']=train_money\n",
    "        target_test_df['money']=test_money\n",
    "        target_final_test_df['money']=final_test_money\n",
    "        #学習データラベル変換終わり============================================\n",
    "\n",
    "        for_arr=np.arange(1,85)\n",
    "        #for_arr=np.arange(1,100,1)\n",
    "        accuracy_arr=[0]*len(for_arr)\n",
    "        target_per_arr=[0]*len(for_arr)\n",
    "        pred_0=[0]*len(for_arr)\n",
    "        gain_arr=[0]*len(for_arr)\n",
    "        model_gain_arr=[0]*len(target_test_df)\n",
    "        #depths_arr=[4,5,6,7,8]\n",
    "        #depths_arr=[5,6,8]\n",
    "        depths_arr=[5,8]\n",
    "        for depth in depths_arr:\n",
    "            for sum_target_per in for_arr:\n",
    "\n",
    "                index=sum_target_per-1\n",
    "                #target_per=50+sum_target_per\n",
    "                target_per=100+(sum_target_per*2)\n",
    "                target_per_arr[index]=target_per\n",
    "\n",
    "                #モデルの評価指標値を格納するseries======================\n",
    "                model_score_s=pd.Series(index=['target_com','depth','target_per','threshold','total_get_test', 'total_use_test','num_com_test','num_pred_test','gain_test','gain_std_test','num_hit_test','buy_hit_per_test','buy_hit_per_std_test','plus_month_num_test','diff_mea_med_test','total_get_final', 'total_use_final','num_com_final','num_pred_final','gain_final','gain_std_final','num_hit_final','buy_hit_per_final','buy_hit_per_std_final','plus_month_num_final','diff_mea_med_final'], dtype='float64')\n",
    "                model_score_s['target_com']=result_com#目標としているresult_comラベル番号\n",
    "                model_score_s['depth']=depth#ハイパーパラメータ＿木の深さ\n",
    "                model_score_s['target_per']=target_per#学習データ_1に対してどの程度の0のデータを持たせるか。\n",
    "                #======================\n",
    "                #trainの[0]に対して、target_perの割合の量[1]を持った学習データの作成\n",
    "                # 一層目の判別機のtrainデータ　:terget_result_df\n",
    "                target_df=result_train_df#ベースのデータフレームをコピー\n",
    "                target_df=target_df.sample(frac=1, random_state=7)#シャッフル、時系列の偏りを無くす\n",
    "                target_1_df=target_df[target_df['result_com']==1]\n",
    "                len_1=len(target_1_df)\n",
    "                target_0_df=target_df[target_df['result_com']==0]\n",
    "                len_0=len(target_0_df)\n",
    "                target_0_df=target_0_df.iloc[(len_0-int(len_1*(target_per/100))):len_0]#1に対する目標の割合ぶん0の結果だったレースを抽出（後ろから抽出）\n",
    "                target_train_df=pd.concat([target_1_df, target_0_df])\n",
    "                #学習＆予測ぱーと========================================================================\n",
    "                #==========================================================================================================================================\n",
    "                #データの切り分け\n",
    "                target_x_train=target_train_df.drop('money',axis=1).copy()\n",
    "                target_x_train=target_x_train.drop('result_com',axis=1)\n",
    "\n",
    "                target_x_test=target_test_df.drop('money',axis=1).copy()\n",
    "                target_x_test=target_x_test.drop('result_com',axis=1)\n",
    "\n",
    "                target_x_final=target_final_test_df.drop('money',axis=1).copy()\n",
    "                target_x_final=target_x_final.drop('result_com',axis=1)\n",
    "\n",
    "                target_y_train=target_train_df['result_com']\n",
    "                target_y_test=target_test_df['result_com']\n",
    "                target_y_final=target_final_test_df['result_com']\n",
    "                train_x, valid_x, train_y, valid_y = train_test_split(target_x_train, target_y_train, test_size=0.2, shuffle=True, random_state=7)#学習データ内でさらに分割してロスをもとに修正をする。\n",
    "\n",
    "                #XGboostのデータ型に変換する\n",
    "                train = xgb.DMatrix(train_x, label=train_y)#学習用\n",
    "                valid = xgb.DMatrix(valid_x, label=valid_y)#学習時のロス修正用\n",
    "                test = xgb.DMatrix(target_x_test, label=target_y_test)#実際に使った時の利益率の算出用\n",
    "                final = xgb.DMatrix(target_x_final, label=target_y_final)#最終確認用の区間\n",
    "\n",
    "                #xgb.config_context(verbosity=0)\n",
    "                param = {'max_depth': depth, #パラメータの設定\n",
    "                                 #'eta': 1.8,\n",
    "                                 #'eta': 0.8,\n",
    "                                 'eta': 1.3,\n",
    "                                 #'eta': 0.2,\n",
    "                                 #'objective': 'binary:hinge',\n",
    "                                 'objective': 'binary:logistic',#確率で出力\n",
    "                                 'eval_metric': 'logloss',\n",
    "                                 'verbosity':0,\n",
    "                                 'subsample':0.8,\n",
    "                                 'nthread':10,\n",
    "                                 'gpu_id':0,\n",
    "                                 'seed':7,\n",
    "                                 'tree_method':'gpu_hist'\n",
    "                                }\n",
    "                evallist = [(valid, 'eval'), (train, 'train')]#学習時にバリデーションを監視するデータの指定。\n",
    "                #bst = xgb.train(param, train,num_boost_round=1000,early_stopping_rounds=30)\n",
    "                #num_round = 10000\n",
    "                num_round = 400\n",
    "                bst = xgb.train(param, train,num_round,evallist, early_stopping_rounds=30, verbose_eval=0 )\n",
    "                #bst = xgb.train(param, train,num_round,evallist, verbose=100,early_stopping_rounds=30 )\n",
    "                #RF = RandomForestClassifier(random_state=1,n_estimators=1000,max_depth=depth)\n",
    "                #RF = RF.fit(target_x_train,target_y_train)\n",
    "\n",
    "\n",
    "                # 未知データに対する予測値\n",
    "                #predict_y_test = RF.predict(target_x_test)\n",
    "                predict_y_test=bst.predict(test)\n",
    "                predict_y_final=bst.predict(final)\n",
    "                #==========================================================================================================================================\n",
    "                #==========================================================================================================================================\n",
    "                #==========================================================================================================================================\n",
    "                #==========================================================================================================================================\n",
    "\n",
    "                #[1]の正答率を見る\n",
    "                pred_test_df=pd.DataFrame({'pred_proba':predict_y_test#確率分布での出力\n",
    "                                          , 'test':target_y_test})\n",
    "                pred_final_test_df=pd.DataFrame({'pred_proba':predict_y_final#確率分布での出力\n",
    "                                          , 'test':target_y_final})\n",
    "\n",
    "\n",
    "                th_arr=[0.85,0.9,0.92]\n",
    "                for th in th_arr:\n",
    "                    trans_test_df=pred_th_trans(pred_test_df,th)\n",
    "                    trans_final_test_df=pred_th_trans(pred_final_test_df,th)\n",
    "                    #num_1=len(trans_df[trans_df['test']==1])\n",
    "                    #追加　配当金の情報も考慮する。\n",
    "                    count_test=0\n",
    "                    gain_index=0\n",
    "                    model_test_gain_arr=[0]*len(test_df)\n",
    "                    test_hit_arr=[0]*len(test_df)#あたっているかあたっていないかのフラグを格納した配列\n",
    "                    for _, s in trans_test_df.iterrows():\n",
    "                        if ((s['pred']==1) and (s['test']==1)):#もし購買しているかつ的中をしていたら・・・\n",
    "                            count_test+=1#的中回数\n",
    "                            model_test_gain_arr[gain_index]=test_gain_arr[gain_index]\n",
    "                            test_hit_arr[gain_index]=1\n",
    "                        gain_index+=1\n",
    "\n",
    "                    count_final=0\n",
    "                    gain_index=0\n",
    "                    model_final_test_gain_arr=[0]*len(final_test_df)\n",
    "                    final_test_hit_arr=[0]*len(final_test_df)#あたっているかあたっていないかのフラグを格納した配列\n",
    "                    for _, s in trans_final_test_df.iterrows():\n",
    "                        if ((s['pred']==1) and (s['test']==1)):#もし購買しているかつ的中をしていたら・・・\n",
    "                            count_final+=1#的中回数\n",
    "                            model_final_test_gain_arr[gain_index]=final_test_gain_arr[gain_index]\n",
    "                            final_test_hit_arr[gain_index]=1\n",
    "                        gain_index+=1\n",
    "\n",
    "    #                     gain_arr[index]=sum(model_gain_arr)\n",
    "    #                     accuracy_arr[index]=(count/num_1)*100\n",
    "                    #=================================================\n",
    "                    try:\n",
    "                        pred_0[index]=trans_df['pred'].value_counts()[0]\n",
    "                    except:\n",
    "                        pred_0[index]=0\n",
    "\n",
    "                    #V4から増やした集計(月での集計を加えて，comごとでの安定性について確認する)\n",
    "                    test_analysis_df=trans_test_df.copy()#集計結果を格納するためのdf\n",
    "                    final_test_analysis_df=trans_final_test_df.copy()#集計結果を格納するためのdf\n",
    "                    #集計のための情報を結合する\n",
    "                    test_analysis_df['hit_flag']=test_hit_arr#的中時に１のフラグを結合する\n",
    "                    test_analysis_df['gain']=model_test_gain_arr#的中して得られたゲインの金額を格納した配列\n",
    "                    test_analysis_df['date']=test_dates#月ごとの分析のために日付のデータを結合する\n",
    "                    test_analysis_df=get_event_info(test_analysis_df)#開催情報を取得\n",
    "\n",
    "                    final_test_analysis_df['hit_flag']=final_test_hit_arr#的中時に１のフラグを結合する\n",
    "                    final_test_analysis_df['gain']=model_final_test_gain_arr#的中して得られたゲインの金額を格納した配列\n",
    "                    final_test_analysis_df['date']=final_test_dates#月ごとの分析のために日付のデータを結合する\n",
    "                    final_test_analysis_df=get_event_info(final_test_analysis_df)#開催情報を取得\n",
    "\n",
    "                    test_m_analysis=calc_monthly_analysis(test_analysis_df)#月別の分析結果を取得\n",
    "                    final_test_m_analysis=calc_monthly_analysis(final_test_analysis_df)#月別の分析結果を取得\n",
    "                    test_m_desc=test_m_analysis.describe()\n",
    "                    final_test_m_desc=final_test_m_analysis.describe()\n",
    "                    #scoreのseriesに情報書き込み==================\n",
    "                    model_score_s['threshold']=th\n",
    "                    #テストデータ=============================================================\n",
    "                    #総収益\n",
    "                    model_score_s['total_get_test']=sum(model_test_gain_arr)\n",
    "                    #投資金額\n",
    "                    model_score_s['total_use_test']=100*trans_test_df['pred'].sum()\n",
    "                    #出現数\n",
    "                    model_score_s['num_com_test']=sum(target_y_test)\n",
    "                    #購買予測数\n",
    "                    model_score_s['num_pred_test']=trans_test_df['pred'].sum()\n",
    "                    #利益率\n",
    "                    model_score_s['gain_test']=(model_score_s['total_get_test']/model_score_s['total_use_test'])*100\n",
    "                    #利益率の標準偏差\n",
    "                    model_score_s['gain_std_test']=test_m_desc.loc['std','income_per']\n",
    "                    #的中数\n",
    "                    model_score_s['num_hit_test']=count_test\n",
    "                    #購買的中率\n",
    "                    model_score_s['buy_hit_per_test']=(count_test/trans_test_df['pred'].sum())*100\n",
    "                    #購買的中率の標準偏差\n",
    "                    model_score_s['buy_hit_per_std_test']=test_m_desc.loc['std','buy_hit_per']\n",
    "                    #配当がプラスになった月の数\n",
    "                    model_score_s['plus_month_num_test']=len(test_m_analysis[test_m_analysis['income']>0])\n",
    "                    #得られた配当の中央値と平均の差(中央値-平均，つまりマイナスが大きいほど高い配当が引っ張っている)\n",
    "                    model_score_s['diff_mea_med_test']=(test_m_desc.loc['mean','mean_income'])-(test_m_desc.loc['mean','median_income'])\n",
    "\n",
    "                    #最終テストデータ(カラム名の説明に関してはテストと同じなので割愛させていただきます)=============================================================\n",
    "                    model_score_s['total_get_final']=sum(model_final_test_gain_arr)\n",
    "                    model_score_s['total_use_final']=100*trans_final_test_df['pred'].sum()\n",
    "                    model_score_s['num_com_final']=sum(target_y_final)\n",
    "                    model_score_s['num_pred_final']=trans_final_test_df['pred'].sum()\n",
    "                    model_score_s['gain_final']=(model_score_s['total_get_final']/model_score_s['total_use_final'])*100\n",
    "                    model_score_s['gain_std_final']=final_test_m_desc.loc['std','income_per']\n",
    "\n",
    "                    model_score_s['num_hit_final']=count_final\n",
    "                    model_score_s['buy_hit_per_final']=(count_final/trans_final_test_df['pred'].sum())*100\n",
    "                    model_score_s['buy_hit_per_std_final']=final_test_m_desc.loc['std','buy_hit_per']\n",
    "                    model_score_s['plus_month_num_final']=len(final_test_m_analysis[final_test_m_analysis['income']>0])\n",
    "                    model_score_s['diff_mea_med_final']=(final_test_m_desc.loc['mean','mean_income'])-(final_test_m_desc.loc['mean','median_income'])\n",
    "\n",
    "                    #dfに書き込み\n",
    "                    model_score_df=model_score_df.append(model_score_s,ignore_index=True)\n",
    "    #モデルの「スコアを保存\n",
    "    dir_path = \"../../bot_database/{place_name}/model_score_{place_name}/v4_score/{V}/{place_name}_model_score_st{stDate}_finalM{finalM}_{V}.csv\".format(place_name=place_name,V=version,stDate=now_ym.strftime('%Y%m%d'),finalM=range_final_m)#作成したデータの書き込み先#使用するデータの読み込み\n",
    "    #print(dir_path)\n",
    "    model_score_df.to_csv(dir_path, encoding='utf_8_sig')\n",
    "    return None\n",
    "\n",
    "def model_score_period_XGboost_th_section_has_final(version,place_name,result_df,now_ym,range_test_m,range_final_m):#昨年同時期のデータを用いてXGboostの出力を確率のやつを使用したバージョン、閾値の探索も行う。\n",
    "    print(place_name)\n",
    "    #result_dfは加工関数にて分けられたものを渡す。\n",
    "    model_score_df=pd.DataFrame(columns=['target_com','depth','target_per','threshold','total_get_test', 'total_use_test','num_com_test','num_pred_test','gain_test','gain_std_test','num_hit_test','buy_hit_per_test','buy_hit_per_std_test','plus_month_num_test','diff_mea_med_test','total_get_final', 'total_use_final','num_com_final','num_pred_final','gain_final','gain_std_final','num_hit_final','buy_hit_per_final','buy_hit_per_std_final','plus_month_num_final','diff_mea_med_final'])#スコアを格納するdf\n",
    "\n",
    "    #学習データの切り分け\n",
    "    #年，月，日とかの取得\n",
    "    #now_ym:開始の月\n",
    "    test_en_date = now_ym - relativedelta(years=1)+relativedelta(months=range_test_m)#テストデータに使用する区間の終了日を決める(一年前の昨年同時期で三カ月)\n",
    "    test_st_date = now_ym - relativedelta(years=1)#テストデータに使用する区間の開始を決める(一年前の昨年同時期)\n",
    "    final_test_en_date = now_ym + relativedelta(months=range_final_m)#最終テストの終了日\n",
    "    #以下学習データ\n",
    "    final_test_df=result_df[(result_df['date']>=now_ym) & (result_df['date']<final_test_en_date) ].copy()#今の日付以降を最終チェックデータ(予測のターゲット)に。\n",
    "    test_df = result_df[(result_df['date']<test_en_date) & ((result_df['date']>=test_st_date) )].copy()#今日より前の，指定した区間でのテストデータ\n",
    "    train_df =  result_df[(result_df['date']<test_st_date)].copy()#そのほかを学習データに\n",
    "\n",
    "    #V4ではdateは性能評価用のdf作成時に使用するので別でとっておく(最終的にtransしたpredのdfに結合する)\n",
    "    final_test_dates=final_test_df['date'].values\n",
    "    test_dates=test_df['date'].values\n",
    "    train_dates=train_df['date'].values\n",
    "\n",
    "    #学習データを切り分けたらyearはいらないから削除する\n",
    "    final_test_df=final_test_df.drop(['year'],axis=1)\n",
    "    test_df=test_df.drop(['year'],axis=1)\n",
    "    train_df=train_df.drop(['year'],axis=1)\n",
    "    final_test_df=final_test_df.drop(['date'],axis=1)\n",
    "    test_df=test_df.drop(['date'],axis=1)\n",
    "    train_df=train_df.drop(['date'],axis=1)\n",
    "\n",
    "    train_money=pd.Series(train_df['money'])\n",
    "    test_money=pd.Series(test_df['money'])\n",
    "    final_test_money=pd.Series(final_test_df['money'])\n",
    "    test_gain_arr=test_money.values\n",
    "    final_test_gain_arr=final_test_money.values\n",
    "    #x,yへの切り分け\n",
    "    #出現数の分布\n",
    "    result_com_s=test_df['result_com'].value_counts()\n",
    "    result_com_s=result_com_s.sort_index()\n",
    "    gain_mean=test_df.groupby('result_com')['money'].mean()\n",
    "    gain_mean=gain_mean.sort_index()\n",
    "\n",
    "    gain_median=test_df.groupby('result_com')['money'].median()\n",
    "    gain_median=gain_median.sort_index()\n",
    "    result_com_df=pd.DataFrame({'result_com':result_com_s.index,\n",
    "                                'result_com_num':result_com_s.values,\n",
    "                                'result_com_per':result_com_s.values/sum(result_com_s.values)*100,\n",
    "                                'gain_mean':gain_mean.values,\n",
    "                                'gain_median':gain_median.values,})\n",
    "    result_com_df=result_com_df.iloc[0:28]#探索的に探すにも最後のほうは役にモデルなのはわかっているため\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    for result_com_number in tqdm(result_com_df['result_com'].values):\n",
    "        #print(result_com_number)\n",
    "        result_com=result_com_number\n",
    "        #result_comごとの閾値の決定========================================================================\n",
    "\n",
    "        gain_th=10#利益率の閾値\n",
    "        result_s=result_com_df[result_com_df['result_com']==result_com]\n",
    "        buy_accuracy_th=result_s['result_com_per'].values[0]*1.1#買ったうちの的中率の閾値\n",
    "        num_tp_th=result_s['result_com_num'].values[0]*0.2#あたった回数の閾値(出現回数の20%が的中)\n",
    "        #===============================================================================\n",
    "        #学習データのラベル変換==========================================================\n",
    "        result_train_df=train_df.copy()\n",
    "        result_arr=[0]*len(result_train_df)\n",
    "        i=0\n",
    "        for result in result_train_df['result_com']:\n",
    "            if ((result==result_com)):\n",
    "                result_arr[i]=1\n",
    "            else:\n",
    "                result_arr[i]=0\n",
    "            i+=1\n",
    "        result_train_df['result_com']=result_arr\n",
    "\n",
    "        target_test_df=test_df.copy()\n",
    "        result_arr=[0]*len(target_test_df)\n",
    "        i=0\n",
    "        for result in target_test_df['result_com']:\n",
    "            if ((result==result_com)):\n",
    "                result_arr[i]=1\n",
    "            else:\n",
    "                result_arr[i]=0\n",
    "            i+=1\n",
    "        target_test_df['result_com']=result_arr\n",
    "\n",
    "        target_final_test_df=final_test_df.copy()\n",
    "        result_arr=[0]*len(target_final_test_df)\n",
    "        i=0\n",
    "        for result in target_final_test_df['result_com']:\n",
    "            if ((result==result_com)):\n",
    "                result_arr[i]=1\n",
    "            else:\n",
    "                result_arr[i]=0\n",
    "            i+=1\n",
    "        target_final_test_df['result_com']=result_arr\n",
    "\n",
    "        result_train_df['money']=train_money\n",
    "        target_test_df['money']=test_money\n",
    "        target_final_test_df['money']=final_test_money\n",
    "        #学習データラベル変換終わり============================================\n",
    "\n",
    "        for_arr=np.arange(1,85)\n",
    "        #for_arr=np.arange(1,100,1)\n",
    "        accuracy_arr=[0]*len(for_arr)\n",
    "        target_per_arr=[0]*len(for_arr)\n",
    "        pred_0=[0]*len(for_arr)\n",
    "        gain_arr=[0]*len(for_arr)\n",
    "        model_gain_arr=[0]*len(target_test_df)\n",
    "        #depths_arr=[4,5,6,7,8]\n",
    "        #depths_arr=[5,6,8]\n",
    "        depths_arr=[5,8]\n",
    "        for depth in depths_arr:\n",
    "            for sum_target_per in for_arr:\n",
    "\n",
    "                index=sum_target_per-1\n",
    "                #target_per=50+sum_target_per\n",
    "                target_per=100+(sum_target_per*2)\n",
    "                target_per_arr[index]=target_per\n",
    "\n",
    "                #モデルの評価指標値を格納するseries======================\n",
    "                model_score_s=pd.Series(index=['target_com','depth','target_per','threshold','total_get_test', 'total_use_test','num_com_test','num_pred_test','gain_test','gain_std_test','num_hit_test','buy_hit_per_test','buy_hit_per_std_test','plus_month_num_test','diff_mea_med_test','total_get_final', 'total_use_final','num_com_final','num_pred_final','gain_final','gain_std_final','num_hit_final','buy_hit_per_final','buy_hit_per_std_final','plus_month_num_final','diff_mea_med_final'], dtype='float64')\n",
    "                model_score_s['target_com']=result_com#目標としているresult_comラベル番号\n",
    "                model_score_s['depth']=depth#ハイパーパラメータ＿木の深さ\n",
    "                model_score_s['target_per']=target_per#学習データ_1に対してどの程度の0のデータを持たせるか。\n",
    "                #======================\n",
    "                #trainの[0]に対して、target_perの割合の量[1]を持った学習データの作成\n",
    "                # 一層目の判別機のtrainデータ　:terget_result_df\n",
    "                target_df=result_train_df#ベースのデータフレームをコピー\n",
    "                target_df=target_df.sample(frac=1, random_state=7)#シャッフル、時系列の偏りを無くす\n",
    "                target_1_df=target_df[target_df['result_com']==1]\n",
    "                len_1=len(target_1_df)\n",
    "                target_0_df=target_df[target_df['result_com']==0]\n",
    "                len_0=len(target_0_df)\n",
    "                target_0_df=target_0_df.iloc[(len_0-int(len_1*(target_per/100))):len_0]#1に対する目標の割合ぶん0の結果だったレースを抽出（後ろから抽出）\n",
    "                target_train_df=pd.concat([target_1_df, target_0_df])\n",
    "                #学習＆予測ぱーと========================================================================\n",
    "                #==========================================================================================================================================\n",
    "                #データの切り分け\n",
    "                target_x_train=target_train_df.drop('money',axis=1).copy()\n",
    "                target_x_train=target_x_train.drop('result_com',axis=1)\n",
    "\n",
    "                target_x_test=target_test_df.drop('money',axis=1).copy()\n",
    "                target_x_test=target_x_test.drop('result_com',axis=1)\n",
    "\n",
    "                target_x_final=target_final_test_df.drop('money',axis=1).copy()\n",
    "                target_x_final=target_x_final.drop('result_com',axis=1)\n",
    "\n",
    "                target_y_train=target_train_df['result_com']\n",
    "                target_y_test=target_test_df['result_com']\n",
    "                target_y_final=target_final_test_df['result_com']\n",
    "                train_x, valid_x, train_y, valid_y = train_test_split(target_x_train, target_y_train, test_size=0.2, shuffle=True, random_state=7)#学習データ内でさらに分割してロスをもとに修正をする。\n",
    "\n",
    "                #XGboostのデータ型に変換する\n",
    "                train = xgb.DMatrix(train_x, label=train_y)#学習用\n",
    "                valid = xgb.DMatrix(valid_x, label=valid_y)#学習時のロス修正用\n",
    "                test = xgb.DMatrix(target_x_test, label=target_y_test)#実際に使った時の利益率の算出用\n",
    "                final = xgb.DMatrix(target_x_final, label=target_y_final)#最終確認用の区間\n",
    "\n",
    "                #xgb.config_context(verbosity=0)\n",
    "                param = {'max_depth': depth, #パラメータの設定\n",
    "                                 #'eta': 1.8,\n",
    "                                 #'eta': 0.8,\n",
    "                                 'eta': 1.3,\n",
    "                                 #'eta': 0.2,\n",
    "                                 #'objective': 'binary:hinge',\n",
    "                                 'objective': 'binary:logistic',#確率で出力\n",
    "                                 'eval_metric': 'logloss',\n",
    "                                 'verbosity':0,\n",
    "                                 'subsample':0.8,\n",
    "                                 #'nthread':10,\n",
    "                                 'nthread':5,\n",
    "                                 'gpu_id':0,\n",
    "                                 'seed':7,\n",
    "                                 'tree_method':'gpu_hist'\n",
    "                                }\n",
    "                evallist = [(valid, 'eval'), (train, 'train')]#学習時にバリデーションを監視するデータの指定。\n",
    "                #bst = xgb.train(param, train,num_boost_round=1000,early_stopping_rounds=30)\n",
    "                #num_round = 10000\n",
    "                num_round = 400\n",
    "                bst = xgb.train(param, train,num_round,evallist, early_stopping_rounds=30, verbose_eval=0 )\n",
    "                #bst = xgb.train(param, train,num_round,evallist, verbose=100,early_stopping_rounds=30 )\n",
    "                #RF = RandomForestClassifier(random_state=1,n_estimators=1000,max_depth=depth)\n",
    "                #RF = RF.fit(target_x_train,target_y_train)\n",
    "\n",
    "\n",
    "                # 未知データに対する予測値\n",
    "                #predict_y_test = RF.predict(target_x_test)\n",
    "                predict_y_test=bst.predict(test)\n",
    "                predict_y_final=bst.predict(final)\n",
    "                #==========================================================================================================================================\n",
    "                #==========================================================================================================================================\n",
    "                #==========================================================================================================================================\n",
    "                #==========================================================================================================================================\n",
    "\n",
    "                #[1]の正答率を見る\n",
    "                pred_test_df=pd.DataFrame({'pred_proba':predict_y_test#確率分布での出力\n",
    "                                          , 'test':target_y_test})\n",
    "                pred_final_test_df=pd.DataFrame({'pred_proba':predict_y_final#確率分布での出力\n",
    "                                          , 'test':target_y_final})\n",
    "\n",
    "\n",
    "                th_arr=[0.85,0.9,0.92]\n",
    "                for th in th_arr:\n",
    "                    trans_test_df=pred_th_trans(pred_test_df,th)\n",
    "                    trans_final_test_df=pred_th_trans(pred_final_test_df,th)\n",
    "                    #num_1=len(trans_df[trans_df['test']==1])\n",
    "                    #追加　配当金の情報も考慮する。\n",
    "                    count_test=0\n",
    "                    gain_index=0\n",
    "                    model_test_gain_arr=[0]*len(test_df)\n",
    "                    test_hit_arr=[0]*len(test_df)#あたっているかあたっていないかのフラグを格納した配列\n",
    "                    for _, s in trans_test_df.iterrows():\n",
    "                        if ((s['pred']==1) and (s['test']==1)):#もし購買しているかつ的中をしていたら・・・\n",
    "                            count_test+=1#的中回数\n",
    "                            model_test_gain_arr[gain_index]=test_gain_arr[gain_index]\n",
    "                            test_hit_arr[gain_index]=1\n",
    "                        gain_index+=1\n",
    "\n",
    "                    count_final=0\n",
    "                    gain_index=0\n",
    "                    model_final_test_gain_arr=[0]*len(final_test_df)\n",
    "                    final_test_hit_arr=[0]*len(final_test_df)#あたっているかあたっていないかのフラグを格納した配列\n",
    "                    for _, s in trans_final_test_df.iterrows():\n",
    "                        if ((s['pred']==1) and (s['test']==1)):#もし購買しているかつ的中をしていたら・・・\n",
    "                            count_final+=1#的中回数\n",
    "                            model_final_test_gain_arr[gain_index]=final_test_gain_arr[gain_index]\n",
    "                            final_test_hit_arr[gain_index]=1\n",
    "                        gain_index+=1\n",
    "\n",
    "    #                     gain_arr[index]=sum(model_gain_arr)\n",
    "    #                     accuracy_arr[index]=(count/num_1)*100\n",
    "                    #=================================================\n",
    "                    try:\n",
    "                        pred_0[index]=trans_df['pred'].value_counts()[0]\n",
    "                    except:\n",
    "                        pred_0[index]=0\n",
    "\n",
    "                    #V4から増やした集計(月での集計を加えて，comごとでの安定性について確認する)\n",
    "                    test_analysis_df=trans_test_df.copy()#集計結果を格納するためのdf\n",
    "                    final_test_analysis_df=trans_final_test_df.copy()#集計結果を格納するためのdf\n",
    "                    #集計のための情報を結合する\n",
    "                    test_analysis_df['hit_flag']=test_hit_arr#的中時に１のフラグを結合する\n",
    "                    test_analysis_df['gain']=model_test_gain_arr#的中して得られたゲインの金額を格納した配列\n",
    "                    test_analysis_df['date']=test_dates#月ごとの分析のために日付のデータを結合する\n",
    "                    test_analysis_df=get_event_info(test_analysis_df)#開催情報を取得\n",
    "\n",
    "                    final_test_analysis_df['hit_flag']=final_test_hit_arr#的中時に１のフラグを結合する\n",
    "                    final_test_analysis_df['gain']=model_final_test_gain_arr#的中して得られたゲインの金額を格納した配列\n",
    "                    final_test_analysis_df['date']=final_test_dates#月ごとの分析のために日付のデータを結合する\n",
    "                    final_test_analysis_df=get_event_info(final_test_analysis_df)#開催情報を取得\n",
    "\n",
    "                    test_m_analysis=calc_monthly_analysis(test_analysis_df)#月別の分析結果を取得\n",
    "                    final_test_m_analysis=calc_monthly_analysis(final_test_analysis_df)#月別の分析結果を取得\n",
    "                    test_m_desc=test_m_analysis.describe()\n",
    "                    final_test_m_desc=final_test_m_analysis.describe()\n",
    "                    #scoreのseriesに情報書き込み==================\n",
    "                    model_score_s['threshold']=th\n",
    "                    #テストデータ=============================================================\n",
    "                    #総収益\n",
    "                    model_score_s['total_get_test']=sum(model_test_gain_arr)\n",
    "                    #投資金額\n",
    "                    model_score_s['total_use_test']=100*trans_test_df['pred'].sum()\n",
    "                    #出現数\n",
    "                    model_score_s['num_com_test']=sum(target_y_test)\n",
    "                    #購買予測数\n",
    "                    model_score_s['num_pred_test']=trans_test_df['pred'].sum()\n",
    "                    #利益率\n",
    "                    model_score_s['gain_test']=(model_score_s['total_get_test']/model_score_s['total_use_test'])*100\n",
    "                    #利益率の標準偏差\n",
    "                    model_score_s['gain_std_test']=test_m_desc.loc['std','income_per']\n",
    "                    #的中数\n",
    "                    model_score_s['num_hit_test']=count_test\n",
    "                    #購買的中率\n",
    "                    model_score_s['buy_hit_per_test']=(count_test/trans_test_df['pred'].sum())*100\n",
    "                    #購買的中率の標準偏差\n",
    "                    model_score_s['buy_hit_per_std_test']=test_m_desc.loc['std','buy_hit_per']\n",
    "                    #配当がプラスになった月の数\n",
    "                    model_score_s['plus_month_num_test']=len(test_m_analysis[test_m_analysis['income']>0])\n",
    "                    #得られた配当の中央値と平均の差(中央値-平均，つまりマイナスが大きいほど高い配当が引っ張っている)\n",
    "                    model_score_s['diff_mea_med_test']=(test_m_desc.loc['mean','mean_income'])-(test_m_desc.loc['mean','median_income'])\n",
    "\n",
    "                    #最終テストデータ(カラム名の説明に関してはテストと同じなので割愛させていただきます)=============================================================\n",
    "                    model_score_s['total_get_final']=sum(model_final_test_gain_arr)\n",
    "                    model_score_s['total_use_final']=100*trans_final_test_df['pred'].sum()\n",
    "                    model_score_s['num_com_final']=sum(target_y_final)\n",
    "                    model_score_s['num_pred_final']=trans_final_test_df['pred'].sum()\n",
    "                    model_score_s['gain_final']=(model_score_s['total_get_final']/model_score_s['total_use_final'])*100\n",
    "                    model_score_s['gain_std_final']=final_test_m_desc.loc['std','income_per']\n",
    "\n",
    "                    model_score_s['num_hit_final']=count_final\n",
    "                    model_score_s['buy_hit_per_final']=(count_final/trans_final_test_df['pred'].sum())*100\n",
    "                    model_score_s['buy_hit_per_std_final']=final_test_m_desc.loc['std','buy_hit_per']\n",
    "                    model_score_s['plus_month_num_final']=len(final_test_m_analysis[final_test_m_analysis['income']>0])\n",
    "                    model_score_s['diff_mea_med_final']=(final_test_m_desc.loc['mean','mean_income'])-(final_test_m_desc.loc['mean','median_income'])\n",
    "\n",
    "                    #dfに書き込み\n",
    "                    model_score_df=model_score_df.append(model_score_s,ignore_index=True)\n",
    "    #モデルの「スコアを保存\n",
    "    dir_path = \"../../bot_database/{place_name}/model_score_{place_name}/v4_score/{V}/{place_name}_model_score_period_st{stDate}_finalM{finalM}_{V}.csv\".format(place_name=place_name,V=version,stDate=now_ym.strftime('%Y%m%d'),finalM=range_final_m)#作成したデータの書き込み先#使用するデータの読み込み\n",
    "    #print(dir_path)\n",
    "    model_score_df.to_csv(dir_path, encoding='utf_8_sig')\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "champion-examination",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### 機能チェック(いったん芦屋だけで動かしてみる)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "naughty-integer",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "st_date: 2020-01-01 00:00:00 =======================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/28 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asiya\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|██████████████████████████████████████████████████████████████████████▌        | 25/28 [2:05:01<13:29, 270.00s/it]<ipython-input-8-f5d39244789d>:90: RuntimeWarning: invalid value encountered in true_divide\n",
      "  income_per=(get_m/use_m)*100\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 28/28 [2:16:22<00:00, 292.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "st_date: 2020-04-01 00:00:00 =======================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/28 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asiya\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 28/28 [2:12:14<00:00, 283.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "st_date: 2020-07-01 00:00:00 =======================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/28 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asiya\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 28/28 [2:11:17<00:00, 281.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "st_date: 2020-10-01 00:00:00 =======================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/28 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asiya\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 28/28 [2:02:47<00:00, 263.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#設定する変数=================================================================\n",
    "\n",
    "\n",
    "place_master=master.get_place_master()\n",
    "place_name='asiya'\n",
    "#設定する変数=================================================================\n",
    "\n",
    "\n",
    "result_filepath=\"../..//bot_database/{place_name}/{place_name}_train/train_{place_name}.csv\".format(place_name=place_name)#作成したデータの書き込み先#使用するデータの読み込み\n",
    "result_base_df=pd.read_csv(result_filepath)\n",
    "result_base_df=result_base_df.drop([\"Unnamed: 0\"],axis=1)\n",
    "for i in range(4):\n",
    "    now_ym=datetime.datetime(year=2020, month=1+(i*3),day=1)\n",
    "    print('st_date:',now_ym,'=======================================')\n",
    "    #now_ym=datetime.datetime(year=2020, month=1,day=1)#スタート地点(今)の年月を指定，これを基準にさかのぼっていってテスト,学習データを決める(配列の中身は[year,month])\n",
    "    range_test_m=5#テストデータに使用する月の数を指定\n",
    "    range_final_m=5#最終的な評価に使うデータの数(今はここで５となっているが実際に評価をする際に必要な数は大きい値位にしておけば後で調整ができる)\n",
    "\n",
    "    result_df=data_making_clustar_section_has_final(result_base_df,now_ym,range_test_m,range_final_m)#モデル関連に使用するdfの作成関数(クラスタリングあり、モータ番号、艇番号なし)（加工関数）\n",
    "    model_score_XGboost_th_section_has_final(version,place_name,result_df,now_ym,range_test_m,range_final_m)\n",
    "    \n",
    "print('DONE')\n",
    "    #display(result_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bottom-dream",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 区間変更バージョンも作る(場所は同じく芦屋，なおテスト区間は５カ月，ファイナル区間は３カ月)\n",
    "＝１０月スタートだけデータが少なくなってしまって同じロジックが適用できない，，"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "contrary-organic",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "st_date: 2020-01-01 00:00:00 =======================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/28 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asiya\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|██████████████████████████████████████████████████████████████████████▌        | 25/28 [1:55:22<12:56, 258.92s/it]<ipython-input-4-f5d39244789d>:90: RuntimeWarning: invalid value encountered in true_divide\n",
      "  income_per=(get_m/use_m)*100\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 28/28 [2:06:02<00:00, 270.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "st_date: 2020-04-01 00:00:00 =======================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/28 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asiya\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 28/28 [2:06:58<00:00, 272.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "st_date: 2020-07-01 00:00:00 =======================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/28 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asiya\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 28/28 [2:06:27<00:00, 271.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "st_date: 2020-10-01 00:00:00 =======================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/28 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asiya\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 28/28 [2:12:15<00:00, 283.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "#設定する変数=================================================================\n",
    "version='V4_1'#バージョン\n",
    "\n",
    "place_master=master.get_place_master()\n",
    "place_name='asiya'\n",
    "#設定する変数=================================================================\n",
    "\n",
    "\n",
    "result_filepath=\"../..//bot_database/{place_name}/{place_name}_train/train_{place_name}.csv\".format(place_name=place_name)#作成したデータの書き込み先#使用するデータの読み込み\n",
    "result_base_df=pd.read_csv(result_filepath)\n",
    "result_base_df=result_base_df.drop([\"Unnamed: 0\"],axis=1)\n",
    "for i in range(4):\n",
    "    now_ym=datetime.datetime(year=2020, month=1+(i*3),day=1)\n",
    "    print('st_date:',now_ym,'=======================================')\n",
    "    #now_ym=datetime.datetime(year=2020, month=1,day=1)#スタート地点(今)の年月を指定，これを基準にさかのぼっていってテスト,学習データを決める(配列の中身は[year,month])\n",
    "    range_test_m=5#テストデータに使用する月の数を指定\n",
    "    range_final_m=3#最終的な評価に使うデータの数(今はここで５となっているが実際に評価をする際に必要な数は大きい値位にしておけば後で調整ができる)\n",
    "\n",
    "    result_df=data_making_clustar_section_has_final(result_base_df,now_ym,range_test_m,range_final_m)#モデル関連に使用するdfの作成関数(クラスタリングあり、モータ番号、艇番号なし)（加工関数）\n",
    "    model_score_XGboost_th_section_has_final(version,place_name,result_df,now_ym,range_test_m,range_final_m)\n",
    "    \n",
    "print('DONE')\n",
    "    #display(result_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lonely-upset",
   "metadata": {},
   "source": [
    "# 昨年同時期バージョン(period)\n",
    "（ex:20200101がnowdateの場合，，）<br>\n",
    "test:20190101---20190401<br>\n",
    "final:20200101--20200401<br>\n",
    "train:  ～20281201"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "forbidden-community",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "st_date: 2020-01-01 00:00:00 =======================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/28 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asiya\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 28/28 [1:54:39<00:00, 245.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "st_date: 2020-04-01 00:00:00 =======================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/28 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asiya\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 28/28 [1:52:38<00:00, 241.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "st_date: 2020-07-01 00:00:00 =======================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/28 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asiya\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 28/28 [1:53:29<00:00, 243.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "st_date: 2020-10-01 00:00:00 =======================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/28 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asiya\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████████████████████████████████████████████████████████████████████▎     | 26/28 [1:48:23<07:32, 226.08s/it]<ipython-input-10-f5d39244789d>:90: RuntimeWarning: invalid value encountered in true_divide\n",
      "  income_per=(get_m/use_m)*100\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 28/28 [1:55:03<00:00, 246.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#設定する変数=================================================================\n",
    "version='V4_1'#バージョン\n",
    "\n",
    "place_master=master.get_place_master()\n",
    "place_name='asiya'\n",
    "#設定する変数=================================================================\n",
    "\n",
    "\n",
    "result_filepath=\"../..//bot_database/{place_name}/{place_name}_train/train_{place_name}.csv\".format(place_name=place_name)#作成したデータの書き込み先#使用するデータの読み込み\n",
    "result_base_df=pd.read_csv(result_filepath)\n",
    "result_base_df=result_base_df.drop([\"Unnamed: 0\"],axis=1)\n",
    "for i in range(4):\n",
    "    now_ym=datetime.datetime(year=2020, month=1+(i*3),day=1)\n",
    "    print('st_date:',now_ym,'=======================================')\n",
    "    #now_ym=datetime.datetime(year=2020, month=1,day=1)#スタート地点(今)の年月を指定，これを基準にさかのぼっていってテスト,学習データを決める(配列の中身は[year,month])\n",
    "    range_test_m=3#テストデータに使用する月の数を指定\n",
    "    range_final_m=3#最終的な評価に使うデータの数(今はここで５となっているが実際に評価をする際に必要な数は大きい値位にしておけば後で調整ができる)\n",
    "\n",
    "    result_df=data_making_clustar_section_has_final(result_base_df,now_ym,range_test_m,range_final_m)#モデル関連に使用するdfの作成関数(クラスタリングあり、モータ番号、艇番号なし)（加工関数）\n",
    "    model_score_period_XGboost_th_section_has_final(version,place_name,result_df,now_ym,range_test_m,range_final_m)\n",
    "    \n",
    "print('DONE')\n",
    "    #display(result_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grateful-parks",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "productive-council",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valued-animation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smart-castle",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "structured-startup",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ready-fiction",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "restricted-military",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surrounded-replication",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "according-ranking",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "substantial-grass",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "objective-editor",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "written-wayne",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../bot_database/asiya/model_score_asiya/v4_score/asiya_model_score_st20200101_V4_1.csv'"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "version='V4_1'#バージョン\n",
    "now_ym=datetime.datetime(year=2020, month=1,day=1)#スタート地点(今)の年月を指定，これを基準にさかのぼっていってテスト,学習データを決める(配列の中身は[year,month])\n",
    "range_test_m=5#テストデータに使用する月の数を指定\n",
    "range_final_m=5#最終的な評価に使うデータの数(今はここで５となっているが実際に評価をする際に必要な数は大きい値位にしておけば後で調整ができる)\n",
    "place_master=master.get_place_master()\n",
    "place_name='asiya'\n",
    "\n",
    "#def model_score_XGboost_th_section_has_final(version,place_name,result_df,now_ym,range_test_m,range_final_m):#XGboostの出力を確率のやつを使用したバージョン、閾値の探索も行う。\n",
    "dir_path = \"../../bot_database/{place_name}/model_score_{place_name}/v4_score/{place_name}_model_score_st{stDate}_{V}.csv\".format(place_name=place_name,V=version,stDate=now_ym.strftime('%Y%m%d'))#作成したデータの書き込み先#使用するデータの読み込み\n",
    "dir_path   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "chief-charity",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_score_df.to_csv('csv/asiya_ex.csv', encoding='utf_8_sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "temporal-decimal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_com</th>\n",
       "      <th>depth</th>\n",
       "      <th>target_per</th>\n",
       "      <th>threshold</th>\n",
       "      <th>total_get_test</th>\n",
       "      <th>total_use_test</th>\n",
       "      <th>num_com_test</th>\n",
       "      <th>num_pred_test</th>\n",
       "      <th>gain_test</th>\n",
       "      <th>gain_std_test</th>\n",
       "      <th>...</th>\n",
       "      <th>num_com_final</th>\n",
       "      <th>num_pred_final</th>\n",
       "      <th>gain_final</th>\n",
       "      <th>gain_std_final</th>\n",
       "      <th>num_hit_final</th>\n",
       "      <th>buy_hit_per_final</th>\n",
       "      <th>buy_hit_per_std_final</th>\n",
       "      <th>diff_mea_med_final</th>\n",
       "      <th>plus_month_num_final</th>\n",
       "      <th>plus_month_num_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>0.85</td>\n",
       "      <td>24140.0</td>\n",
       "      <td>29700.0</td>\n",
       "      <td>22543.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>81.279461</td>\n",
       "      <td>49.191472</td>\n",
       "      <td>...</td>\n",
       "      <td>22364.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>100.437710</td>\n",
       "      <td>31.332901</td>\n",
       "      <td>37.0</td>\n",
       "      <td>12.457912</td>\n",
       "      <td>0.970024</td>\n",
       "      <td>110.960101</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>22640.0</td>\n",
       "      <td>27600.0</td>\n",
       "      <td>22543.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>82.028986</td>\n",
       "      <td>47.842818</td>\n",
       "      <td>...</td>\n",
       "      <td>22364.0</td>\n",
       "      <td>277.0</td>\n",
       "      <td>102.310469</td>\n",
       "      <td>41.024556</td>\n",
       "      <td>35.0</td>\n",
       "      <td>12.635379</td>\n",
       "      <td>1.052518</td>\n",
       "      <td>127.272222</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>0.92</td>\n",
       "      <td>22640.0</td>\n",
       "      <td>26600.0</td>\n",
       "      <td>22543.0</td>\n",
       "      <td>266.0</td>\n",
       "      <td>85.112782</td>\n",
       "      <td>51.492222</td>\n",
       "      <td>...</td>\n",
       "      <td>22364.0</td>\n",
       "      <td>266.0</td>\n",
       "      <td>93.120301</td>\n",
       "      <td>45.356422</td>\n",
       "      <td>33.0</td>\n",
       "      <td>12.406015</td>\n",
       "      <td>1.083072</td>\n",
       "      <td>70.083333</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>0.85</td>\n",
       "      <td>21240.0</td>\n",
       "      <td>27600.0</td>\n",
       "      <td>22543.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>76.956522</td>\n",
       "      <td>50.287162</td>\n",
       "      <td>...</td>\n",
       "      <td>22364.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>115.296296</td>\n",
       "      <td>42.007690</td>\n",
       "      <td>34.0</td>\n",
       "      <td>12.592593</td>\n",
       "      <td>0.884247</td>\n",
       "      <td>287.916667</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>19220.0</td>\n",
       "      <td>26400.0</td>\n",
       "      <td>22543.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>72.803030</td>\n",
       "      <td>48.121798</td>\n",
       "      <td>...</td>\n",
       "      <td>22364.0</td>\n",
       "      <td>251.0</td>\n",
       "      <td>107.968127</td>\n",
       "      <td>58.600878</td>\n",
       "      <td>31.0</td>\n",
       "      <td>12.350598</td>\n",
       "      <td>1.031249</td>\n",
       "      <td>176.285714</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>15150.0</td>\n",
       "      <td>14300.0</td>\n",
       "      <td>22543.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>105.944056</td>\n",
       "      <td>62.067236</td>\n",
       "      <td>...</td>\n",
       "      <td>22364.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>139.155844</td>\n",
       "      <td>70.768224</td>\n",
       "      <td>23.0</td>\n",
       "      <td>14.935065</td>\n",
       "      <td>0.984789</td>\n",
       "      <td>14.552381</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>0.92</td>\n",
       "      <td>14810.0</td>\n",
       "      <td>13100.0</td>\n",
       "      <td>22543.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>113.053435</td>\n",
       "      <td>63.646672</td>\n",
       "      <td>...</td>\n",
       "      <td>22364.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>131.063830</td>\n",
       "      <td>71.077784</td>\n",
       "      <td>19.0</td>\n",
       "      <td>13.475177</td>\n",
       "      <td>0.924710</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>0.85</td>\n",
       "      <td>7690.0</td>\n",
       "      <td>18700.0</td>\n",
       "      <td>22543.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>41.122995</td>\n",
       "      <td>26.704037</td>\n",
       "      <td>...</td>\n",
       "      <td>22364.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>87.266667</td>\n",
       "      <td>77.401831</td>\n",
       "      <td>18.0</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.534782</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>6900.0</td>\n",
       "      <td>16600.0</td>\n",
       "      <td>22543.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>41.566265</td>\n",
       "      <td>31.173842</td>\n",
       "      <td>...</td>\n",
       "      <td>22364.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>86.861314</td>\n",
       "      <td>70.251188</td>\n",
       "      <td>17.0</td>\n",
       "      <td>12.408759</td>\n",
       "      <td>1.513609</td>\n",
       "      <td>12.533333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>0.92</td>\n",
       "      <td>5560.0</td>\n",
       "      <td>15700.0</td>\n",
       "      <td>22543.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>35.414013</td>\n",
       "      <td>32.276274</td>\n",
       "      <td>...</td>\n",
       "      <td>22364.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>88.914729</td>\n",
       "      <td>82.262264</td>\n",
       "      <td>16.0</td>\n",
       "      <td>12.403101</td>\n",
       "      <td>1.680580</td>\n",
       "      <td>4.533333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>162 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     target_com  depth  target_per  threshold  total_get_test  total_use_test  \\\n",
       "0           1.0    5.0       102.0       0.85         24140.0         29700.0   \n",
       "1           1.0    5.0       102.0       0.90         22640.0         27600.0   \n",
       "2           1.0    5.0       102.0       0.92         22640.0         26600.0   \n",
       "3           1.0    5.0       104.0       0.85         21240.0         27600.0   \n",
       "4           1.0    5.0       104.0       0.90         19220.0         26400.0   \n",
       "..          ...    ...         ...        ...             ...             ...   \n",
       "157         1.0    5.0       206.0       0.90         15150.0         14300.0   \n",
       "158         1.0    5.0       206.0       0.92         14810.0         13100.0   \n",
       "159         1.0    5.0       208.0       0.85          7690.0         18700.0   \n",
       "160         1.0    5.0       208.0       0.90          6900.0         16600.0   \n",
       "161         1.0    5.0       208.0       0.92          5560.0         15700.0   \n",
       "\n",
       "     num_com_test  num_pred_test   gain_test  gain_std_test  ...  \\\n",
       "0         22543.0          297.0   81.279461      49.191472  ...   \n",
       "1         22543.0          276.0   82.028986      47.842818  ...   \n",
       "2         22543.0          266.0   85.112782      51.492222  ...   \n",
       "3         22543.0          276.0   76.956522      50.287162  ...   \n",
       "4         22543.0          264.0   72.803030      48.121798  ...   \n",
       "..            ...            ...         ...            ...  ...   \n",
       "157       22543.0          143.0  105.944056      62.067236  ...   \n",
       "158       22543.0          131.0  113.053435      63.646672  ...   \n",
       "159       22543.0          187.0   41.122995      26.704037  ...   \n",
       "160       22543.0          166.0   41.566265      31.173842  ...   \n",
       "161       22543.0          157.0   35.414013      32.276274  ...   \n",
       "\n",
       "     num_com_final  num_pred_final  gain_final  gain_std_final  num_hit_final  \\\n",
       "0          22364.0           297.0  100.437710       31.332901           37.0   \n",
       "1          22364.0           277.0  102.310469       41.024556           35.0   \n",
       "2          22364.0           266.0   93.120301       45.356422           33.0   \n",
       "3          22364.0           270.0  115.296296       42.007690           34.0   \n",
       "4          22364.0           251.0  107.968127       58.600878           31.0   \n",
       "..             ...             ...         ...             ...            ...   \n",
       "157        22364.0           154.0  139.155844       70.768224           23.0   \n",
       "158        22364.0           141.0  131.063830       71.077784           19.0   \n",
       "159        22364.0           150.0   87.266667       77.401831           18.0   \n",
       "160        22364.0           137.0   86.861314       70.251188           17.0   \n",
       "161        22364.0           129.0   88.914729       82.262264           16.0   \n",
       "\n",
       "     buy_hit_per_final  buy_hit_per_std_final  diff_mea_med_final  \\\n",
       "0            12.457912               0.970024          110.960101   \n",
       "1            12.635379               1.052518          127.272222   \n",
       "2            12.406015               1.083072           70.083333   \n",
       "3            12.592593               0.884247          287.916667   \n",
       "4            12.350598               1.031249          176.285714   \n",
       "..                 ...                    ...                 ...   \n",
       "157          14.935065               0.984789           14.552381   \n",
       "158          13.475177               0.924710            8.333333   \n",
       "159          12.000000               1.534782            6.000000   \n",
       "160          12.408759               1.513609           12.533333   \n",
       "161          12.403101               1.680580            4.533333   \n",
       "\n",
       "     plus_month_num_final  plus_month_num_test  \n",
       "0                     4.0                  2.0  \n",
       "1                     4.0                  2.0  \n",
       "2                     3.0                  2.0  \n",
       "3                     3.0                  3.0  \n",
       "4                     3.0                  2.0  \n",
       "..                    ...                  ...  \n",
       "157                   4.0                  2.0  \n",
       "158                   3.0                  2.0  \n",
       "159                   2.0                  0.0  \n",
       "160                   2.0                  0.0  \n",
       "161                   2.0                  0.0  \n",
       "\n",
       "[162 rows x 26 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "popular-locking",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_proba</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16748</th>\n",
       "      <td>0.000480</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16749</th>\n",
       "      <td>0.471421</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16750</th>\n",
       "      <td>0.000002</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16751</th>\n",
       "      <td>0.013508</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16752</th>\n",
       "      <td>0.002222</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16201</th>\n",
       "      <td>0.101803</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16202</th>\n",
       "      <td>0.005151</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16203</th>\n",
       "      <td>0.999900</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16204</th>\n",
       "      <td>0.877730</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16205</th>\n",
       "      <td>0.004401</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>908 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pred_proba  test\n",
       "16748    0.000480     0\n",
       "16749    0.471421     0\n",
       "16750    0.000002     0\n",
       "16751    0.013508     1\n",
       "16752    0.002222     1\n",
       "...           ...   ...\n",
       "16201    0.101803     0\n",
       "16202    0.005151     0\n",
       "16203    0.999900     0\n",
       "16204    0.877730     0\n",
       "16205    0.004401     0\n",
       "\n",
       "[908 rows x 2 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unauthorized-accent",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "advisory-precipitation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20190801'"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "now_ym\n",
    "test_st_date = now_ym - relativedelta(months=range_test_month) \n",
    "test_st_date\n",
    "tstr = test_st_date.strftime('%Y%m%d')\n",
    "tstr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "challenging-preference",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "banned-preserve",
   "metadata": {},
   "source": [
    "## モデルのスコアシートの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tracked-scoop",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "meaning-opportunity",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
