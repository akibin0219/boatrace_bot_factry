{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "grateful-touch",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn\n",
    "from pandas import DataFrame\n",
    "from tqdm import tqdm\n",
    "from imblearn.under_sampling import RandomUnderSampler #アンダーサンプリング用\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "# 機械学習用\n",
    "from sklearn.cluster import KMeans #クラスタリング用\n",
    "from sklearn.ensemble import RandomForestClassifier#ランダムフォレスト\n",
    "from copy import deepcopy as cp\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "import time\n",
    "import datetime\n",
    "import os #ディレクトリ作成用\n",
    "import xgboost as xgb\n",
    "import sys\n",
    "#自作のモジュールのインポート\n",
    "import module.master as master\n",
    "import module.graph as graph\n",
    "import module.trans_text_code as trans\n",
    "import module.data_making as making\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sustained-palace",
   "metadata": {},
   "source": [
    "# 新規関数案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "activated-iceland",
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef trans_date_type(df):\\n    df['date']=pd.to_datetime(df['date'])#日付が文字列なのでdateを日付型に変換\\n    df['year']=df['date'].dt.year\\n    df=df.drop('date',axis=1)\\n    return df\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dateのカラムを年だけに変換するやつ\n",
    "\"\"\"\n",
    "def trans_date_type(df):\n",
    "    df['date']=pd.to_datetime(df['date'])#日付が文字列なのでdateを日付型に変換\n",
    "    df['year']=df['date'].dt.year\n",
    "    df=df.drop('date',axis=1)\n",
    "    return df\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sexual-lotus",
   "metadata": {},
   "source": [
    "# テスト(V1_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "selected-lying",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>result_com</th>\n",
       "      <th>result_com_num</th>\n",
       "      <th>result_com_per</th>\n",
       "      <th>gain_mean</th>\n",
       "      <th>gain_median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>401</td>\n",
       "      <td>8.899245</td>\n",
       "      <td>989.576060</td>\n",
       "      <td>790.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>353</td>\n",
       "      <td>7.833999</td>\n",
       "      <td>1072.237960</td>\n",
       "      <td>720.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>220</td>\n",
       "      <td>4.882379</td>\n",
       "      <td>1479.363636</td>\n",
       "      <td>1005.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>154</td>\n",
       "      <td>3.417665</td>\n",
       "      <td>2228.051948</td>\n",
       "      <td>1505.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>227</td>\n",
       "      <td>5.037727</td>\n",
       "      <td>1569.295154</td>\n",
       "      <td>1150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>225</td>\n",
       "      <td>4.993342</td>\n",
       "      <td>1449.288889</td>\n",
       "      <td>1040.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>148</td>\n",
       "      <td>3.284510</td>\n",
       "      <td>1923.108108</td>\n",
       "      <td>1215.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>93</td>\n",
       "      <td>2.063915</td>\n",
       "      <td>2947.634409</td>\n",
       "      <td>2200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>221</td>\n",
       "      <td>4.904572</td>\n",
       "      <td>1893.303167</td>\n",
       "      <td>1290.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>169</td>\n",
       "      <td>3.750555</td>\n",
       "      <td>2130.059172</td>\n",
       "      <td>1480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>128</td>\n",
       "      <td>2.840657</td>\n",
       "      <td>2870.312500</td>\n",
       "      <td>1985.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>80</td>\n",
       "      <td>1.775411</td>\n",
       "      <td>3786.625000</td>\n",
       "      <td>2670.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>108</td>\n",
       "      <td>2.396804</td>\n",
       "      <td>2884.259259</td>\n",
       "      <td>1700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>102</td>\n",
       "      <td>2.263648</td>\n",
       "      <td>2893.235294</td>\n",
       "      <td>2080.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>74</td>\n",
       "      <td>1.642255</td>\n",
       "      <td>4221.756757</td>\n",
       "      <td>2680.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>42</td>\n",
       "      <td>0.932091</td>\n",
       "      <td>6478.095238</td>\n",
       "      <td>3645.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>56</td>\n",
       "      <td>1.242787</td>\n",
       "      <td>5181.607143</td>\n",
       "      <td>2485.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>38</td>\n",
       "      <td>0.843320</td>\n",
       "      <td>4122.368421</td>\n",
       "      <td>2820.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>45</td>\n",
       "      <td>0.998668</td>\n",
       "      <td>11904.000000</td>\n",
       "      <td>5720.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>26</td>\n",
       "      <td>0.577008</td>\n",
       "      <td>12113.461538</td>\n",
       "      <td>7285.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>97</td>\n",
       "      <td>2.152685</td>\n",
       "      <td>3454.845361</td>\n",
       "      <td>2390.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>103</td>\n",
       "      <td>2.285841</td>\n",
       "      <td>4193.980583</td>\n",
       "      <td>2760.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>71</td>\n",
       "      <td>1.575677</td>\n",
       "      <td>5095.352113</td>\n",
       "      <td>3480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>56</td>\n",
       "      <td>1.242787</td>\n",
       "      <td>4777.857143</td>\n",
       "      <td>2640.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>37</td>\n",
       "      <td>0.821127</td>\n",
       "      <td>8803.783784</td>\n",
       "      <td>5860.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>0.577008</td>\n",
       "      <td>7287.692308</td>\n",
       "      <td>3955.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>31</td>\n",
       "      <td>0.687972</td>\n",
       "      <td>11877.419355</td>\n",
       "      <td>3010.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>21</td>\n",
       "      <td>0.466045</td>\n",
       "      <td>4578.095238</td>\n",
       "      <td>3850.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    result_com  result_com_num  result_com_per     gain_mean  gain_median\n",
       "0            1             401        8.899245    989.576060        790.0\n",
       "1            2             353        7.833999   1072.237960        720.0\n",
       "2            3             220        4.882379   1479.363636       1005.0\n",
       "3            4             154        3.417665   2228.051948       1505.0\n",
       "4            5             227        5.037727   1569.295154       1150.0\n",
       "5            6             225        4.993342   1449.288889       1040.0\n",
       "6            7             148        3.284510   1923.108108       1215.0\n",
       "7            8              93        2.063915   2947.634409       2200.0\n",
       "8            9             221        4.904572   1893.303167       1290.0\n",
       "9           10             169        3.750555   2130.059172       1480.0\n",
       "10          11             128        2.840657   2870.312500       1985.0\n",
       "11          12              80        1.775411   3786.625000       2670.0\n",
       "12          13             108        2.396804   2884.259259       1700.0\n",
       "13          14             102        2.263648   2893.235294       2080.0\n",
       "14          15              74        1.642255   4221.756757       2680.0\n",
       "15          16              42        0.932091   6478.095238       3645.0\n",
       "16          17              56        1.242787   5181.607143       2485.0\n",
       "17          18              38        0.843320   4122.368421       2820.0\n",
       "18          19              45        0.998668  11904.000000       5720.0\n",
       "19          20              26        0.577008  12113.461538       7285.0\n",
       "20          21              97        2.152685   3454.845361       2390.0\n",
       "21          22             103        2.285841   4193.980583       2760.0\n",
       "22          23              71        1.575677   5095.352113       3480.0\n",
       "23          24              56        1.242787   4777.857143       2640.0\n",
       "24          25              37        0.821127   8803.783784       5860.0\n",
       "25          26              26        0.577008   7287.692308       3955.0\n",
       "26          27              31        0.687972  11877.419355       3010.0\n",
       "27          28              21        0.466045   4578.095238       3850.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#place_master=master.get_place_master()\n",
    "#for place in place_master.items():\n",
    "\n",
    "pd.set_option('display.width',400)#勝手に改行コードを入れられるのを防ぐ\n",
    "place_name='tokuyama'#今回は徳山を例にしていったんXGboostバージョンを作る。\n",
    "\n",
    "################################################========================================================================================================================\n",
    "################################################========================================================================================================================\n",
    "################################################========================================================================================================================\n",
    "################################################========================================================================================================================\n",
    "result_filepath=\"../..//bot_database/{place_name}/{place_name}_train/train_{place_name}.csv\".format(place_name=place_name)#作成したデータの書き込み先#使用するデータの読み込み\n",
    "result_base_df=pd.read_csv(result_filepath)\n",
    "result_base_df=result_base_df.drop([\"Unnamed: 0\"],axis=1)\n",
    "result_df=making.data_making_mo_bo(result_base_df)\n",
    "\n",
    "\n",
    "#学習データの切り分け\n",
    "test_df = result_df[(result_df['year']==2019) | ((result_df['year']==2020) )]#2019,2020のデータを検証用データに。\n",
    "train_df =  result_df[(result_df['year']!=2019) & ((result_df['year']!=2020) )]#そのほかを学習データに\n",
    "#学習データを切り分けたらyearはいらないから削除する\n",
    "test_df=test_df.drop(['year'],axis=1)\n",
    "train_df=train_df.drop(['year'],axis=1)\n",
    "\n",
    "train_money=pd.Series(train_df['money'])\n",
    "test_money=pd.Series(test_df['money'])\n",
    "\n",
    "#x,yへの切り分け\n",
    "#出現数の分布\n",
    "result_com_s=test_df['result_com'].value_counts()\n",
    "result_com_s=result_com_s.sort_index()\n",
    "gain_mean=test_df.groupby('result_com')['money'].mean()\n",
    "gain_mean=gain_mean.sort_index()\n",
    "\n",
    "gain_median=test_df.groupby('result_com')['money'].median()\n",
    "gain_median=gain_median.sort_index()\n",
    "result_com_df=pd.DataFrame({'result_com':result_com_s.index,\n",
    "                            'result_com_num':result_com_s.values,\n",
    "                            'result_com_per':result_com_s.values/sum(result_com_s.values)*100,\n",
    "                            'gain_mean':gain_mean.values,\n",
    "                            'gain_median':gain_median.values,})\n",
    "result_com_df=result_com_df.iloc[0:28]#探索的に探すにも最後のほうは役にモデルなのはわかっているため\n",
    "result_com_df\n",
    "#result_com_df=result_com_df.set_index('result_com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "super-onion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>result_com</th>\n",
       "      <th>money</th>\n",
       "      <th>racer_1_rank</th>\n",
       "      <th>racer_1_age</th>\n",
       "      <th>racer_1_doub</th>\n",
       "      <th>racer_1_ave_st</th>\n",
       "      <th>racer_2_rank</th>\n",
       "      <th>racer_2_age</th>\n",
       "      <th>racer_2_doub</th>\n",
       "      <th>racer_2_ave_st</th>\n",
       "      <th>...</th>\n",
       "      <th>racer_6_bo_90</th>\n",
       "      <th>racer_6_bo_91</th>\n",
       "      <th>racer_6_bo_92</th>\n",
       "      <th>racer_6_bo_93</th>\n",
       "      <th>racer_6_bo_94</th>\n",
       "      <th>racer_6_bo_95</th>\n",
       "      <th>racer_6_bo_96</th>\n",
       "      <th>racer_6_bo_97</th>\n",
       "      <th>racer_6_bo_98</th>\n",
       "      <th>racer_6_bo_99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14797</th>\n",
       "      <td>20</td>\n",
       "      <td>16650.0</td>\n",
       "      <td>3</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.387</td>\n",
       "      <td>0.17</td>\n",
       "      <td>2</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.297</td>\n",
       "      <td>0.17</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14798</th>\n",
       "      <td>42</td>\n",
       "      <td>1740.0</td>\n",
       "      <td>4</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.442</td>\n",
       "      <td>0.18</td>\n",
       "      <td>4</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.468</td>\n",
       "      <td>0.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14799</th>\n",
       "      <td>3</td>\n",
       "      <td>910.0</td>\n",
       "      <td>3</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.448</td>\n",
       "      <td>0.18</td>\n",
       "      <td>2</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.17</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14800</th>\n",
       "      <td>63</td>\n",
       "      <td>6920.0</td>\n",
       "      <td>4</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.630</td>\n",
       "      <td>0.16</td>\n",
       "      <td>2</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.295</td>\n",
       "      <td>0.19</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14801</th>\n",
       "      <td>21</td>\n",
       "      <td>1250.0</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.20</td>\n",
       "      <td>4</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.15</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19298</th>\n",
       "      <td>12</td>\n",
       "      <td>730.0</td>\n",
       "      <td>3</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.416</td>\n",
       "      <td>0.14</td>\n",
       "      <td>2</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.17</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19299</th>\n",
       "      <td>70</td>\n",
       "      <td>14660.0</td>\n",
       "      <td>2</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.18</td>\n",
       "      <td>4</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.14</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19300</th>\n",
       "      <td>9</td>\n",
       "      <td>4170.0</td>\n",
       "      <td>4</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.17</td>\n",
       "      <td>3</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.386</td>\n",
       "      <td>0.17</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19301</th>\n",
       "      <td>14</td>\n",
       "      <td>1480.0</td>\n",
       "      <td>4</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.435</td>\n",
       "      <td>0.15</td>\n",
       "      <td>2</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19302</th>\n",
       "      <td>11</td>\n",
       "      <td>2530.0</td>\n",
       "      <td>4</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.12</td>\n",
       "      <td>4</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.428</td>\n",
       "      <td>0.13</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4506 rows × 1238 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       result_com    money  racer_1_rank  racer_1_age  racer_1_doub  racer_1_ave_st  racer_2_rank  racer_2_age  racer_2_doub  racer_2_ave_st  ...  racer_6_bo_90  racer_6_bo_91  racer_6_bo_92  racer_6_bo_93  racer_6_bo_94  racer_6_bo_95  racer_6_bo_96  racer_6_bo_97  racer_6_bo_98  racer_6_bo_99\n",
       "14797          20  16650.0             3         31.0         0.387            0.17             2         27.0         0.297            0.17  ...              0              0              0              0              0              0              0              0              0              0\n",
       "14798          42   1740.0             4         25.0         0.442            0.18             4         27.0         0.468            0.16  ...              0              0              0              0              0              0              0              0              0              0\n",
       "14799           3    910.0             3         33.0         0.448            0.18             2         26.0         0.193            0.17  ...              0              0              0              0              0              0              0              0              0              0\n",
       "14800          63   6920.0             4         30.0         0.630            0.16             2         30.0         0.295            0.19  ...              0              0              0              0              0              0              0              0              0              0\n",
       "14801          21   1250.0             1         27.0         0.111            0.20             4         31.0         0.400            0.15  ...              0              0              0              0              0              0              0              0              0              0\n",
       "...           ...      ...           ...          ...           ...             ...           ...          ...           ...             ...  ...            ...            ...            ...            ...            ...            ...            ...            ...            ...            ...\n",
       "19298          12    730.0             3         33.0         0.416            0.14             2         35.0         0.179            0.17  ...              0              0              0              0              0              0              0              0              0              0\n",
       "19299          70  14660.0             2         35.0         0.259            0.18             4         33.0         0.485            0.14  ...              0              0              0              0              0              0              0              0              0              0\n",
       "19300           9   4170.0             4         24.0         0.500            0.17             3         46.0         0.386            0.17  ...              0              0              0              0              0              0              0              0              0              0\n",
       "19301          14   1480.0             4         35.0         0.435            0.15             2         47.0         0.215            0.16  ...              0              0              0              0              0              0              0              0              0              0\n",
       "19302          11   2530.0             4         45.0         0.675            0.12             4         39.0         0.428            0.13  ...              0              0              0              0              0              0              0              0              0              0\n",
       "\n",
       "[4506 rows x 1238 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "whole-nicaragua",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                                                                                                                                                                                                                | 0/59 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-logloss:13.42816\ttrain-logloss:12.48201\n",
      "[1]\teval-logloss:12.91169\ttrain-logloss:10.32249\n",
      "[2]\teval-logloss:12.91169\ttrain-logloss:8.98359\n",
      "[3]\teval-logloss:12.73954\ttrain-logloss:7.81745\n",
      "[4]\teval-logloss:13.08385\ttrain-logloss:6.82407\n",
      "[5]\teval-logloss:12.73954\ttrain-logloss:6.17622\n",
      "[6]\teval-logloss:12.39522\ttrain-logloss:5.83070\n",
      "[7]\teval-logloss:13.94463\ttrain-logloss:4.83732\n",
      "[8]\teval-logloss:13.42816\ttrain-logloss:4.18946\n",
      "[9]\teval-logloss:14.46110\ttrain-logloss:3.88713\n",
      "[10]\teval-logloss:13.25600\ttrain-logloss:3.67118\n",
      "[11]\teval-logloss:13.94463\ttrain-logloss:2.98013\n",
      "[12]\teval-logloss:14.11678\ttrain-logloss:2.89375\n",
      "[13]\teval-logloss:12.73954\ttrain-logloss:2.54823\n",
      "[14]\teval-logloss:13.60032\ttrain-logloss:2.24590\n",
      "[15]\teval-logloss:13.25600\ttrain-logloss:1.85719\n",
      "[16]\teval-logloss:13.77247\ttrain-logloss:2.02995\n",
      "[17]\teval-logloss:12.22307\ttrain-logloss:1.59804\n",
      "[18]\teval-logloss:12.22307\ttrain-logloss:1.20933\n",
      "[19]\teval-logloss:13.08385\ttrain-logloss:1.20933\n",
      "[20]\teval-logloss:12.91169\ttrain-logloss:1.12295\n",
      "[21]\teval-logloss:12.39522\ttrain-logloss:1.03657\n",
      "[22]\teval-logloss:12.56738\ttrain-logloss:1.16614\n",
      "[23]\teval-logloss:12.91169\ttrain-logloss:0.77743\n",
      "[24]\teval-logloss:12.91169\ttrain-logloss:0.73424\n",
      "[25]\teval-logloss:13.25600\ttrain-logloss:0.64785\n",
      "[26]\teval-logloss:11.53445\ttrain-logloss:0.38871\n",
      "[27]\teval-logloss:12.22307\ttrain-logloss:0.60467\n",
      "[28]\teval-logloss:12.73954\ttrain-logloss:0.56147\n",
      "[29]\teval-logloss:12.56738\ttrain-logloss:0.21595\n",
      "[30]\teval-logloss:13.08385\ttrain-logloss:0.21595\n",
      "[31]\teval-logloss:11.87876\ttrain-logloss:0.30233\n",
      "[32]\teval-logloss:12.56738\ttrain-logloss:0.30233\n",
      "[33]\teval-logloss:12.39522\ttrain-logloss:0.21595\n",
      "[34]\teval-logloss:13.60032\ttrain-logloss:0.43190\n",
      "[35]\teval-logloss:12.39522\ttrain-logloss:0.21595\n",
      "[36]\teval-logloss:13.08385\ttrain-logloss:0.17276\n",
      "[37]\teval-logloss:12.39522\ttrain-logloss:0.12957\n",
      "[38]\teval-logloss:12.73954\ttrain-logloss:0.04319\n",
      "[39]\teval-logloss:12.22307\ttrain-logloss:0.00000\n",
      "[40]\teval-logloss:11.70660\ttrain-logloss:0.08638\n",
      "[41]\teval-logloss:12.05091\ttrain-logloss:0.04319\n",
      "[42]\teval-logloss:11.87876\ttrain-logloss:0.12957\n",
      "[43]\teval-logloss:12.39522\ttrain-logloss:0.17276\n",
      "[44]\teval-logloss:12.39522\ttrain-logloss:0.04319\n",
      "[45]\teval-logloss:12.22307\ttrain-logloss:0.00000\n",
      "[46]\teval-logloss:12.05091\ttrain-logloss:0.00000\n",
      "[47]\teval-logloss:11.87876\ttrain-logloss:0.08638\n",
      "[48]\teval-logloss:12.39522\ttrain-logloss:0.08638\n",
      "[49]\teval-logloss:11.87876\ttrain-logloss:0.08638\n",
      "[50]\teval-logloss:12.56738\ttrain-logloss:0.08638\n",
      "[51]\teval-logloss:12.73954\ttrain-logloss:0.00000\n",
      "[52]\teval-logloss:12.39522\ttrain-logloss:0.04319\n",
      "[53]\teval-logloss:12.39522\ttrain-logloss:0.00000\n",
      "[54]\teval-logloss:12.73954\ttrain-logloss:0.04319\n",
      "[55]\teval-logloss:12.56738\ttrain-logloss:0.00000\n",
      "[56]\teval-logloss:13.25600\ttrain-logloss:0.04319\n",
      "[57]\teval-logloss:12.56738\ttrain-logloss:0.04319\n",
      "[58]\teval-logloss:13.25600\ttrain-logloss:0.00000\n",
      "[59]\teval-logloss:12.73954\ttrain-logloss:0.04319\n",
      "[60]\teval-logloss:13.25600\ttrain-logloss:0.00000\n",
      "[61]\teval-logloss:12.73954\ttrain-logloss:0.04319\n",
      "[62]\teval-logloss:13.42816\ttrain-logloss:0.00000\n",
      "[63]\teval-logloss:12.91169\ttrain-logloss:0.04319\n",
      "[64]\teval-logloss:13.42816\ttrain-logloss:0.00000\n",
      "[65]\teval-logloss:12.73954\ttrain-logloss:0.00000\n",
      "[66]\teval-logloss:13.42816\ttrain-logloss:0.00000\n",
      "[67]\teval-logloss:12.73954\ttrain-logloss:0.00000\n",
      "[68]\teval-logloss:13.42816\ttrain-logloss:0.00000\n",
      "[69]\teval-logloss:12.73954\ttrain-logloss:0.04319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|████▋                                                                                                                                                                                                                                                                                   | 1/59 [00:00<00:36,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-logloss:15.88573\ttrain-logloss:12.50578\n",
      "[1]\teval-logloss:16.39271\ttrain-logloss:11.40730\n",
      "[2]\teval-logloss:15.88573\ttrain-logloss:9.46384\n",
      "[3]\teval-logloss:16.22372\ttrain-logloss:7.94286\n",
      "[4]\teval-logloss:15.71673\ttrain-logloss:7.64712\n",
      "[5]\teval-logloss:14.87174\ttrain-logloss:6.71763\n",
      "[6]\teval-logloss:15.37873\ttrain-logloss:5.32341\n",
      "[7]\teval-logloss:15.54773\ttrain-logloss:5.02766\n",
      "[8]\teval-logloss:15.71673\ttrain-logloss:4.56292\n",
      "[9]\teval-logloss:15.20974\ttrain-logloss:3.67569\n",
      "[10]\teval-logloss:15.54773\ttrain-logloss:3.54894\n",
      "[11]\teval-logloss:16.73071\ttrain-logloss:3.08420\n",
      "[12]\teval-logloss:16.22372\ttrain-logloss:2.91520\n",
      "[13]\teval-logloss:18.58968\ttrain-logloss:2.07021\n",
      "[14]\teval-logloss:17.74469\ttrain-logloss:1.90122\n",
      "[15]\teval-logloss:17.57569\ttrain-logloss:1.60547\n",
      "[16]\teval-logloss:16.73071\ttrain-logloss:1.43647\n",
      "[17]\teval-logloss:17.74469\ttrain-logloss:1.26748\n",
      "[18]\teval-logloss:17.40670\ttrain-logloss:1.18298\n",
      "[19]\teval-logloss:17.40670\ttrain-logloss:1.05623\n",
      "[20]\teval-logloss:17.40670\ttrain-logloss:0.92948\n",
      "[21]\teval-logloss:17.74469\ttrain-logloss:0.67599\n",
      "[22]\teval-logloss:17.74469\ttrain-logloss:0.76049\n",
      "[23]\teval-logloss:18.25168\ttrain-logloss:0.71824\n",
      "[24]\teval-logloss:17.23770\ttrain-logloss:0.63374\n",
      "[25]\teval-logloss:19.60366\ttrain-logloss:0.50699\n",
      "[26]\teval-logloss:18.58968\ttrain-logloss:0.46474\n",
      "[27]\teval-logloss:19.94165\ttrain-logloss:0.42249\n",
      "[28]\teval-logloss:19.94165\ttrain-logloss:0.54924\n",
      "[29]\teval-logloss:19.09667\ttrain-logloss:0.50699\n",
      "[30]\teval-logloss:19.94165\ttrain-logloss:0.16900\n",
      "[31]\teval-logloss:18.08269\ttrain-logloss:0.33799\n",
      "[32]\teval-logloss:18.75868\ttrain-logloss:0.25350\n",
      "[33]\teval-logloss:18.75868\ttrain-logloss:0.25350\n",
      "[34]\teval-logloss:17.91369\ttrain-logloss:0.50699\n",
      "[35]\teval-logloss:17.91369\ttrain-logloss:0.12675\n",
      "[36]\teval-logloss:19.26566\ttrain-logloss:0.25350\n",
      "[37]\teval-logloss:19.26566\ttrain-logloss:0.21125\n",
      "[38]\teval-logloss:18.42068\ttrain-logloss:0.12675\n",
      "[39]\teval-logloss:18.92767\ttrain-logloss:0.12675\n",
      "[40]\teval-logloss:17.74469\ttrain-logloss:0.25350\n",
      "[41]\teval-logloss:17.74469\ttrain-logloss:0.04225\n",
      "[42]\teval-logloss:18.08269\ttrain-logloss:0.04225\n",
      "[43]\teval-logloss:17.74469\ttrain-logloss:0.04225\n",
      "[44]\teval-logloss:17.40670\ttrain-logloss:0.00000\n",
      "[45]\teval-logloss:17.40670\ttrain-logloss:0.04225\n",
      "[46]\teval-logloss:17.40670\ttrain-logloss:0.00000\n",
      "[47]\teval-logloss:17.57569\ttrain-logloss:0.04225\n",
      "[48]\teval-logloss:17.40670\ttrain-logloss:0.00000\n",
      "[49]\teval-logloss:17.57569\ttrain-logloss:0.00000\n",
      "[50]\teval-logloss:17.40670\ttrain-logloss:0.00000\n",
      "[51]\teval-logloss:17.57569\ttrain-logloss:0.00000\n",
      "[52]\teval-logloss:17.40670\ttrain-logloss:0.04225\n",
      "[53]\teval-logloss:17.57569\ttrain-logloss:0.00000\n",
      "[54]\teval-logloss:17.23770\ttrain-logloss:0.00000\n",
      "[55]\teval-logloss:17.57569\ttrain-logloss:0.00000\n",
      "[56]\teval-logloss:17.40670\ttrain-logloss:0.00000\n",
      "[57]\teval-logloss:17.57569\ttrain-logloss:0.00000\n",
      "[58]\teval-logloss:17.40670\ttrain-logloss:0.00000\n",
      "[59]\teval-logloss:17.57569\ttrain-logloss:0.00000\n",
      "[60]\teval-logloss:17.40670\ttrain-logloss:0.04225\n",
      "[61]\teval-logloss:17.40670\ttrain-logloss:0.00000\n",
      "[62]\teval-logloss:17.23770\ttrain-logloss:0.00000\n",
      "[63]\teval-logloss:17.57569\ttrain-logloss:0.00000\n",
      "[64]\teval-logloss:17.23770\ttrain-logloss:0.00000\n",
      "[65]\teval-logloss:17.57569\ttrain-logloss:0.00000\n",
      "[66]\teval-logloss:17.23770\ttrain-logloss:0.00000\n",
      "[67]\teval-logloss:17.74469\ttrain-logloss:0.04225\n",
      "[68]\teval-logloss:17.40670\ttrain-logloss:0.00000\n",
      "[69]\teval-logloss:17.74469\ttrain-logloss:0.00000\n",
      "[70]\teval-logloss:16.73071\ttrain-logloss:0.04225\n",
      "[71]\teval-logloss:17.23770\ttrain-logloss:0.00000\n",
      "[72]\teval-logloss:16.89971\ttrain-logloss:0.00000\n",
      "[73]\teval-logloss:17.57569\ttrain-logloss:0.00000\n",
      "[74]\teval-logloss:17.23770\ttrain-logloss:0.08450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|█████████▍                                                                                                                                                                                                                                                                              | 2/59 [00:01<00:33,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-logloss:17.18162\ttrain-logloss:14.98491\n",
      "[1]\teval-logloss:16.02517\ttrain-logloss:10.96962\n",
      "[2]\teval-logloss:15.69475\ttrain-logloss:8.44454\n",
      "[3]\teval-logloss:16.19037\ttrain-logloss:7.40967\n",
      "[4]\teval-logloss:16.68600\ttrain-logloss:6.25061\n",
      "[5]\teval-logloss:18.50328\ttrain-logloss:5.33993\n",
      "[6]\teval-logloss:17.84245\ttrain-logloss:4.92598\n",
      "[7]\teval-logloss:16.52079\ttrain-logloss:4.05669\n",
      "[8]\teval-logloss:15.36433\ttrain-logloss:3.31158\n",
      "[9]\teval-logloss:16.02517\ttrain-logloss:2.56648\n",
      "[10]\teval-logloss:16.02517\ttrain-logloss:2.69066\n",
      "[11]\teval-logloss:15.19913\ttrain-logloss:1.98695\n",
      "[12]\teval-logloss:15.69475\ttrain-logloss:1.86277\n",
      "[13]\teval-logloss:15.85996\ttrain-logloss:1.73858\n",
      "[14]\teval-logloss:14.53829\ttrain-logloss:1.53161\n",
      "[15]\teval-logloss:14.37309\ttrain-logloss:1.49021\n",
      "[16]\teval-logloss:16.02517\ttrain-logloss:1.28324\n",
      "[17]\teval-logloss:16.68600\ttrain-logloss:1.40742\n",
      "[18]\teval-logloss:17.51204\ttrain-logloss:1.11766\n",
      "[19]\teval-logloss:15.52954\ttrain-logloss:0.91068\n",
      "[20]\teval-logloss:15.52954\ttrain-logloss:0.95208\n",
      "[21]\teval-logloss:15.85996\ttrain-logloss:0.95208\n",
      "[22]\teval-logloss:17.51204\ttrain-logloss:0.49674\n",
      "[23]\teval-logloss:16.68600\ttrain-logloss:0.66232\n",
      "[24]\teval-logloss:17.34683\ttrain-logloss:0.49674\n",
      "[25]\teval-logloss:16.19037\ttrain-logloss:0.62092\n",
      "[26]\teval-logloss:16.68600\ttrain-logloss:0.49674\n",
      "[27]\teval-logloss:16.02517\ttrain-logloss:0.53813\n",
      "[28]\teval-logloss:18.00766\ttrain-logloss:0.45534\n",
      "[29]\teval-logloss:15.85996\ttrain-logloss:0.45534\n",
      "[30]\teval-logloss:16.68600\ttrain-logloss:0.41395\n",
      "[31]\teval-logloss:15.52954\ttrain-logloss:0.24837\n",
      "[32]\teval-logloss:15.69475\ttrain-logloss:0.28976\n",
      "[33]\teval-logloss:15.36433\ttrain-logloss:0.24837\n",
      "[34]\teval-logloss:15.85996\ttrain-logloss:0.28976\n",
      "[35]\teval-logloss:15.36433\ttrain-logloss:0.20697\n",
      "[36]\teval-logloss:16.85121\ttrain-logloss:0.20697\n",
      "[37]\teval-logloss:16.02517\ttrain-logloss:0.08279\n",
      "[38]\teval-logloss:17.18162\ttrain-logloss:0.12418\n",
      "[39]\teval-logloss:17.18162\ttrain-logloss:0.24837\n",
      "[40]\teval-logloss:16.85121\ttrain-logloss:0.12418\n",
      "[41]\teval-logloss:17.18162\ttrain-logloss:0.16558\n",
      "[42]\teval-logloss:17.18162\ttrain-logloss:0.24837\n",
      "[43]\teval-logloss:17.18162\ttrain-logloss:0.28976\n",
      "[44]\teval-logloss:17.67724\ttrain-logloss:0.28976\n",
      "[45]\teval-logloss:17.01641\ttrain-logloss:0.37255\n",
      "[46]\teval-logloss:17.34683\ttrain-logloss:0.16558\n",
      "[47]\teval-logloss:17.18162\ttrain-logloss:0.16558\n",
      "[48]\teval-logloss:17.18162\ttrain-logloss:0.12418\n",
      "[49]\teval-logloss:17.51204\ttrain-logloss:0.20697\n",
      "[50]\teval-logloss:17.51204\ttrain-logloss:0.12418\n",
      "[51]\teval-logloss:17.01641\ttrain-logloss:0.12418\n",
      "[52]\teval-logloss:17.18162\ttrain-logloss:0.04140\n",
      "[53]\teval-logloss:16.52079\ttrain-logloss:0.04140\n",
      "[54]\teval-logloss:17.34683\ttrain-logloss:0.08279\n",
      "[55]\teval-logloss:16.68600\ttrain-logloss:0.08279\n",
      "[56]\teval-logloss:17.34683\ttrain-logloss:0.04140\n",
      "[57]\teval-logloss:16.52079\ttrain-logloss:0.00000\n",
      "[58]\teval-logloss:17.18162\ttrain-logloss:0.12418\n",
      "[59]\teval-logloss:17.01641\ttrain-logloss:0.04140\n",
      "[60]\teval-logloss:17.34683\ttrain-logloss:0.00000\n",
      "[61]\teval-logloss:17.18162\ttrain-logloss:0.08279\n",
      "[62]\teval-logloss:17.34683\ttrain-logloss:0.00000\n",
      "[63]\teval-logloss:17.51204\ttrain-logloss:0.12418\n",
      "[64]\teval-logloss:17.67724\ttrain-logloss:0.00000\n",
      "[65]\teval-logloss:17.01641\ttrain-logloss:0.00000\n",
      "[66]\teval-logloss:17.01641\ttrain-logloss:0.00000\n",
      "[67]\teval-logloss:17.18162\ttrain-logloss:0.00000\n",
      "[68]\teval-logloss:17.34683\ttrain-logloss:0.12418\n",
      "[69]\teval-logloss:17.18162\ttrain-logloss:0.20697\n",
      "[70]\teval-logloss:17.84245\ttrain-logloss:0.08279\n",
      "[71]\teval-logloss:17.34683\ttrain-logloss:0.08279\n",
      "[72]\teval-logloss:17.34683\ttrain-logloss:0.28976\n",
      "[73]\teval-logloss:17.34683\ttrain-logloss:0.12418\n",
      "[74]\teval-logloss:17.51204\ttrain-logloss:0.08279\n",
      "[75]\teval-logloss:17.51204\ttrain-logloss:0.04140\n",
      "[76]\teval-logloss:17.51204\ttrain-logloss:0.08279\n",
      "[77]\teval-logloss:17.67724\ttrain-logloss:0.04140\n",
      "[78]\teval-logloss:17.34683\ttrain-logloss:0.04140\n",
      "[79]\teval-logloss:17.18162\ttrain-logloss:0.04140\n",
      "[80]\teval-logloss:17.34683\ttrain-logloss:0.04140\n",
      "[81]\teval-logloss:17.18162\ttrain-logloss:0.04140\n",
      "[82]\teval-logloss:17.01641\ttrain-logloss:0.12418\n",
      "[83]\teval-logloss:17.01641\ttrain-logloss:0.00000\n",
      "[84]\teval-logloss:16.85121\ttrain-logloss:0.08279\n",
      "[85]\teval-logloss:17.01641\ttrain-logloss:0.00000\n",
      "[86]\teval-logloss:17.01641\ttrain-logloss:0.04140\n",
      "[87]\teval-logloss:17.01641\ttrain-logloss:0.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|██████████████▏                                                                                                                                                                                                                                                                         | 3/59 [00:01<00:32,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-logloss:15.83532\ttrain-logloss:13.55178\n",
      "[1]\teval-logloss:14.70423\ttrain-logloss:12.21283\n",
      "[2]\teval-logloss:14.70423\ttrain-logloss:10.34642\n",
      "[3]\teval-logloss:14.86581\ttrain-logloss:8.23656\n",
      "[4]\teval-logloss:15.51215\ttrain-logloss:7.66852\n",
      "[5]\teval-logloss:14.86581\ttrain-logloss:6.97876\n",
      "[6]\teval-logloss:16.15849\ttrain-logloss:5.72096\n",
      "[7]\teval-logloss:16.15849\ttrain-logloss:4.74718\n",
      "[8]\teval-logloss:16.96642\ttrain-logloss:4.13857\n",
      "[9]\teval-logloss:16.64325\ttrain-logloss:3.61110\n",
      "[10]\teval-logloss:16.48166\ttrain-logloss:3.73283\n",
      "[11]\teval-logloss:15.67374\ttrain-logloss:3.20536\n",
      "[12]\teval-logloss:16.64325\ttrain-logloss:2.71847\n",
      "[13]\teval-logloss:16.80483\ttrain-logloss:2.43445\n",
      "[14]\teval-logloss:16.48166\ttrain-logloss:2.27215\n",
      "[15]\teval-logloss:15.67374\ttrain-logloss:2.06928\n",
      "[16]\teval-logloss:15.51215\ttrain-logloss:1.90699\n",
      "[17]\teval-logloss:15.18898\ttrain-logloss:1.62297\n",
      "[18]\teval-logloss:14.86581\ttrain-logloss:1.42010\n",
      "[19]\teval-logloss:15.35057\ttrain-logloss:1.25780\n",
      "[20]\teval-logloss:15.67374\ttrain-logloss:0.97378\n",
      "[21]\teval-logloss:15.99691\ttrain-logloss:1.01435\n",
      "[22]\teval-logloss:15.02740\ttrain-logloss:0.73033\n",
      "[23]\teval-logloss:15.18898\ttrain-logloss:0.56804\n",
      "[24]\teval-logloss:16.15849\ttrain-logloss:0.97378\n",
      "[25]\teval-logloss:16.48166\ttrain-logloss:0.56804\n",
      "[26]\teval-logloss:15.02740\ttrain-logloss:0.77091\n",
      "[27]\teval-logloss:16.15849\ttrain-logloss:0.56804\n",
      "[28]\teval-logloss:15.51215\ttrain-logloss:0.52746\n",
      "[29]\teval-logloss:16.32008\ttrain-logloss:0.36517\n",
      "[30]\teval-logloss:16.15849\ttrain-logloss:0.20287\n",
      "[31]\teval-logloss:15.83532\ttrain-logloss:0.28402\n",
      "[32]\teval-logloss:15.99691\ttrain-logloss:0.52746\n",
      "[33]\teval-logloss:16.32008\ttrain-logloss:0.32459\n",
      "[34]\teval-logloss:16.48166\ttrain-logloss:0.32459\n",
      "[35]\teval-logloss:16.64325\ttrain-logloss:0.16230\n",
      "[36]\teval-logloss:15.99691\ttrain-logloss:0.32459\n",
      "[37]\teval-logloss:16.32008\ttrain-logloss:0.24344\n",
      "[38]\teval-logloss:15.99691\ttrain-logloss:0.12172\n",
      "[39]\teval-logloss:16.32008\ttrain-logloss:0.24344\n",
      "[40]\teval-logloss:15.99691\ttrain-logloss:0.12172\n",
      "[41]\teval-logloss:16.15849\ttrain-logloss:0.16230\n",
      "[42]\teval-logloss:15.99691\ttrain-logloss:0.28402\n",
      "[43]\teval-logloss:16.64325\ttrain-logloss:0.08115\n",
      "[44]\teval-logloss:16.15849\ttrain-logloss:0.12172\n",
      "[45]\teval-logloss:16.96642\ttrain-logloss:0.04057\n",
      "[46]\teval-logloss:16.80483\ttrain-logloss:0.20287\n",
      "[47]\teval-logloss:16.80483\ttrain-logloss:0.16230\n",
      "[48]\teval-logloss:16.96642\ttrain-logloss:0.12172\n",
      "[49]\teval-logloss:16.96642\ttrain-logloss:0.08115\n",
      "[50]\teval-logloss:17.45117\ttrain-logloss:0.04057\n",
      "[51]\teval-logloss:16.32008\ttrain-logloss:0.16230\n",
      "[52]\teval-logloss:17.12800\ttrain-logloss:0.12172\n",
      "[53]\teval-logloss:16.80483\ttrain-logloss:0.12172\n",
      "[54]\teval-logloss:16.96642\ttrain-logloss:0.12172\n",
      "[55]\teval-logloss:16.15849\ttrain-logloss:0.04057\n",
      "[56]\teval-logloss:17.28959\ttrain-logloss:0.04057\n",
      "[57]\teval-logloss:16.96642\ttrain-logloss:0.12172\n",
      "[58]\teval-logloss:17.45117\ttrain-logloss:0.08115\n",
      "[59]\teval-logloss:16.48166\ttrain-logloss:0.24344\n",
      "[60]\teval-logloss:17.28959\ttrain-logloss:0.04057\n",
      "[61]\teval-logloss:15.99691\ttrain-logloss:0.04057\n",
      "[62]\teval-logloss:16.80483\ttrain-logloss:0.00000\n",
      "[63]\teval-logloss:15.35057\ttrain-logloss:0.04057\n",
      "[64]\teval-logloss:17.12800\ttrain-logloss:0.04057\n",
      "[65]\teval-logloss:15.35057\ttrain-logloss:0.00000\n",
      "[66]\teval-logloss:17.12800\ttrain-logloss:0.00000\n",
      "[67]\teval-logloss:15.35057\ttrain-logloss:0.04057\n",
      "[68]\teval-logloss:16.96642\ttrain-logloss:0.00000\n",
      "[69]\teval-logloss:15.35057\ttrain-logloss:0.00000\n",
      "[70]\teval-logloss:16.96642\ttrain-logloss:0.00000\n",
      "[71]\teval-logloss:15.35057\ttrain-logloss:0.00000\n",
      "[72]\teval-logloss:16.96642\ttrain-logloss:0.00000\n",
      "[73]\teval-logloss:15.18898\ttrain-logloss:0.00000\n",
      "[74]\teval-logloss:16.96642\ttrain-logloss:0.00000\n",
      "[75]\teval-logloss:15.35057\ttrain-logloss:0.00000\n",
      "[76]\teval-logloss:16.96642\ttrain-logloss:0.00000\n",
      "[77]\teval-logloss:15.35057\ttrain-logloss:0.00000\n",
      "[78]\teval-logloss:16.96642\ttrain-logloss:0.00000\n",
      "[79]\teval-logloss:15.51215\ttrain-logloss:0.04057\n",
      "[80]\teval-logloss:16.96642\ttrain-logloss:0.00000\n",
      "[81]\teval-logloss:15.18898\ttrain-logloss:0.00000\n",
      "[82]\teval-logloss:16.96642\ttrain-logloss:0.00000\n",
      "[83]\teval-logloss:15.51215\ttrain-logloss:0.00000\n",
      "[84]\teval-logloss:16.96642\ttrain-logloss:0.00000\n",
      "[85]\teval-logloss:15.18898\ttrain-logloss:0.00000\n",
      "[86]\teval-logloss:16.96642\ttrain-logloss:0.00000\n",
      "[87]\teval-logloss:15.18898\ttrain-logloss:0.00000\n",
      "[88]\teval-logloss:16.96642\ttrain-logloss:0.00000\n",
      "[89]\teval-logloss:15.18898\ttrain-logloss:0.00000\n",
      "[90]\teval-logloss:16.96642\ttrain-logloss:0.00000\n",
      "[91]\teval-logloss:15.35057\ttrain-logloss:0.00000\n",
      "[92]\teval-logloss:16.80483\ttrain-logloss:0.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|██████████████████▉                                                                                                                                                                                                                                                                     | 4/59 [00:02<00:32,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-logloss:16.51509\ttrain-logloss:13.53761\n",
      "[1]\teval-logloss:15.56230\ttrain-logloss:12.58482\n",
      "[2]\teval-logloss:14.92710\ttrain-logloss:10.36163\n",
      "[3]\teval-logloss:16.03870\ttrain-logloss:8.41635\n",
      "[4]\teval-logloss:14.13311\ttrain-logloss:7.42385\n",
      "[5]\teval-logloss:14.29191\ttrain-logloss:6.82836\n",
      "[6]\teval-logloss:14.76830\ttrain-logloss:5.91526\n",
      "[7]\teval-logloss:15.40350\ttrain-logloss:5.12127\n",
      "[8]\teval-logloss:15.56230\ttrain-logloss:4.68457\n",
      "[9]\teval-logloss:15.24470\ttrain-logloss:4.48607\n",
      "[10]\teval-logloss:15.24470\ttrain-logloss:3.37448\n",
      "[11]\teval-logloss:14.76830\ttrain-logloss:3.49358\n",
      "[12]\teval-logloss:14.13311\ttrain-logloss:3.21568\n",
      "[13]\teval-logloss:14.60951\ttrain-logloss:2.65988\n",
      "[14]\teval-logloss:14.29191\ttrain-logloss:2.50108\n",
      "[15]\teval-logloss:14.13311\ttrain-logloss:1.78649\n",
      "[16]\teval-logloss:13.97431\ttrain-logloss:1.62769\n",
      "[17]\teval-logloss:15.08590\ttrain-logloss:1.42919\n",
      "[18]\teval-logloss:14.76830\ttrain-logloss:1.38949\n",
      "[19]\teval-logloss:14.92710\ttrain-logloss:1.19099\n",
      "[20]\teval-logloss:13.97431\ttrain-logloss:0.91309\n",
      "[21]\teval-logloss:14.29191\ttrain-logloss:0.59550\n",
      "[22]\teval-logloss:14.29191\ttrain-logloss:0.71459\n",
      "[23]\teval-logloss:13.81551\ttrain-logloss:0.59550\n",
      "[24]\teval-logloss:13.81551\ttrain-logloss:0.51610\n",
      "[25]\teval-logloss:13.33911\ttrain-logloss:0.55580\n",
      "[26]\teval-logloss:13.97431\ttrain-logloss:0.23820\n",
      "[27]\teval-logloss:14.13311\ttrain-logloss:0.35730\n",
      "[28]\teval-logloss:14.60951\ttrain-logloss:0.51610\n",
      "[29]\teval-logloss:13.97431\ttrain-logloss:0.35730\n",
      "[30]\teval-logloss:14.60951\ttrain-logloss:0.31760\n",
      "[31]\teval-logloss:13.02152\ttrain-logloss:0.31760\n",
      "[32]\teval-logloss:14.60951\ttrain-logloss:0.31760\n",
      "[33]\teval-logloss:13.97431\ttrain-logloss:0.11910\n",
      "[34]\teval-logloss:15.08590\ttrain-logloss:0.23820\n",
      "[35]\teval-logloss:13.81551\ttrain-logloss:0.03970\n",
      "[36]\teval-logloss:15.40350\ttrain-logloss:0.03970\n",
      "[37]\teval-logloss:14.45071\ttrain-logloss:0.15880\n",
      "[38]\teval-logloss:15.40350\ttrain-logloss:0.11910\n",
      "[39]\teval-logloss:14.76830\ttrain-logloss:0.03970\n",
      "[40]\teval-logloss:14.76830\ttrain-logloss:0.11910\n",
      "[41]\teval-logloss:14.13311\ttrain-logloss:0.03970\n",
      "[42]\teval-logloss:14.76830\ttrain-logloss:0.07940\n",
      "[43]\teval-logloss:14.60951\ttrain-logloss:0.03970\n",
      "[44]\teval-logloss:14.76830\ttrain-logloss:0.00000\n",
      "[45]\teval-logloss:14.29191\ttrain-logloss:0.03970\n",
      "[46]\teval-logloss:15.24470\ttrain-logloss:0.03970\n",
      "[47]\teval-logloss:14.13311\ttrain-logloss:0.00000\n",
      "[48]\teval-logloss:15.56230\ttrain-logloss:0.03970\n",
      "[49]\teval-logloss:14.29191\ttrain-logloss:0.00000\n",
      "[50]\teval-logloss:15.24470\ttrain-logloss:0.00000\n",
      "[51]\teval-logloss:14.76830\ttrain-logloss:0.00000\n",
      "[52]\teval-logloss:14.76830\ttrain-logloss:0.03970\n",
      "[53]\teval-logloss:14.60951\ttrain-logloss:0.00000\n",
      "[54]\teval-logloss:14.76830\ttrain-logloss:0.03970\n",
      "[55]\teval-logloss:14.76830\ttrain-logloss:0.07940\n",
      "[56]\teval-logloss:14.92710\ttrain-logloss:0.03970\n",
      "[57]\teval-logloss:14.76830\ttrain-logloss:0.07940\n",
      "[58]\teval-logloss:14.76830\ttrain-logloss:0.00000\n",
      "[59]\teval-logloss:14.92710\ttrain-logloss:0.00000\n",
      "[60]\teval-logloss:15.08590\ttrain-logloss:0.00000\n",
      "[61]\teval-logloss:15.24470\ttrain-logloss:0.07940\n",
      "[62]\teval-logloss:15.08590\ttrain-logloss:0.00000\n",
      "[63]\teval-logloss:15.08590\ttrain-logloss:0.00000\n",
      "[64]\teval-logloss:15.08590\ttrain-logloss:0.03970\n",
      "[65]\teval-logloss:14.92710\ttrain-logloss:0.00000\n",
      "[66]\teval-logloss:15.08590\ttrain-logloss:0.00000\n",
      "[67]\teval-logloss:15.24470\ttrain-logloss:0.00000\n",
      "[68]\teval-logloss:15.24470\ttrain-logloss:0.00000\n",
      "[69]\teval-logloss:14.92710\ttrain-logloss:0.00000\n",
      "[70]\teval-logloss:15.24470\ttrain-logloss:0.00000\n",
      "[71]\teval-logloss:14.92710\ttrain-logloss:0.00000\n",
      "[72]\teval-logloss:15.87990\ttrain-logloss:0.03970\n",
      "[73]\teval-logloss:14.76830\ttrain-logloss:0.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|███████████████████████▋                                                                                                                                                                                                                                                                | 5/59 [00:02<00:30,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-logloss:18.18751\ttrain-logloss:14.05891\n",
      "[1]\teval-logloss:14.45674\ttrain-logloss:10.74864\n",
      "[2]\teval-logloss:15.38943\ttrain-logloss:9.15192\n",
      "[3]\teval-logloss:15.38943\ttrain-logloss:7.74993\n",
      "[4]\teval-logloss:14.92308\ttrain-logloss:6.38687\n",
      "[5]\teval-logloss:15.23398\ttrain-logloss:6.11426\n",
      "[6]\teval-logloss:14.61219\ttrain-logloss:5.41327\n",
      "[7]\teval-logloss:14.61219\ttrain-logloss:4.75121\n",
      "[8]\teval-logloss:14.76763\ttrain-logloss:4.59543\n",
      "[9]\teval-logloss:15.54488\ttrain-logloss:3.50499\n",
      "[10]\teval-logloss:14.76763\ttrain-logloss:3.03766\n",
      "[11]\teval-logloss:15.54488\ttrain-logloss:2.53138\n",
      "[12]\teval-logloss:16.47757\ttrain-logloss:2.64822\n",
      "[13]\teval-logloss:17.25481\ttrain-logloss:2.29772\n",
      "[14]\teval-logloss:16.78847\ttrain-logloss:2.02511\n",
      "[15]\teval-logloss:17.41026\ttrain-logloss:1.51883\n",
      "[16]\teval-logloss:16.78847\ttrain-logloss:1.24622\n",
      "[17]\teval-logloss:16.47757\ttrain-logloss:1.40200\n",
      "[18]\teval-logloss:16.32212\ttrain-logloss:1.24622\n",
      "[19]\teval-logloss:16.78847\ttrain-logloss:1.36305\n",
      "[20]\teval-logloss:16.47757\ttrain-logloss:1.01255\n",
      "[21]\teval-logloss:16.78847\ttrain-logloss:1.09044\n",
      "[22]\teval-logloss:16.16667\ttrain-logloss:0.89572\n",
      "[23]\teval-logloss:16.78847\ttrain-logloss:0.81783\n",
      "[24]\teval-logloss:16.32212\ttrain-logloss:0.81783\n",
      "[25]\teval-logloss:15.85578\ttrain-logloss:0.70100\n",
      "[26]\teval-logloss:16.63302\ttrain-logloss:0.66205\n",
      "[27]\teval-logloss:15.38943\ttrain-logloss:0.66205\n",
      "[28]\teval-logloss:15.23398\ttrain-logloss:0.89572\n",
      "[29]\teval-logloss:16.16667\ttrain-logloss:0.62311\n",
      "[30]\teval-logloss:15.38943\ttrain-logloss:0.42839\n",
      "[31]\teval-logloss:16.01122\ttrain-logloss:0.50628\n",
      "[32]\teval-logloss:15.38943\ttrain-logloss:0.50628\n",
      "[33]\teval-logloss:13.99039\ttrain-logloss:0.23367\n",
      "[34]\teval-logloss:15.54488\ttrain-logloss:0.27261\n",
      "[35]\teval-logloss:15.07853\ttrain-logloss:0.19472\n",
      "[36]\teval-logloss:15.54488\ttrain-logloss:0.23367\n",
      "[37]\teval-logloss:15.54488\ttrain-logloss:0.11683\n",
      "[38]\teval-logloss:14.92308\ttrain-logloss:0.27261\n",
      "[39]\teval-logloss:14.92308\ttrain-logloss:0.27261\n",
      "[40]\teval-logloss:15.70033\ttrain-logloss:0.23367\n",
      "[41]\teval-logloss:16.16667\ttrain-logloss:0.19472\n",
      "[42]\teval-logloss:17.09937\ttrain-logloss:0.19472\n",
      "[43]\teval-logloss:16.63302\ttrain-logloss:0.15578\n",
      "[44]\teval-logloss:16.01122\ttrain-logloss:0.19472\n",
      "[45]\teval-logloss:17.25481\ttrain-logloss:0.35050\n",
      "[46]\teval-logloss:16.78847\ttrain-logloss:0.19472\n",
      "[47]\teval-logloss:15.23398\ttrain-logloss:0.27261\n",
      "[48]\teval-logloss:16.63302\ttrain-logloss:0.19472\n",
      "[49]\teval-logloss:16.01122\ttrain-logloss:0.23367\n",
      "[50]\teval-logloss:18.03206\ttrain-logloss:0.15578\n",
      "[51]\teval-logloss:17.09937\ttrain-logloss:0.11683\n",
      "[52]\teval-logloss:16.94392\ttrain-logloss:0.15578\n",
      "[53]\teval-logloss:16.32212\ttrain-logloss:0.11683\n",
      "[54]\teval-logloss:16.78847\ttrain-logloss:0.07789\n",
      "[55]\teval-logloss:16.63302\ttrain-logloss:0.07789\n",
      "[56]\teval-logloss:16.94392\ttrain-logloss:0.03894\n",
      "[57]\teval-logloss:16.47757\ttrain-logloss:0.11683\n",
      "[58]\teval-logloss:16.63302\ttrain-logloss:0.11683\n",
      "[59]\teval-logloss:16.94392\ttrain-logloss:0.07789\n",
      "[60]\teval-logloss:16.63302\ttrain-logloss:0.03894\n",
      "[61]\teval-logloss:16.32212\ttrain-logloss:0.00000\n",
      "[62]\teval-logloss:17.41026\ttrain-logloss:0.00000\n",
      "[63]\teval-logloss:16.32212\ttrain-logloss:0.00000\n",
      "[64]\teval-logloss:17.09937\ttrain-logloss:0.00000\n",
      "[65]\teval-logloss:16.47757\ttrain-logloss:0.03894\n",
      "[66]\teval-logloss:17.41026\ttrain-logloss:0.03894\n",
      "[67]\teval-logloss:16.63302\ttrain-logloss:0.00000\n",
      "[68]\teval-logloss:17.09937\ttrain-logloss:0.07789\n",
      "[69]\teval-logloss:16.78847\ttrain-logloss:0.00000\n",
      "[70]\teval-logloss:17.09937\ttrain-logloss:0.00000\n",
      "[71]\teval-logloss:16.78847\ttrain-logloss:0.03894\n",
      "[72]\teval-logloss:17.25481\ttrain-logloss:0.00000\n",
      "[73]\teval-logloss:16.94392\ttrain-logloss:0.00000\n",
      "[74]\teval-logloss:17.25481\ttrain-logloss:0.00000\n",
      "[75]\teval-logloss:16.94392\ttrain-logloss:0.00000\n",
      "[76]\teval-logloss:17.25481\ttrain-logloss:0.03894\n",
      "[77]\teval-logloss:16.94392\ttrain-logloss:0.03894\n",
      "[78]\teval-logloss:16.94392\ttrain-logloss:0.00000\n",
      "[79]\teval-logloss:17.09937\ttrain-logloss:0.03894\n",
      "[80]\teval-logloss:16.94392\ttrain-logloss:0.07789\n",
      "[81]\teval-logloss:17.09937\ttrain-logloss:0.07789\n",
      "[82]\teval-logloss:16.94392\ttrain-logloss:0.03894\n",
      "[83]\teval-logloss:16.94392\ttrain-logloss:0.00000\n",
      "[84]\teval-logloss:17.41026\ttrain-logloss:0.00000\n",
      "[85]\teval-logloss:16.78847\ttrain-logloss:0.00000\n",
      "[86]\teval-logloss:17.25481\ttrain-logloss:0.00000\n",
      "[87]\teval-logloss:16.01122\ttrain-logloss:0.07789\n",
      "[88]\teval-logloss:17.56571\ttrain-logloss:0.07789\n",
      "[89]\teval-logloss:16.32212\ttrain-logloss:0.11683\n",
      "[90]\teval-logloss:17.72116\ttrain-logloss:0.11683\n",
      "[91]\teval-logloss:16.47757\ttrain-logloss:0.11683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|████████████████████████████▍                                                                                                                                                                                                                                                           | 6/59 [00:03<00:30,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-logloss:19.02963\ttrain-logloss:11.57981\n",
      "[1]\teval-logloss:18.26844\ttrain-logloss:10.05112\n",
      "[2]\teval-logloss:18.42068\ttrain-logloss:8.71352\n",
      "[3]\teval-logloss:17.50726\ttrain-logloss:7.68165\n",
      "[4]\teval-logloss:17.65950\ttrain-logloss:6.61157\n",
      "[5]\teval-logloss:16.89831\ttrain-logloss:5.96188\n",
      "[6]\teval-logloss:17.05055\ttrain-logloss:5.84723\n",
      "[7]\teval-logloss:17.05055\ttrain-logloss:5.57971\n",
      "[8]\teval-logloss:17.50726\ttrain-logloss:5.15932\n",
      "[9]\teval-logloss:17.20278\ttrain-logloss:4.70071\n",
      "[10]\teval-logloss:15.68041\ttrain-logloss:4.28032\n",
      "[11]\teval-logloss:17.65950\ttrain-logloss:3.43955\n",
      "[12]\teval-logloss:16.74607\ttrain-logloss:3.17203\n",
      "[13]\teval-logloss:16.59384\ttrain-logloss:3.01916\n",
      "[14]\teval-logloss:17.20278\ttrain-logloss:2.59877\n",
      "[15]\teval-logloss:16.59384\ttrain-logloss:2.25481\n",
      "[16]\teval-logloss:17.35502\ttrain-logloss:1.98729\n",
      "[17]\teval-logloss:17.05055\ttrain-logloss:1.68156\n",
      "[18]\teval-logloss:16.59384\ttrain-logloss:1.71977\n",
      "[19]\teval-logloss:16.74607\ttrain-logloss:1.33760\n",
      "[20]\teval-logloss:16.74607\ttrain-logloss:1.33760\n",
      "[21]\teval-logloss:16.74607\ttrain-logloss:1.41404\n",
      "[22]\teval-logloss:16.44160\ttrain-logloss:1.14651\n",
      "[23]\teval-logloss:15.98489\ttrain-logloss:0.95543\n",
      "[24]\teval-logloss:15.68041\ttrain-logloss:0.80256\n",
      "[25]\teval-logloss:15.37594\ttrain-logloss:0.76434\n",
      "[26]\teval-logloss:15.37594\ttrain-logloss:0.91721\n",
      "[27]\teval-logloss:16.13713\ttrain-logloss:0.76434\n",
      "[28]\teval-logloss:15.07147\ttrain-logloss:0.57326\n",
      "[29]\teval-logloss:15.52818\ttrain-logloss:0.38217\n",
      "[30]\teval-logloss:14.91923\ttrain-logloss:0.30574\n",
      "[31]\teval-logloss:15.07147\ttrain-logloss:0.45861\n",
      "[32]\teval-logloss:14.46252\ttrain-logloss:0.49682\n",
      "[33]\teval-logloss:15.98489\ttrain-logloss:0.26752\n",
      "[34]\teval-logloss:15.52818\ttrain-logloss:0.22930\n",
      "[35]\teval-logloss:15.68041\ttrain-logloss:0.30574\n",
      "[36]\teval-logloss:16.13713\ttrain-logloss:0.38217\n",
      "[37]\teval-logloss:16.13713\ttrain-logloss:0.34396\n",
      "[38]\teval-logloss:15.52818\ttrain-logloss:0.38217\n",
      "[39]\teval-logloss:15.52818\ttrain-logloss:0.22930\n",
      "[40]\teval-logloss:15.22370\ttrain-logloss:0.34396\n",
      "[41]\teval-logloss:14.61476\ttrain-logloss:0.15287\n",
      "[42]\teval-logloss:15.83265\ttrain-logloss:0.15287\n",
      "[43]\teval-logloss:15.83265\ttrain-logloss:0.07643\n",
      "[44]\teval-logloss:16.44160\ttrain-logloss:0.30574\n",
      "[45]\teval-logloss:16.13713\ttrain-logloss:0.03822\n",
      "[46]\teval-logloss:16.44160\ttrain-logloss:0.07643\n",
      "[47]\teval-logloss:16.44160\ttrain-logloss:0.07643\n",
      "[48]\teval-logloss:16.89831\ttrain-logloss:0.11465\n",
      "[49]\teval-logloss:16.74607\ttrain-logloss:0.07643\n",
      "[50]\teval-logloss:17.81173\ttrain-logloss:0.11465\n",
      "[51]\teval-logloss:16.89831\ttrain-logloss:0.19109\n",
      "[52]\teval-logloss:17.65950\ttrain-logloss:0.15287\n",
      "[53]\teval-logloss:16.59384\ttrain-logloss:0.22930\n",
      "[54]\teval-logloss:17.96397\ttrain-logloss:0.15287\n",
      "[55]\teval-logloss:17.20278\ttrain-logloss:0.15287\n",
      "[56]\teval-logloss:17.05055\ttrain-logloss:0.11465\n",
      "[57]\teval-logloss:16.74607\ttrain-logloss:0.15287\n",
      "[58]\teval-logloss:16.74607\ttrain-logloss:0.03822\n",
      "[59]\teval-logloss:17.05055\ttrain-logloss:0.15287\n",
      "[60]\teval-logloss:16.44160\ttrain-logloss:0.03822\n",
      "[61]\teval-logloss:16.89831\ttrain-logloss:0.15287\n",
      "[62]\teval-logloss:16.89831\ttrain-logloss:0.00000\n",
      "[63]\teval-logloss:17.50726\ttrain-logloss:0.07643\n",
      "[64]\teval-logloss:16.44160\ttrain-logloss:0.00000\n",
      "[65]\teval-logloss:16.28936\ttrain-logloss:0.03822\n",
      "[66]\teval-logloss:16.59384\ttrain-logloss:0.03822\n",
      "[67]\teval-logloss:16.44160\ttrain-logloss:0.03822\n",
      "[68]\teval-logloss:17.05055\ttrain-logloss:0.00000\n",
      "[69]\teval-logloss:17.35502\ttrain-logloss:0.11465\n",
      "[70]\teval-logloss:16.59384\ttrain-logloss:0.00000\n",
      "[71]\teval-logloss:17.05055\ttrain-logloss:0.07643\n",
      "[72]\teval-logloss:16.59384\ttrain-logloss:0.00000\n",
      "[73]\teval-logloss:16.89831\ttrain-logloss:0.03822\n",
      "[74]\teval-logloss:16.59384\ttrain-logloss:0.00000\n",
      "[75]\teval-logloss:16.89831\ttrain-logloss:0.00000\n",
      "[76]\teval-logloss:16.59384\ttrain-logloss:0.03822\n",
      "[77]\teval-logloss:17.20278\ttrain-logloss:0.00000\n",
      "[78]\teval-logloss:16.74607\ttrain-logloss:0.11465\n",
      "[79]\teval-logloss:17.05055\ttrain-logloss:0.00000\n",
      "[80]\teval-logloss:16.59384\ttrain-logloss:0.07643\n",
      "[81]\teval-logloss:16.89831\ttrain-logloss:0.07643\n",
      "[82]\teval-logloss:16.59384\ttrain-logloss:0.03822\n",
      "[83]\teval-logloss:17.05055\ttrain-logloss:0.07643\n",
      "[84]\teval-logloss:16.44160\ttrain-logloss:0.00000\n",
      "[85]\teval-logloss:16.89831\ttrain-logloss:0.03822\n",
      "[86]\teval-logloss:16.44160\ttrain-logloss:0.03822\n",
      "[87]\teval-logloss:17.35502\ttrain-logloss:0.11465\n",
      "[88]\teval-logloss:16.89831\ttrain-logloss:0.03822\n",
      "[89]\teval-logloss:17.05055\ttrain-logloss:0.07643\n",
      "[90]\teval-logloss:17.05055\ttrain-logloss:0.03822\n",
      "[91]\teval-logloss:16.74607\ttrain-logloss:0.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█████████████████████████████████▏                                                                                                                                                                                                                                                      | 7/59 [00:04<00:30,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-logloss:16.17426\ttrain-logloss:13.49226\n",
      "[1]\teval-logloss:16.17426\ttrain-logloss:11.65581\n",
      "[2]\teval-logloss:14.82640\ttrain-logloss:10.38154\n",
      "[3]\teval-logloss:15.57521\ttrain-logloss:8.28275\n",
      "[4]\teval-logloss:14.67664\ttrain-logloss:7.49570\n",
      "[5]\teval-logloss:15.42545\ttrain-logloss:6.78361\n",
      "[6]\teval-logloss:15.72497\ttrain-logloss:5.47186\n",
      "[7]\teval-logloss:16.17426\ttrain-logloss:4.94716\n",
      "[8]\teval-logloss:16.02449\ttrain-logloss:4.57238\n",
      "[9]\teval-logloss:15.87473\ttrain-logloss:4.45994\n",
      "[10]\teval-logloss:15.57521\ttrain-logloss:3.48550\n",
      "[11]\teval-logloss:14.82640\ttrain-logloss:3.22315\n",
      "[12]\teval-logloss:16.02449\ttrain-logloss:2.62350\n",
      "[13]\teval-logloss:14.82640\ttrain-logloss:2.21123\n",
      "[14]\teval-logloss:14.82640\ttrain-logloss:2.17375\n",
      "[15]\teval-logloss:14.67664\ttrain-logloss:1.94888\n",
      "[16]\teval-logloss:13.92783\ttrain-logloss:1.64905\n",
      "[17]\teval-logloss:14.07759\ttrain-logloss:1.57410\n",
      "[18]\teval-logloss:14.37712\ttrain-logloss:1.49914\n",
      "[19]\teval-logloss:13.77807\ttrain-logloss:1.23679\n",
      "[20]\teval-logloss:14.22735\ttrain-logloss:1.12435\n",
      "[21]\teval-logloss:14.07759\ttrain-logloss:0.86201\n",
      "[22]\teval-logloss:13.77807\ttrain-logloss:1.08688\n",
      "[23]\teval-logloss:14.37712\ttrain-logloss:0.67461\n",
      "[24]\teval-logloss:15.27569\ttrain-logloss:0.63713\n",
      "[25]\teval-logloss:14.67664\ttrain-logloss:0.52470\n",
      "[26]\teval-logloss:13.92783\ttrain-logloss:0.44974\n",
      "[27]\teval-logloss:15.27569\ttrain-logloss:0.44974\n",
      "[28]\teval-logloss:13.77807\ttrain-logloss:0.37478\n",
      "[29]\teval-logloss:14.97616\ttrain-logloss:0.26235\n",
      "[30]\teval-logloss:15.27569\ttrain-logloss:0.41226\n",
      "[31]\teval-logloss:14.67664\ttrain-logloss:0.41226\n",
      "[32]\teval-logloss:14.67664\ttrain-logloss:0.22487\n",
      "[33]\teval-logloss:14.97616\ttrain-logloss:0.26235\n",
      "[34]\teval-logloss:14.97616\ttrain-logloss:0.26235\n",
      "[35]\teval-logloss:14.37712\ttrain-logloss:0.22487\n",
      "[36]\teval-logloss:15.27569\ttrain-logloss:0.14991\n",
      "[37]\teval-logloss:15.42545\ttrain-logloss:0.29983\n",
      "[38]\teval-logloss:15.57521\ttrain-logloss:0.18739\n",
      "[39]\teval-logloss:15.57521\ttrain-logloss:0.26235\n",
      "[40]\teval-logloss:16.32402\ttrain-logloss:0.26235\n",
      "[41]\teval-logloss:15.57521\ttrain-logloss:0.18739\n",
      "[42]\teval-logloss:16.17426\ttrain-logloss:0.14991\n",
      "[43]\teval-logloss:14.67664\ttrain-logloss:0.22487\n",
      "[44]\teval-logloss:15.87473\ttrain-logloss:0.26235\n",
      "[45]\teval-logloss:14.37712\ttrain-logloss:0.26235\n",
      "[46]\teval-logloss:14.97616\ttrain-logloss:0.22487\n",
      "[47]\teval-logloss:15.57521\ttrain-logloss:0.22487\n",
      "[48]\teval-logloss:14.22735\ttrain-logloss:0.26235\n",
      "[49]\teval-logloss:14.22735\ttrain-logloss:0.26235\n",
      "[50]\teval-logloss:14.07759\ttrain-logloss:0.22487\n",
      "[51]\teval-logloss:14.22735\ttrain-logloss:0.26235\n",
      "[52]\teval-logloss:13.77807\ttrain-logloss:0.18739\n",
      "[53]\teval-logloss:14.07759\ttrain-logloss:0.18739\n",
      "[54]\teval-logloss:14.52688\ttrain-logloss:0.37478\n",
      "[55]\teval-logloss:14.82640\ttrain-logloss:0.41226\n",
      "[56]\teval-logloss:14.52688\ttrain-logloss:0.18739\n",
      "[57]\teval-logloss:15.87473\ttrain-logloss:0.41226\n",
      "[58]\teval-logloss:14.97616\ttrain-logloss:0.18739\n",
      "[59]\teval-logloss:15.72497\ttrain-logloss:0.26235\n",
      "[60]\teval-logloss:15.72497\ttrain-logloss:0.07496\n",
      "[61]\teval-logloss:15.87473\ttrain-logloss:0.26235\n",
      "[62]\teval-logloss:15.72497\ttrain-logloss:0.00000\n",
      "[63]\teval-logloss:15.72497\ttrain-logloss:0.07496\n",
      "[64]\teval-logloss:16.17426\ttrain-logloss:0.03748\n",
      "[65]\teval-logloss:16.02449\ttrain-logloss:0.03748\n",
      "[66]\teval-logloss:16.02449\ttrain-logloss:0.11243\n",
      "[67]\teval-logloss:16.62354\ttrain-logloss:0.11243\n",
      "[68]\teval-logloss:15.57521\ttrain-logloss:0.11243\n",
      "[69]\teval-logloss:15.87473\ttrain-logloss:0.07496\n",
      "[70]\teval-logloss:15.72497\ttrain-logloss:0.14991\n",
      "[71]\teval-logloss:16.02449\ttrain-logloss:0.22487\n",
      "[72]\teval-logloss:15.87473\ttrain-logloss:0.26235\n",
      "[73]\teval-logloss:16.32402\ttrain-logloss:0.29983\n",
      "[74]\teval-logloss:16.92306\ttrain-logloss:0.14991\n",
      "[75]\teval-logloss:17.07282\ttrain-logloss:0.14991\n",
      "[76]\teval-logloss:16.32402\ttrain-logloss:0.11243\n",
      "[77]\teval-logloss:17.37235\ttrain-logloss:0.22487\n",
      "[78]\teval-logloss:16.92306\ttrain-logloss:0.37478\n",
      "[79]\teval-logloss:17.07282\ttrain-logloss:0.11243\n",
      "[80]\teval-logloss:16.92306\ttrain-logloss:0.03748\n",
      "[81]\teval-logloss:16.62354\ttrain-logloss:0.07496\n",
      "[82]\teval-logloss:16.92306\ttrain-logloss:0.07496\n",
      "[83]\teval-logloss:16.47378\ttrain-logloss:0.03748\n",
      "[84]\teval-logloss:16.17426\ttrain-logloss:0.07496\n",
      "[85]\teval-logloss:16.92306\ttrain-logloss:0.18739\n",
      "[86]\teval-logloss:16.47378\ttrain-logloss:0.03748\n",
      "[87]\teval-logloss:16.77330\ttrain-logloss:0.07496\n",
      "[88]\teval-logloss:16.47378\ttrain-logloss:0.11243\n",
      "[89]\teval-logloss:16.92306\ttrain-logloss:0.00000\n",
      "[90]\teval-logloss:16.47378\ttrain-logloss:0.11243\n",
      "[91]\teval-logloss:16.62354\ttrain-logloss:0.00000\n",
      "[92]\teval-logloss:16.62354\ttrain-logloss:0.03748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█████████████████████████████████████▉                                                                                                                                                                                                                                                  | 8/59 [00:04<00:30,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-logloss:19.37474\ttrain-logloss:14.39058\n",
      "[1]\teval-logloss:17.61340\ttrain-logloss:10.96776\n",
      "[2]\teval-logloss:16.58595\ttrain-logloss:9.79001\n",
      "[3]\teval-logloss:16.14562\ttrain-logloss:8.02339\n",
      "[4]\teval-logloss:15.55850\ttrain-logloss:7.32411\n",
      "[5]\teval-logloss:15.55850\ttrain-logloss:5.96234\n",
      "[6]\teval-logloss:16.43917\ttrain-logloss:5.33666\n",
      "[7]\teval-logloss:15.99884\ttrain-logloss:4.93181\n",
      "[8]\teval-logloss:16.58595\ttrain-logloss:4.19572\n",
      "[9]\teval-logloss:16.87951\ttrain-logloss:4.01170\n",
      "[10]\teval-logloss:16.58595\ttrain-logloss:3.57004\n",
      "[11]\teval-logloss:17.46662\ttrain-logloss:3.27561\n",
      "[12]\teval-logloss:16.29239\ttrain-logloss:2.50271\n",
      "[13]\teval-logloss:16.58595\ttrain-logloss:2.64993\n",
      "[14]\teval-logloss:17.02629\ttrain-logloss:2.64993\n",
      "[15]\teval-logloss:16.73273\ttrain-logloss:2.17147\n",
      "[16]\teval-logloss:16.87951\ttrain-logloss:1.76662\n",
      "[17]\teval-logloss:17.02629\ttrain-logloss:1.98745\n",
      "[18]\teval-logloss:16.58595\ttrain-logloss:1.87703\n",
      "[19]\teval-logloss:15.85206\ttrain-logloss:1.58260\n",
      "[20]\teval-logloss:16.58595\ttrain-logloss:1.17775\n",
      "[21]\teval-logloss:16.43917\ttrain-logloss:1.25135\n",
      "[22]\teval-logloss:16.43917\ttrain-logloss:1.14094\n",
      "[23]\teval-logloss:16.29239\ttrain-logloss:0.77290\n",
      "[24]\teval-logloss:16.73273\ttrain-logloss:1.03053\n",
      "[25]\teval-logloss:16.73273\ttrain-logloss:0.77290\n",
      "[26]\teval-logloss:16.73273\ttrain-logloss:0.84650\n",
      "[27]\teval-logloss:16.43917\ttrain-logloss:0.69929\n",
      "[28]\teval-logloss:17.02629\ttrain-logloss:0.40485\n",
      "[29]\teval-logloss:16.43917\ttrain-logloss:0.55207\n",
      "[30]\teval-logloss:17.17307\ttrain-logloss:0.40485\n",
      "[31]\teval-logloss:16.43917\ttrain-logloss:0.66248\n",
      "[32]\teval-logloss:15.99884\ttrain-logloss:0.58887\n",
      "[33]\teval-logloss:15.70528\ttrain-logloss:0.58887\n",
      "[34]\teval-logloss:15.99884\ttrain-logloss:0.66248\n",
      "[35]\teval-logloss:16.14562\ttrain-logloss:0.51526\n",
      "[36]\teval-logloss:15.70528\ttrain-logloss:0.29444\n",
      "[37]\teval-logloss:16.58595\ttrain-logloss:0.44166\n",
      "[38]\teval-logloss:16.87951\ttrain-logloss:0.36805\n",
      "[39]\teval-logloss:16.43917\ttrain-logloss:0.22083\n",
      "[40]\teval-logloss:15.99884\ttrain-logloss:0.29444\n",
      "[41]\teval-logloss:17.17307\ttrain-logloss:0.33124\n",
      "[42]\teval-logloss:16.29239\ttrain-logloss:0.22083\n",
      "[43]\teval-logloss:16.87951\ttrain-logloss:0.36805\n",
      "[44]\teval-logloss:16.14562\ttrain-logloss:0.36805\n",
      "[45]\teval-logloss:17.61340\ttrain-logloss:0.29444\n",
      "[46]\teval-logloss:16.73273\ttrain-logloss:0.33124\n",
      "[47]\teval-logloss:17.76018\ttrain-logloss:0.25763\n",
      "[48]\teval-logloss:17.02629\ttrain-logloss:0.25763\n",
      "[49]\teval-logloss:17.61340\ttrain-logloss:0.18402\n",
      "[50]\teval-logloss:16.73273\ttrain-logloss:0.11041\n",
      "[51]\teval-logloss:17.31984\ttrain-logloss:0.07361\n",
      "[52]\teval-logloss:16.87951\ttrain-logloss:0.00000\n",
      "[53]\teval-logloss:17.76018\ttrain-logloss:0.00000\n",
      "[54]\teval-logloss:16.43917\ttrain-logloss:0.03680\n",
      "[55]\teval-logloss:17.31984\ttrain-logloss:0.00000\n",
      "[56]\teval-logloss:16.87951\ttrain-logloss:0.03680\n",
      "[57]\teval-logloss:17.76018\ttrain-logloss:0.07361\n",
      "[58]\teval-logloss:17.17307\ttrain-logloss:0.07361\n",
      "[59]\teval-logloss:17.76018\ttrain-logloss:0.03680\n",
      "[60]\teval-logloss:17.31984\ttrain-logloss:0.03680\n",
      "[61]\teval-logloss:17.76018\ttrain-logloss:0.00000\n",
      "[62]\teval-logloss:17.02629\ttrain-logloss:0.00000\n",
      "[63]\teval-logloss:17.02629\ttrain-logloss:0.07361\n",
      "[64]\teval-logloss:16.58595\ttrain-logloss:0.00000\n",
      "[65]\teval-logloss:17.46662\ttrain-logloss:0.00000\n",
      "[66]\teval-logloss:17.02629\ttrain-logloss:0.03680\n",
      "[67]\teval-logloss:17.46662\ttrain-logloss:0.03680\n",
      "[68]\teval-logloss:16.73273\ttrain-logloss:0.07361\n",
      "[69]\teval-logloss:17.76018\ttrain-logloss:0.07361\n",
      "[70]\teval-logloss:16.87951\ttrain-logloss:0.00000\n",
      "[71]\teval-logloss:17.31984\ttrain-logloss:0.00000\n",
      "[72]\teval-logloss:16.87951\ttrain-logloss:0.00000\n",
      "[73]\teval-logloss:17.17307\ttrain-logloss:0.00000\n",
      "[74]\teval-logloss:16.87951\ttrain-logloss:0.00000\n",
      "[75]\teval-logloss:17.31984\ttrain-logloss:0.00000\n",
      "[76]\teval-logloss:16.87951\ttrain-logloss:0.00000\n",
      "[77]\teval-logloss:17.17307\ttrain-logloss:0.00000\n",
      "[78]\teval-logloss:16.87951\ttrain-logloss:0.00000\n",
      "[79]\teval-logloss:17.31984\ttrain-logloss:0.00000\n",
      "[80]\teval-logloss:17.17307\ttrain-logloss:0.00000\n",
      "[81]\teval-logloss:17.31984\ttrain-logloss:0.00000\n",
      "[82]\teval-logloss:16.87951\ttrain-logloss:0.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|██████████████████████████████████████████▋                                                                                                                                                                                                                                             | 9/59 [00:05<00:29,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-logloss:17.98895\ttrain-logloss:13.83357\n",
      "[1]\teval-logloss:16.83765\ttrain-logloss:10.43839\n",
      "[2]\teval-logloss:16.26201\ttrain-logloss:9.39094\n",
      "[3]\teval-logloss:15.97418\ttrain-logloss:8.34348\n",
      "[4]\teval-logloss:17.12548\ttrain-logloss:7.04320\n",
      "[5]\teval-logloss:17.26939\ttrain-logloss:6.71813\n",
      "[6]\teval-logloss:17.26939\ttrain-logloss:5.52621\n",
      "[7]\teval-logloss:16.26201\ttrain-logloss:5.34561\n",
      "[8]\teval-logloss:17.12548\ttrain-logloss:4.55099\n",
      "[9]\teval-logloss:17.84504\ttrain-logloss:4.55099\n",
      "[10]\teval-logloss:18.42068\ttrain-logloss:4.22592\n",
      "[11]\teval-logloss:16.83765\ttrain-logloss:3.57578\n",
      "[12]\teval-logloss:17.98895\ttrain-logloss:3.25071\n",
      "[13]\teval-logloss:17.26939\ttrain-logloss:2.52833\n",
      "[14]\teval-logloss:16.40592\ttrain-logloss:2.13102\n",
      "[15]\teval-logloss:16.83765\ttrain-logloss:1.84207\n",
      "[16]\teval-logloss:18.27677\ttrain-logloss:2.02266\n",
      "[17]\teval-logloss:17.55721\ttrain-logloss:1.51700\n",
      "[18]\teval-logloss:18.13286\ttrain-logloss:1.37252\n",
      "[19]\teval-logloss:17.26939\ttrain-logloss:1.15581\n",
      "[20]\teval-logloss:19.42806\ttrain-logloss:1.30028\n",
      "[21]\teval-logloss:17.98895\ttrain-logloss:1.30028\n",
      "[22]\teval-logloss:17.84504\ttrain-logloss:1.11969\n",
      "[23]\teval-logloss:16.69374\ttrain-logloss:0.83074\n",
      "[24]\teval-logloss:17.12548\ttrain-logloss:0.72238\n",
      "[25]\teval-logloss:16.69374\ttrain-logloss:0.83074\n",
      "[26]\teval-logloss:17.70112\ttrain-logloss:0.68626\n",
      "[27]\teval-logloss:17.41330\ttrain-logloss:0.61402\n",
      "[28]\teval-logloss:17.70112\ttrain-logloss:0.68626\n",
      "[29]\teval-logloss:17.70112\ttrain-logloss:0.57790\n",
      "[30]\teval-logloss:16.98156\ttrain-logloss:0.57790\n",
      "[31]\teval-logloss:17.12548\ttrain-logloss:0.61402\n",
      "[32]\teval-logloss:17.41330\ttrain-logloss:0.50567\n",
      "[33]\teval-logloss:18.56459\ttrain-logloss:0.54178\n",
      "[34]\teval-logloss:17.70112\ttrain-logloss:0.61402\n",
      "[35]\teval-logloss:17.41330\ttrain-logloss:0.50567\n",
      "[36]\teval-logloss:16.83765\ttrain-logloss:0.21671\n",
      "[37]\teval-logloss:17.41330\ttrain-logloss:0.36119\n",
      "[38]\teval-logloss:17.41330\ttrain-logloss:0.32507\n",
      "[39]\teval-logloss:17.26939\ttrain-logloss:0.18060\n",
      "[40]\teval-logloss:17.70112\ttrain-logloss:0.21671\n",
      "[41]\teval-logloss:17.70112\ttrain-logloss:0.28895\n",
      "[42]\teval-logloss:17.98895\ttrain-logloss:0.14448\n",
      "[43]\teval-logloss:17.98895\ttrain-logloss:0.14448\n",
      "[44]\teval-logloss:17.55721\ttrain-logloss:0.03612\n",
      "[45]\teval-logloss:17.41330\ttrain-logloss:0.32507\n",
      "[46]\teval-logloss:17.98895\ttrain-logloss:0.00000\n",
      "[47]\teval-logloss:17.98895\ttrain-logloss:0.28895\n",
      "[48]\teval-logloss:18.13286\ttrain-logloss:0.10836\n",
      "[49]\teval-logloss:17.55721\ttrain-logloss:0.18060\n",
      "[50]\teval-logloss:18.56459\ttrain-logloss:0.07224\n",
      "[51]\teval-logloss:17.84504\ttrain-logloss:0.14448\n",
      "[52]\teval-logloss:18.13286\ttrain-logloss:0.03612\n",
      "[53]\teval-logloss:17.41330\ttrain-logloss:0.10836\n",
      "[54]\teval-logloss:17.55721\ttrain-logloss:0.14448\n",
      "[55]\teval-logloss:17.12548\ttrain-logloss:0.10836\n",
      "[56]\teval-logloss:17.84504\ttrain-logloss:0.03612\n",
      "[57]\teval-logloss:16.98156\ttrain-logloss:0.14448\n",
      "[58]\teval-logloss:17.55721\ttrain-logloss:0.07224\n",
      "[59]\teval-logloss:17.41330\ttrain-logloss:0.10836\n",
      "[60]\teval-logloss:19.14024\ttrain-logloss:0.07224\n",
      "[61]\teval-logloss:18.56459\ttrain-logloss:0.10836\n",
      "[62]\teval-logloss:18.85242\ttrain-logloss:0.14448\n",
      "[63]\teval-logloss:18.27677\ttrain-logloss:0.10836\n",
      "[64]\teval-logloss:18.99633\ttrain-logloss:0.07224\n",
      "[65]\teval-logloss:17.98895\ttrain-logloss:0.07224\n",
      "[66]\teval-logloss:18.70850\ttrain-logloss:0.18060\n",
      "[67]\teval-logloss:19.28415\ttrain-logloss:0.18060\n",
      "[68]\teval-logloss:18.85242\ttrain-logloss:0.07224\n",
      "[69]\teval-logloss:19.28415\ttrain-logloss:0.07224\n",
      "[70]\teval-logloss:18.85242\ttrain-logloss:0.25283\n",
      "[71]\teval-logloss:18.85242\ttrain-logloss:0.18060\n",
      "[72]\teval-logloss:19.14024\ttrain-logloss:0.10836\n",
      "[73]\teval-logloss:18.85242\ttrain-logloss:0.03612\n",
      "[74]\teval-logloss:17.98895\ttrain-logloss:0.21671\n",
      "[75]\teval-logloss:19.14024\ttrain-logloss:0.03612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|███████████████████████████████████████████████▎                                                                                                                                                                                                                                       | 10/59 [00:05<00:28,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-logloss:16.29522\ttrain-logloss:13.33239\n",
      "[1]\teval-logloss:15.01994\ttrain-logloss:10.74392\n",
      "[2]\teval-logloss:13.74466\ttrain-logloss:9.68017\n",
      "[3]\teval-logloss:13.17787\ttrain-logloss:7.97816\n",
      "[4]\teval-logloss:13.88636\ttrain-logloss:7.16261\n",
      "[5]\teval-logloss:13.88636\ttrain-logloss:6.27615\n",
      "[6]\teval-logloss:13.88636\ttrain-logloss:5.42515\n",
      "[7]\teval-logloss:14.16976\ttrain-logloss:5.31877\n",
      "[8]\teval-logloss:14.16976\ttrain-logloss:4.68052\n",
      "[9]\teval-logloss:14.02806\ttrain-logloss:4.21956\n",
      "[10]\teval-logloss:13.31957\ttrain-logloss:3.79406\n",
      "[11]\teval-logloss:14.02806\ttrain-logloss:3.43947\n",
      "[12]\teval-logloss:14.02806\ttrain-logloss:3.15580\n",
      "[13]\teval-logloss:14.02806\ttrain-logloss:3.08489\n",
      "[14]\teval-logloss:14.16976\ttrain-logloss:2.80122\n",
      "[15]\teval-logloss:14.87824\ttrain-logloss:2.69484\n",
      "[16]\teval-logloss:15.01994\ttrain-logloss:1.98568\n",
      "[17]\teval-logloss:15.87012\ttrain-logloss:1.98568\n",
      "[18]\teval-logloss:15.16164\ttrain-logloss:1.70201\n",
      "[19]\teval-logloss:14.45315\ttrain-logloss:1.38288\n",
      "[20]\teval-logloss:13.88636\ttrain-logloss:1.09921\n",
      "[21]\teval-logloss:14.31145\ttrain-logloss:1.13467\n",
      "[22]\teval-logloss:15.30334\ttrain-logloss:1.17013\n",
      "[23]\teval-logloss:13.88636\ttrain-logloss:1.09921\n",
      "[24]\teval-logloss:14.59485\ttrain-logloss:0.99284\n",
      "[25]\teval-logloss:14.31145\ttrain-logloss:0.67371\n",
      "[26]\teval-logloss:14.45315\ttrain-logloss:0.74463\n",
      "[27]\teval-logloss:12.89448\ttrain-logloss:0.67371\n",
      "[28]\teval-logloss:14.16976\ttrain-logloss:0.60279\n",
      "[29]\teval-logloss:15.58673\ttrain-logloss:0.46096\n",
      "[30]\teval-logloss:14.59485\ttrain-logloss:0.49642\n",
      "[31]\teval-logloss:15.30334\ttrain-logloss:0.24821\n",
      "[32]\teval-logloss:15.58673\ttrain-logloss:0.42550\n",
      "[33]\teval-logloss:16.15352\ttrain-logloss:0.46096\n",
      "[34]\teval-logloss:16.15352\ttrain-logloss:0.56734\n",
      "[35]\teval-logloss:16.43692\ttrain-logloss:0.21275\n",
      "[36]\teval-logloss:16.15352\ttrain-logloss:0.14183\n",
      "[37]\teval-logloss:16.01182\ttrain-logloss:0.35458\n",
      "[38]\teval-logloss:15.58673\ttrain-logloss:0.31913\n",
      "[39]\teval-logloss:16.43692\ttrain-logloss:0.35458\n",
      "[40]\teval-logloss:15.72843\ttrain-logloss:0.24821\n",
      "[41]\teval-logloss:16.29522\ttrain-logloss:0.24821\n",
      "[42]\teval-logloss:15.72843\ttrain-logloss:0.31913\n",
      "[43]\teval-logloss:15.72843\ttrain-logloss:0.24821\n",
      "[44]\teval-logloss:14.73654\ttrain-logloss:0.24821\n",
      "[45]\teval-logloss:15.01994\ttrain-logloss:0.24821\n",
      "[46]\teval-logloss:15.16164\ttrain-logloss:0.24821\n",
      "[47]\teval-logloss:14.87824\ttrain-logloss:0.24821\n",
      "[48]\teval-logloss:15.44503\ttrain-logloss:0.14183\n",
      "[49]\teval-logloss:15.30334\ttrain-logloss:0.24821\n",
      "[50]\teval-logloss:15.44503\ttrain-logloss:0.17729\n",
      "[51]\teval-logloss:16.01182\ttrain-logloss:0.10637\n",
      "[52]\teval-logloss:15.72843\ttrain-logloss:0.07092\n",
      "[53]\teval-logloss:16.29522\ttrain-logloss:0.07092\n",
      "[54]\teval-logloss:16.43692\ttrain-logloss:0.28367\n",
      "[55]\teval-logloss:16.57861\ttrain-logloss:0.14183\n",
      "[56]\teval-logloss:17.42880\ttrain-logloss:0.07092\n",
      "[57]\teval-logloss:17.00371\ttrain-logloss:0.10637\n",
      "[58]\teval-logloss:17.14540\ttrain-logloss:0.17729\n",
      "[59]\teval-logloss:16.86201\ttrain-logloss:0.07092\n",
      "[60]\teval-logloss:16.72031\ttrain-logloss:0.14183\n",
      "[61]\teval-logloss:16.86201\ttrain-logloss:0.07092\n",
      "[62]\teval-logloss:16.72031\ttrain-logloss:0.03546\n",
      "[63]\teval-logloss:16.72031\ttrain-logloss:0.07092\n",
      "[64]\teval-logloss:17.14540\ttrain-logloss:0.07092\n",
      "[65]\teval-logloss:16.86201\ttrain-logloss:0.03546\n",
      "[66]\teval-logloss:16.57861\ttrain-logloss:0.00000\n",
      "[67]\teval-logloss:16.15352\ttrain-logloss:0.14183\n",
      "[68]\teval-logloss:17.00371\ttrain-logloss:0.07092\n",
      "[69]\teval-logloss:16.43692\ttrain-logloss:0.03546\n",
      "[70]\teval-logloss:16.57861\ttrain-logloss:0.03546\n",
      "[71]\teval-logloss:17.14540\ttrain-logloss:0.03546\n",
      "[72]\teval-logloss:17.00371\ttrain-logloss:0.03546\n",
      "[73]\teval-logloss:17.42880\ttrain-logloss:0.03546\n",
      "[74]\teval-logloss:17.14540\ttrain-logloss:0.00000\n",
      "[75]\teval-logloss:17.00371\ttrain-logloss:0.03546\n",
      "[76]\teval-logloss:17.00371\ttrain-logloss:0.03546\n",
      "[77]\teval-logloss:17.00371\ttrain-logloss:0.07092\n",
      "[78]\teval-logloss:16.86201\ttrain-logloss:0.00000\n",
      "[79]\teval-logloss:16.86201\ttrain-logloss:0.03546\n",
      "[80]\teval-logloss:16.57861\ttrain-logloss:0.00000\n",
      "[81]\teval-logloss:16.72031\ttrain-logloss:0.00000\n",
      "[82]\teval-logloss:16.57861\ttrain-logloss:0.00000\n",
      "[83]\teval-logloss:16.86201\ttrain-logloss:0.00000\n",
      "[84]\teval-logloss:16.57861\ttrain-logloss:0.00000\n",
      "[85]\teval-logloss:16.86201\ttrain-logloss:0.00000\n",
      "[86]\teval-logloss:16.57861\ttrain-logloss:0.00000\n",
      "[87]\teval-logloss:16.86201\ttrain-logloss:0.00000\n",
      "[88]\teval-logloss:16.57861\ttrain-logloss:0.00000\n",
      "[89]\teval-logloss:16.86201\ttrain-logloss:0.00000\n",
      "[90]\teval-logloss:16.43692\ttrain-logloss:0.03546\n",
      "[91]\teval-logloss:16.86201\ttrain-logloss:0.03546\n",
      "[92]\teval-logloss:16.57861\ttrain-logloss:0.03546\n",
      "[93]\teval-logloss:16.86201\ttrain-logloss:0.00000\n",
      "[94]\teval-logloss:16.43692\ttrain-logloss:0.00000\n",
      "[95]\teval-logloss:17.00371\ttrain-logloss:0.00000\n",
      "[96]\teval-logloss:16.72031\ttrain-logloss:0.03546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|████████████████████████████████████████████████████                                                                                                                                                                                                                                   | 11/59 [00:06<00:28,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-logloss:19.60239\ttrain-logloss:15.82401\n",
      "[1]\teval-logloss:16.26581\ttrain-logloss:11.29291\n",
      "[2]\teval-logloss:15.29264\ttrain-logloss:8.01657\n",
      "[3]\teval-logloss:14.59752\ttrain-logloss:7.11035\n",
      "[4]\teval-logloss:15.01459\ttrain-logloss:5.75102\n",
      "[5]\teval-logloss:14.87557\ttrain-logloss:5.22820\n",
      "[6]\teval-logloss:15.01459\ttrain-logloss:4.35683\n",
      "[7]\teval-logloss:15.43166\ttrain-logloss:4.21741\n",
      "[8]\teval-logloss:15.57069\ttrain-logloss:4.07799\n",
      "[9]\teval-logloss:15.15362\ttrain-logloss:3.72945\n",
      "[10]\teval-logloss:15.15362\ttrain-logloss:3.52032\n",
      "[11]\teval-logloss:14.04143\ttrain-logloss:3.41575\n",
      "[12]\teval-logloss:14.59752\ttrain-logloss:3.10206\n",
      "[13]\teval-logloss:15.57069\ttrain-logloss:2.85808\n",
      "[14]\teval-logloss:15.98776\ttrain-logloss:2.61410\n",
      "[15]\teval-logloss:15.84874\ttrain-logloss:2.54439\n",
      "[16]\teval-logloss:15.57069\ttrain-logloss:2.47468\n",
      "[17]\teval-logloss:16.40483\ttrain-logloss:2.47468\n",
      "[18]\teval-logloss:16.40483\ttrain-logloss:1.91701\n",
      "[19]\teval-logloss:15.70971\ttrain-logloss:1.63817\n",
      "[20]\teval-logloss:15.70971\ttrain-logloss:1.60331\n",
      "[21]\teval-logloss:14.73654\ttrain-logloss:1.28962\n",
      "[22]\teval-logloss:15.01459\ttrain-logloss:0.83651\n",
      "[23]\teval-logloss:15.29264\ttrain-logloss:0.90622\n",
      "[24]\teval-logloss:16.40483\ttrain-logloss:0.97593\n",
      "[25]\teval-logloss:17.09995\ttrain-logloss:0.76680\n",
      "[26]\teval-logloss:15.70971\ttrain-logloss:0.66224\n",
      "[27]\teval-logloss:16.96093\ttrain-logloss:0.45311\n",
      "[28]\teval-logloss:15.70971\ttrain-logloss:0.45311\n",
      "[29]\teval-logloss:17.09995\ttrain-logloss:0.38340\n",
      "[30]\teval-logloss:16.82191\ttrain-logloss:0.45311\n",
      "[31]\teval-logloss:17.51703\ttrain-logloss:0.48796\n",
      "[32]\teval-logloss:16.68288\ttrain-logloss:0.48796\n",
      "[33]\teval-logloss:17.37800\ttrain-logloss:0.41826\n",
      "[34]\teval-logloss:17.23898\ttrain-logloss:0.31369\n",
      "[35]\teval-logloss:17.37800\ttrain-logloss:0.27884\n",
      "[36]\teval-logloss:17.23898\ttrain-logloss:0.34855\n",
      "[37]\teval-logloss:16.82191\ttrain-logloss:0.13942\n",
      "[38]\teval-logloss:16.40483\ttrain-logloss:0.20913\n",
      "[39]\teval-logloss:15.98776\ttrain-logloss:0.27884\n",
      "[40]\teval-logloss:16.40483\ttrain-logloss:0.27884\n",
      "[41]\teval-logloss:16.40483\ttrain-logloss:0.24398\n",
      "[42]\teval-logloss:15.98776\ttrain-logloss:0.24398\n",
      "[43]\teval-logloss:16.54386\ttrain-logloss:0.17427\n",
      "[44]\teval-logloss:16.26581\ttrain-logloss:0.45311\n",
      "[45]\teval-logloss:16.82191\ttrain-logloss:0.20913\n",
      "[46]\teval-logloss:16.40483\ttrain-logloss:0.27884\n",
      "[47]\teval-logloss:16.40483\ttrain-logloss:0.20913\n",
      "[48]\teval-logloss:16.54386\ttrain-logloss:0.31369\n",
      "[49]\teval-logloss:16.40483\ttrain-logloss:0.17427\n",
      "[50]\teval-logloss:17.23898\ttrain-logloss:0.24398\n",
      "[51]\teval-logloss:16.12679\ttrain-logloss:0.03485\n",
      "[52]\teval-logloss:16.54386\ttrain-logloss:0.17427\n",
      "[53]\teval-logloss:16.12679\ttrain-logloss:0.06971\n",
      "[54]\teval-logloss:16.26581\ttrain-logloss:0.10456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|████████████████████████████████████████████████████                                                                                                                                                                                                                                   | 11/59 [00:06<00:29,  1.63it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-8a681257db45>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    113\u001b[0m         \u001b[1;31m#bst = xgb.train(param, train,num_boost_round=1000,early_stopping_rounds=30)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[0mnum_round\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10000\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m         \u001b[0mbst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_round\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mevallist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    116\u001b[0m         \u001b[1;31m#RF = RandomForestClassifier(random_state=1,n_estimators=1000,max_depth=depth)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m         \u001b[1;31m#RF = RF.fit(target_x_train,target_y_train)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\takuma\\nabepy\\env\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m    225\u001b[0m     \u001b[0mBooster\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtrained\u001b[0m \u001b[0mbooster\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m     \"\"\"\n\u001b[1;32m--> 227\u001b[1;33m     bst = _train_internal(params, dtrain,\n\u001b[0m\u001b[0;32m    228\u001b[0m                           \u001b[0mnum_boost_round\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_boost_round\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m                           \u001b[0mevals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\takuma\\nabepy\\env\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks, evals_result, maximize, verbose_eval, early_stopping_rounds)\u001b[0m\n\u001b[0;32m    108\u001b[0m         \u001b[0mnboost\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m         \u001b[1;31m# check evaluation result.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 110\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mafter_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    111\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m         \u001b[1;31m# do checkpoint after evaluation, in case evaluation also updates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\takuma\\nabepy\\env\\lib\\site-packages\\xgboost\\callback.py\u001b[0m in \u001b[0;36mafter_iteration\u001b[1;34m(self, model, epoch, dtrain, evals)\u001b[0m\n\u001b[0;32m    421\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mevals\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m                 \u001b[1;32massert\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'-'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Dataset name should not contain `-`'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 423\u001b[1;33m             \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval_set\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetric\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    424\u001b[0m             \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# into datasets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    425\u001b[0m             \u001b[1;31m# split up `test-error:0.1234`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\takuma\\nabepy\\env\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36meval_set\u001b[1;34m(self, evals, iteration, feval)\u001b[0m\n\u001b[0;32m   1342\u001b[0m         \u001b[0mevnames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_char_p\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mc_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mevals\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1343\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_char_p\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1344\u001b[1;33m         _check_call(_LIB.XGBoosterEvalOneIter(self.handle,\n\u001b[0m\u001b[0;32m   1345\u001b[0m                                               \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1346\u001b[0m                                               \u001b[0mdmats\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevnames\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "model_score_df=pd.DataFrame(columns=['target_com','depth','target_per','総収益', '投資金額','出現数','購買予測数','利益率','購買的中率','的中数'])#スコアを格納するdf\n",
    "\n",
    "\n",
    "\n",
    "#print(result_com_number)\n",
    "#result_com=result_com_number\n",
    "result_com=1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#result_comごとの閾値の決定========================================================================\n",
    "\n",
    "gain_th=10#利益率の閾値\n",
    "result_s=result_com_df[result_com_df['result_com']==result_com]\n",
    "buy_accuracy_th=result_s['result_com_per'].values[0]*1.1#買ったうちの的中率の閾値\n",
    "num_tp_th=result_s['result_com_num'].values[0]*0.2#あたった回数の閾値(出現回数の20%が的中)\n",
    "#===============================================================================\n",
    "#学習データのラベル変換==========================================================\n",
    "result_train_df=train_df.copy() \n",
    "result_arr=[0]*len(result_train_df)\n",
    "i=0\n",
    "for result in result_train_df['result_com']:\n",
    "    if ((result==result_com)):\n",
    "        result_arr[i]=1\n",
    "    else:\n",
    "        result_arr[i]=0\n",
    "    i+=1\n",
    "result_train_df['result_com']=result_arr\n",
    "result_test_df=test_df.copy() \n",
    "result_arr=[0]*len(result_test_df)\n",
    "i=0\n",
    "for result in result_test_df['result_com']:\n",
    "    if ((result==result_com)):\n",
    "        result_arr[i]=1\n",
    "    else:\n",
    "        result_arr[i]=0\n",
    "    i+=1\n",
    "\n",
    "result_test_df['result_com']=result_arr\n",
    "\n",
    "result_train_df['money']=train_money\n",
    "result_test_df['money']=test_money\n",
    "#学習データラベル変換終わり============================================\n",
    "\n",
    "for_arr=np.arange(1,60)\n",
    "#for_arr=np.arange(1,100,1)\n",
    "accuracy_arr=[0]*len(for_arr)\n",
    "target_per_arr=[0]*len(for_arr)\n",
    "pred_0=[0]*len(for_arr)\n",
    "gain_arr=[0]*len(for_arr)\n",
    "model_gain_arr=[0]*len(result_test_df)\n",
    "test_gain_arr=test_money.values\n",
    "#depths_arr=[4,5,6,7,8]\n",
    "depths_arr=[5,6,8]\n",
    "for depth in depths_arr:\n",
    "    for sum_target_per in tqdm(for_arr):\n",
    "\n",
    "        index=sum_target_per-1\n",
    "        #target_per=50+sum_target_per\n",
    "        #target_per=80+(sum_target_per*2)\n",
    "        target_per=80+(sum_target_per*4)\n",
    "        target_per_arr[index]=target_per\n",
    "\n",
    "        #モデルの評価指標値を格納するseries======================\n",
    "        model_score_s=pd.Series(index=['target_com','depth','target_per','総収益', '投資金額','出現数','購買予測数','利益率','購買的中率','的中数'], dtype='float64')\n",
    "        model_score_s['target_com']=result_com#目標としているresult_comラベル番号\n",
    "        model_score_s['depth']=depth#ハイパーパラメータ＿木の深さ\n",
    "        model_score_s['target_per']=target_per#学習データ_1に対してどの程度の0のデータを持たせるか。\n",
    "        #======================\n",
    "        #trainの[0]に対して、target_perの割合の量[1]を持った学習データの作成\n",
    "        # 一層目の判別機のtrainデータ　:terget_result_df\n",
    "        target_df=result_train_df#ベースのデータフレームをコピー\n",
    "        target_df=target_df.sample(frac=1, random_state=1)#シャッフル、時系列の偏りを無くす\n",
    "        target_1_df=target_df[target_df['result_com']==1]\n",
    "        len_1=len(target_1_df)\n",
    "        target_0_df=target_df[target_df['result_com']==0]\n",
    "        len_0=len(target_0_df)\n",
    "        target_0_df=target_0_df.iloc[(len_0-int(len_1*(target_per/100))):len_0]#1に対する目標の割合ぶん0の結果だったレースを抽出（後ろから抽出）\n",
    "        target_train_df=pd.concat([target_1_df, target_0_df])\n",
    "        #学習＆予測ぱーと========================================================================\n",
    "        #==========================================================================================================================================\n",
    "        #データの切り分け\n",
    "        target_x_train=target_train_df.drop('money',axis=1)\n",
    "        target_x_train=target_x_train.drop('result_com',axis=1)\n",
    "        target_x_test=result_test_df.drop('money',axis=1)\n",
    "        target_x_test=target_x_test.drop('result_com',axis=1)\n",
    "\n",
    "        target_y_train=target_train_df['result_com']\n",
    "        target_y_test=result_test_df['result_com']\n",
    "        train_x, valid_x, train_y, valid_y = train_test_split(target_x_train, target_y_train, test_size=0.2, shuffle=True)#学習データ内でさらに分割してロスをもとに修正をする。\n",
    "\n",
    "        #XGboostのデータ型に変換する\n",
    "        train = xgb.DMatrix(train_x, label=train_y)#学習用\n",
    "        valid = xgb.DMatrix(valid_x, label=valid_y)#学習時のロス修正用\n",
    "        test = xgb.DMatrix(target_x_test, label=target_y_test)#実際に使った時の利益率の算出用\n",
    "        \n",
    "        #xgb.config_context(verbosity=0)\n",
    "        param = {'max_depth': depth, #パラメータの設定\n",
    "                 #'eta': 0.5,\n",
    "                 'eta': 0.8,\n",
    "                 #'objective': 'binary:logistic',\n",
    "                 'objective': 'binary:hinge',\n",
    "                 'eval_metric': 'logloss',\n",
    "                 'verbosity':0,\n",
    "                 'subsample':0.8,\n",
    "                 'nthread':10,\n",
    "                 'gpu_id':0,\n",
    "                 'tree_method':'gpu_hist'\n",
    "                }\n",
    "        evallist = [(valid, 'eval'), (train, 'train')]#学習時にバリデーションを監視するデータの指定。\n",
    "        #bst = xgb.train(param, train,num_boost_round=1000,early_stopping_rounds=30)\n",
    "        num_round = 10000\n",
    "        bst = xgb.train(param, train,num_round,evallist, early_stopping_rounds=30)\n",
    "        #RF = RandomForestClassifier(random_state=1,n_estimators=1000,max_depth=depth)\n",
    "        #RF = RF.fit(target_x_train,target_y_train)\n",
    "        \n",
    "        \n",
    "        # 未知データに対する予測値\n",
    "        #predict_y_test = RF.predict(target_x_test)\n",
    "        predict_y_test=bst.predict(test)\n",
    "\n",
    "        #==========================================================================================================================================\n",
    "        #==========================================================================================================================================\n",
    "        #==========================================================================================================================================\n",
    "        #==========================================================================================================================================\n",
    "        \n",
    "        #[1]の正答率を見る\n",
    "        pred_test_df=pd.DataFrame({'pred':predict_y_test\n",
    "                                  , 'test':target_y_test})\n",
    "        num_1=len(pred_test_df[pred_test_df['test']==1])\n",
    "        count=0\n",
    "        #追加　配当金の情報も考慮する。\n",
    "        gain_index=0\n",
    "        model_gain_arr=[0]*len(result_test_df)\n",
    "        for _, s in pred_test_df.iterrows():\n",
    "            if ((s['pred']==1) and (s['test']==1)):\n",
    "                count+=1#的中回数\n",
    "                model_gain_arr[gain_index]=test_gain_arr[gain_index]\n",
    "            gain_index+=1\n",
    "        #print('test accyracy: {}'.format((count/num_1)*100))\n",
    "        gain_arr[index]=sum(model_gain_arr)\n",
    "        accuracy_arr[index]=(count/num_1)*100\n",
    "        try:\n",
    "            pred_0[index]=pred_test_df['pred'].value_counts()[0]\n",
    "        except:\n",
    "            pred_0[index]=0\n",
    "        #scoreのseriesに情報書き込み==================\n",
    "        model_score_s['総収益']=sum(model_gain_arr)\n",
    "        model_score_s['投資金額']=100*sum(predict_y_test)\n",
    "        model_score_s['出現数']=sum(target_y_test)\n",
    "        model_score_s['購買予測数']=sum(predict_y_test)\n",
    "        model_score_s['利益率']=(model_score_s['総収益']/model_score_s['投資金額'])*100\n",
    "        model_score_s['購買的中率']=(count/sum(predict_y_test))*100\n",
    "        model_score_s['的中数']=count\n",
    "        model_score_df=model_score_df.append(model_score_s,ignore_index=True)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "model_score_df.to_csv('excample.csv',encoding='utf_8_sig')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eleven-simpson",
   "metadata": {},
   "source": [
    "# V2_1のテスト（学習データにクラスタリングあり、ボートとモータの番号はなし）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "surrounded-parent",
   "metadata": {},
   "outputs": [],
   "source": [
    "#　学習データの読み込み\n",
    "\n",
    "#place_master=master.get_place_master()\n",
    "#for place in place_master.items():\n",
    "version='V2_1'\n",
    "pd.set_option('display.width',400)#勝手に改行コードを入れられるのを防ぐ\n",
    "place_name='tokuyama'#今回は徳山を例にしていったんXGboostバージョンを作る。\n",
    "\n",
    "################################################========================================================================================================================\n",
    "################################################========================================================================================================================\n",
    "################################################========================================================================================================================\n",
    "################################################========================================================================================================================\n",
    "result_filepath=\"../..//bot_database/{place_name}/{place_name}_train/train_{place_name}.csv\".format(place_name=place_name)#作成したデータの書き込み先#使用するデータの読み込み\n",
    "result_base_df=pd.read_csv(result_filepath)\n",
    "result_base_df=result_base_df.drop([\"Unnamed: 0\"],axis=1)\n",
    "#result_df=making.data_making_clustar(result_base_df)\n",
    "result_df=making.data_making_mo_bo(result_base_df)#ボート場暗号とかを持ったモデルにしてみる。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "canadian-database",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_th_trans(pred_df,th):\n",
    "    #引数として予測結果のdeと、変換したい閾値を渡す。\n",
    "    trans_df=pred_df.copy()\n",
    "    trans_df.loc[trans_df['pred_proba'] >= th, 'pred'] = 1\n",
    "    trans_df.loc[~(trans_df['pred_proba']  >=  th), 'pred'] = 0\n",
    "    return trans_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "authentic-canon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokuyama\n"
     ]
    }
   ],
   "source": [
    "print(place_name)\n",
    "#result_dfは加工関数にて分けられたものを渡す。\n",
    "model_score_df=pd.DataFrame(columns=['target_com','depth','target_per','threshold','総収益', '投資金額','出現数','購買予測数','利益率','購買的中率','的中数'])#スコアを格納するdf\n",
    "\n",
    "#学習データの切り分け\n",
    "test_df = result_df[(result_df['year']==2019) | ((result_df['year']==2020) )]#2019,2020のデータを検証用データに。\n",
    "train_df =  result_df[(result_df['year']!=2019) & ((result_df['year']!=2020) )]#そのほかを学習データに\n",
    "#学習データを切り分けたらyearはいらないから削除する\n",
    "test_df=test_df.drop(['year'],axis=1)\n",
    "train_df=train_df.drop(['year'],axis=1)\n",
    "\n",
    "train_money=pd.Series(train_df['money'])\n",
    "test_money=pd.Series(test_df['money'])\n",
    "\n",
    "#x,yへの切り分け\n",
    "#出現数の分布\n",
    "result_com_s=test_df['result_com'].value_counts()\n",
    "result_com_s=result_com_s.sort_index()\n",
    "gain_mean=test_df.groupby('result_com')['money'].mean()\n",
    "gain_mean=gain_mean.sort_index()\n",
    "\n",
    "gain_median=test_df.groupby('result_com')['money'].median()\n",
    "gain_median=gain_median.sort_index()\n",
    "result_com_df=pd.DataFrame({'result_com':result_com_s.index,\n",
    "                            'result_com_num':result_com_s.values,\n",
    "                            'result_com_per':result_com_s.values/sum(result_com_s.values)*100,\n",
    "                            'gain_mean':gain_mean.values,\n",
    "                            'gain_median':gain_median.values,})\n",
    "result_com_df=result_com_df.iloc[0:28]#探索的に探すにも最後のほうは役にモデルなのはわかっているため\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "for result_com_number in tqdm(result_com_df['result_com'].values):\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#print(result_com_number)\n",
    "result_com=5\n",
    "\n",
    "#result_comごとの閾値の決定========================================================================\n",
    "\n",
    "gain_th=10#利益率の閾値\n",
    "result_s=result_com_df[result_com_df['result_com']==result_com]\n",
    "buy_accuracy_th=result_s['result_com_per'].values[0]*1.1#買ったうちの的中率の閾値\n",
    "num_tp_th=result_s['result_com_num'].values[0]*0.2#あたった回数の閾値(出現回数の20%が的中)\n",
    "#===============================================================================\n",
    "#学習データのラベル変換==========================================================\n",
    "result_train_df=train_df.copy()\n",
    "result_arr=[0]*len(result_train_df)\n",
    "i=0\n",
    "for result in result_train_df['result_com']:\n",
    "    if ((result==result_com)):\n",
    "        result_arr[i]=1\n",
    "    else:\n",
    "        result_arr[i]=0\n",
    "    i+=1\n",
    "result_train_df['result_com']=result_arr\n",
    "result_test_df=test_df.copy()\n",
    "result_arr=[0]*len(result_test_df)\n",
    "i=0\n",
    "for result in result_test_df['result_com']:\n",
    "    if ((result==result_com)):\n",
    "        result_arr[i]=1\n",
    "    else:\n",
    "        result_arr[i]=0\n",
    "    i+=1\n",
    "\n",
    "result_test_df['result_com']=result_arr\n",
    "\n",
    "result_train_df['money']=train_money\n",
    "result_test_df['money']=test_money\n",
    "#学習データラベル変換終わり============================================\n",
    "\n",
    "for_arr=np.arange(1,60)\n",
    "#for_arr=np.arange(1,100,1)\n",
    "accuracy_arr=[0]*len(for_arr)\n",
    "target_per_arr=[0]*len(for_arr)\n",
    "pred_0=[0]*len(for_arr)\n",
    "gain_arr=[0]*len(for_arr)\n",
    "model_gain_arr=[0]*len(result_test_df)\n",
    "test_gain_arr=test_money.values\n",
    "#depths_arr=[4,5,6,7,8]\n",
    "depths_arr=[5,6,8]\n",
    "for depth in depths_arr:\n",
    "    for sum_target_per in for_arr:\n",
    "\n",
    "        index=sum_target_per-1\n",
    "        #target_per=50+sum_target_per\n",
    "        target_per=80+(sum_target_per*3)\n",
    "        target_per_arr[index]=target_per\n",
    "\n",
    "        #モデルの評価指標値を格納するseries======================\n",
    "        model_score_s=pd.Series(index=['target_com','depth','target_per','threshold','総収益', '投資金額','出現数','購買予測数','利益率','購買的中率','的中数'], dtype='float64')\n",
    "        model_score_s['target_com']=result_com#目標としているresult_comラベル番号\n",
    "        model_score_s['depth']=depth#ハイパーパラメータ＿木の深さ\n",
    "        model_score_s['target_per']=target_per#学習データ_1に対してどの程度の0のデータを持たせるか。\n",
    "        #======================\n",
    "        #trainの[0]に対して、target_perの割合の量[1]を持った学習データの作成\n",
    "        # 一層目の判別機のtrainデータ　:terget_result_df\n",
    "        target_df=result_train_df#ベースのデータフレームをコピー\n",
    "        target_df=target_df.sample(frac=1, random_state=1)#シャッフル、時系列の偏りを無くす\n",
    "        target_1_df=target_df[target_df['result_com']==1]\n",
    "        len_1=len(target_1_df)\n",
    "        target_0_df=target_df[target_df['result_com']==0]\n",
    "        len_0=len(target_0_df)\n",
    "        target_0_df=target_0_df.iloc[(len_0-int(len_1*(target_per/100))):len_0]#1に対する目標の割合ぶん0の結果だったレースを抽出（後ろから抽出）\n",
    "        target_train_df=pd.concat([target_1_df, target_0_df])\n",
    "        #学習＆予測ぱーと========================================================================\n",
    "        #==========================================================================================================================================\n",
    "        #データの切り分け\n",
    "        target_x_train=target_train_df.drop('money',axis=1)\n",
    "        target_x_train=target_x_train.drop('result_com',axis=1)\n",
    "        target_x_test=result_test_df.drop('money',axis=1)\n",
    "        target_x_test=target_x_test.drop('result_com',axis=1)\n",
    "\n",
    "        target_y_train=target_train_df['result_com']\n",
    "        target_y_test=result_test_df['result_com']\n",
    "        train_x, valid_x, train_y, valid_y = train_test_split(target_x_train, target_y_train, test_size=0.2, shuffle=True)#学習データ内でさらに分割してロスをもとに修正をする。\n",
    "\n",
    "        #XGboostのデータ型に変換する\n",
    "        train = xgb.DMatrix(train_x, label=train_y)#学習用\n",
    "        valid = xgb.DMatrix(valid_x, label=valid_y)#学習時のロス修正用\n",
    "        test = xgb.DMatrix(target_x_test, label=target_y_test)#実際に使った時の利益率の算出用\n",
    "\n",
    "        #xgb.config_context(verbosity=0)\n",
    "        param = {'max_depth': depth, #パラメータの設定\n",
    "                 'eta': 0.5,\n",
    "                 #'eta': 0.2,\n",
    "                 #'objective': 'binary:hinge',\n",
    "                 'objective': 'binary:logistic',#確率で出力\n",
    "                 'eval_metric': 'logloss',\n",
    "                 'verbosity':0,\n",
    "                 'subsample':0.8,\n",
    "                 'nthread':10,\n",
    "                 'gpu_id':0,\n",
    "                 'tree_method':'gpu_hist'\n",
    "                }\n",
    "        evallist = [(valid, 'eval'), (train, 'train')]#学習時にバリデーションを監視するデータの指定。\n",
    "        #bst = xgb.train(param, train,num_boost_round=1000,early_stopping_rounds=30)\n",
    "        num_round = 10000\n",
    "        bst = xgb.train(param, train,num_round,evallist, early_stopping_rounds=30, verbose_eval=0 )\n",
    "        #RF = RandomForestClassifier(random_state=1,n_estimators=1000,max_depth=depth)\n",
    "        #RF = RF.fit(target_x_train,target_y_train)\n",
    "\n",
    "\n",
    "        # 未知データに対する予測値\n",
    "        #predict_y_test = RF.predict(target_x_test)\n",
    "        predict_y_test=bst.predict(test)\n",
    "\n",
    "        #==========================================================================================================================================\n",
    "        #==========================================================================================================================================\n",
    "        #==========================================================================================================================================\n",
    "        #==========================================================================================================================================\n",
    "\n",
    "        #[1]の正答率を見る\n",
    "        pred_test_df=pd.DataFrame({'pred_proba':predict_y_test#確率分布での出力\n",
    "                                  , 'test':target_y_test})\n",
    "        \n",
    "        th_arr=[0.85,0.87,0.9,0.92,0.95]\n",
    "        #th_arr=[0.01,0.03,0.05,0.07,0.9,0.1,0.13]\n",
    "        \n",
    "        for th in th_arr:\n",
    "            trans_df=pred_th_trans(pred_test_df,th)\n",
    "            num_1=len(trans_df[trans_df['test']==1])\n",
    "            count=0\n",
    "            #追加　配当金の情報も考慮する。\n",
    "            gain_index=0\n",
    "            model_gain_arr=[0]*len(result_test_df)\n",
    "            for _, s in trans_df.iterrows():\n",
    "                if ((s['pred']==1) and (s['test']==1)):#もし購買しているかつ的中をしていたら・・・\n",
    "                    count+=1#的中回数\n",
    "                    model_gain_arr[gain_index]=test_gain_arr[gain_index]\n",
    "                gain_index+=1\n",
    "            #print('test accyracy: {}'.format((count/num_1)*100))\n",
    "            gain_arr[index]=sum(model_gain_arr)\n",
    "            accuracy_arr[index]=(count/num_1)*100\n",
    "            try:\n",
    "                pred_0[index]=trans_df['pred'].value_counts()[0]\n",
    "            except:\n",
    "                pred_0[index]=0\n",
    "            #scoreのseriesに情報書き込み==================\n",
    "            model_score_s['threshold']=th\n",
    "            model_score_s['総収益']=sum(model_gain_arr)\n",
    "            #model_score_s['投資金額']=100*sum(predict_y_test)\n",
    "            model_score_s['投資金額']=100*trans_df['pred'].sum()\n",
    "            model_score_s['出現数']=sum(target_y_test)\n",
    "            #model_score_s['購買予測数']=sum(predict_y_test)\n",
    "            model_score_s['購買予測数']=trans_df['pred'].sum()\n",
    "            model_score_s['利益率']=(model_score_s['総収益']/model_score_s['投資金額'])*100\n",
    "            model_score_s['購買的中率']=(count/trans_df['pred'].sum())*100\n",
    "            model_score_s['的中数']=count\n",
    "            model_score_df=model_score_df.append(model_score_s,ignore_index=True)\n",
    "\n",
    "\n",
    "#モデルの「スコアを保存\n",
    "#model_score_df.to_csv('{}_model_score.csv'.format(place), encoding='utf_8_sig')\n",
    "\n",
    "#dir_path = \"../../bot_database/{place_name}/model_score_{place_name}/{place_name}_model_score_{V}.csv\".format(place_name=place_name,V=version)#作成したデータの書き込み先#使用するデータの読み込み\n",
    "dir_path = \"csv/{place_name}_model_score_{V}.csv\".format(place_name=place_name,V=version)#作成したデータの書き込み先#使用するデータの読み込み\n",
    "model_score_df=model_score_df.sort_values(['target_com', 'depth','threshold','target_per'])#並べ替え\n",
    "model_score_df.to_csv(dir_path, encoding='utf_8_sig')\n",
    "#return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broke-equilibrium",
   "metadata": {},
   "source": [
    "### 閾値を渡してその閾値を以上を１（予測あり）、それ以外を０に変換する関数案「precision」を上げるための策"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "romance-absorption",
   "metadata": {
    "code_folding": [
     2
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_proba</th>\n",
       "      <th>test</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14797</th>\n",
       "      <td>0.026117</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14798</th>\n",
       "      <td>0.065188</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14799</th>\n",
       "      <td>0.045880</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14800</th>\n",
       "      <td>0.717593</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14801</th>\n",
       "      <td>0.000028</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14802</th>\n",
       "      <td>0.000004</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14803</th>\n",
       "      <td>0.000177</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14804</th>\n",
       "      <td>0.004368</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14805</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14806</th>\n",
       "      <td>0.857891</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14807</th>\n",
       "      <td>0.999793</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14808</th>\n",
       "      <td>0.847561</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14809</th>\n",
       "      <td>0.002010</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14810</th>\n",
       "      <td>0.010449</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14811</th>\n",
       "      <td>0.264361</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14812</th>\n",
       "      <td>0.000333</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14813</th>\n",
       "      <td>0.056877</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14814</th>\n",
       "      <td>0.000889</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14815</th>\n",
       "      <td>0.001143</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14816</th>\n",
       "      <td>0.001786</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14817</th>\n",
       "      <td>0.059859</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14818</th>\n",
       "      <td>0.000542</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14819</th>\n",
       "      <td>0.234757</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14820</th>\n",
       "      <td>0.145952</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14821</th>\n",
       "      <td>0.352645</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14822</th>\n",
       "      <td>0.001708</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14823</th>\n",
       "      <td>0.000881</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14824</th>\n",
       "      <td>0.001274</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14825</th>\n",
       "      <td>0.769249</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14826</th>\n",
       "      <td>0.287273</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14827</th>\n",
       "      <td>0.000358</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14828</th>\n",
       "      <td>0.242719</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14829</th>\n",
       "      <td>0.030154</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14830</th>\n",
       "      <td>0.271985</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14831</th>\n",
       "      <td>0.000060</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14832</th>\n",
       "      <td>0.095373</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14833</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14834</th>\n",
       "      <td>0.000139</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14835</th>\n",
       "      <td>0.025714</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14836</th>\n",
       "      <td>0.951327</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14837</th>\n",
       "      <td>0.060408</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14838</th>\n",
       "      <td>0.052472</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14839</th>\n",
       "      <td>0.013757</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14840</th>\n",
       "      <td>0.000408</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14841</th>\n",
       "      <td>0.049551</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14842</th>\n",
       "      <td>0.233733</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14843</th>\n",
       "      <td>0.003854</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14844</th>\n",
       "      <td>0.021977</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14845</th>\n",
       "      <td>0.000401</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14846</th>\n",
       "      <td>0.001609</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       pred_proba  test  pred\n",
       "14797    0.026117     0   0.0\n",
       "14798    0.065188     0   0.0\n",
       "14799    0.045880     0   0.0\n",
       "14800    0.717593     0   0.0\n",
       "14801    0.000028     0   0.0\n",
       "14802    0.000004     0   0.0\n",
       "14803    0.000177     0   0.0\n",
       "14804    0.004368     0   0.0\n",
       "14805    0.000001     0   0.0\n",
       "14806    0.857891     0   0.0\n",
       "14807    0.999793     0   1.0\n",
       "14808    0.847561     0   0.0\n",
       "14809    0.002010     0   0.0\n",
       "14810    0.010449     0   0.0\n",
       "14811    0.264361     0   0.0\n",
       "14812    0.000333     0   0.0\n",
       "14813    0.056877     0   0.0\n",
       "14814    0.000889     0   0.0\n",
       "14815    0.001143     0   0.0\n",
       "14816    0.001786     0   0.0\n",
       "14817    0.059859     0   0.0\n",
       "14818    0.000542     0   0.0\n",
       "14819    0.234757     0   0.0\n",
       "14820    0.145952     0   0.0\n",
       "14821    0.352645     0   0.0\n",
       "14822    0.001708     0   0.0\n",
       "14823    0.000881     1   0.0\n",
       "14824    0.001274     0   0.0\n",
       "14825    0.769249     0   0.0\n",
       "14826    0.287273     0   0.0\n",
       "14827    0.000358     1   0.0\n",
       "14828    0.242719     0   0.0\n",
       "14829    0.030154     0   0.0\n",
       "14830    0.271985     0   0.0\n",
       "14831    0.000060     0   0.0\n",
       "14832    0.095373     1   0.0\n",
       "14833    0.000003     0   0.0\n",
       "14834    0.000139     0   0.0\n",
       "14835    0.025714     0   0.0\n",
       "14836    0.951327     0   1.0\n",
       "14837    0.060408     0   0.0\n",
       "14838    0.052472     0   0.0\n",
       "14839    0.013757     0   0.0\n",
       "14840    0.000408     0   0.0\n",
       "14841    0.049551     0   0.0\n",
       "14842    0.233733     0   0.0\n",
       "14843    0.003854     0   0.0\n",
       "14844    0.021977     1   0.0\n",
       "14845    0.000401     0   0.0\n",
       "14846    0.001609     0   0.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#th=0.7\n",
    "th_arr=[0.7,0.8,0.9]\n",
    "for th in th_arr:\n",
    "    trans_df=pred_th_trans(pred_test_df,th)\n",
    "trans_df[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "amber-involvement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131080.0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(model_gain_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "first-saver",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>result_com</th>\n",
       "      <th>money</th>\n",
       "      <th>racer_1_rank</th>\n",
       "      <th>racer_1_age</th>\n",
       "      <th>racer_1_doub</th>\n",
       "      <th>racer_1_ave_st</th>\n",
       "      <th>racer_2_rank</th>\n",
       "      <th>racer_2_age</th>\n",
       "      <th>racer_2_doub</th>\n",
       "      <th>racer_2_ave_st</th>\n",
       "      <th>...</th>\n",
       "      <th>racer_6_bo_90</th>\n",
       "      <th>racer_6_bo_91</th>\n",
       "      <th>racer_6_bo_92</th>\n",
       "      <th>racer_6_bo_93</th>\n",
       "      <th>racer_6_bo_94</th>\n",
       "      <th>racer_6_bo_95</th>\n",
       "      <th>racer_6_bo_96</th>\n",
       "      <th>racer_6_bo_97</th>\n",
       "      <th>racer_6_bo_98</th>\n",
       "      <th>racer_6_bo_99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14797</th>\n",
       "      <td>20</td>\n",
       "      <td>16650.0</td>\n",
       "      <td>3</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.387</td>\n",
       "      <td>0.17</td>\n",
       "      <td>2</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.297</td>\n",
       "      <td>0.17</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14798</th>\n",
       "      <td>42</td>\n",
       "      <td>1740.0</td>\n",
       "      <td>4</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.442</td>\n",
       "      <td>0.18</td>\n",
       "      <td>4</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.468</td>\n",
       "      <td>0.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14799</th>\n",
       "      <td>3</td>\n",
       "      <td>910.0</td>\n",
       "      <td>3</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.448</td>\n",
       "      <td>0.18</td>\n",
       "      <td>2</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.17</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14800</th>\n",
       "      <td>63</td>\n",
       "      <td>6920.0</td>\n",
       "      <td>4</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.630</td>\n",
       "      <td>0.16</td>\n",
       "      <td>2</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.295</td>\n",
       "      <td>0.19</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14801</th>\n",
       "      <td>21</td>\n",
       "      <td>1250.0</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.20</td>\n",
       "      <td>4</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.15</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19298</th>\n",
       "      <td>12</td>\n",
       "      <td>730.0</td>\n",
       "      <td>3</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.416</td>\n",
       "      <td>0.14</td>\n",
       "      <td>2</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.17</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19299</th>\n",
       "      <td>70</td>\n",
       "      <td>14660.0</td>\n",
       "      <td>2</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.18</td>\n",
       "      <td>4</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.14</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19300</th>\n",
       "      <td>9</td>\n",
       "      <td>4170.0</td>\n",
       "      <td>4</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.17</td>\n",
       "      <td>3</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.386</td>\n",
       "      <td>0.17</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19301</th>\n",
       "      <td>14</td>\n",
       "      <td>1480.0</td>\n",
       "      <td>4</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.435</td>\n",
       "      <td>0.15</td>\n",
       "      <td>2</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19302</th>\n",
       "      <td>11</td>\n",
       "      <td>2530.0</td>\n",
       "      <td>4</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.12</td>\n",
       "      <td>4</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.428</td>\n",
       "      <td>0.13</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4506 rows × 1238 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       result_com    money  racer_1_rank  racer_1_age  racer_1_doub  racer_1_ave_st  racer_2_rank  racer_2_age  racer_2_doub  racer_2_ave_st  ...  racer_6_bo_90  racer_6_bo_91  racer_6_bo_92  racer_6_bo_93  racer_6_bo_94  racer_6_bo_95  racer_6_bo_96  racer_6_bo_97  racer_6_bo_98  racer_6_bo_99\n",
       "14797          20  16650.0             3         31.0         0.387            0.17             2         27.0         0.297            0.17  ...              0              0              0              0              0              0              0              0              0              0\n",
       "14798          42   1740.0             4         25.0         0.442            0.18             4         27.0         0.468            0.16  ...              0              0              0              0              0              0              0              0              0              0\n",
       "14799           3    910.0             3         33.0         0.448            0.18             2         26.0         0.193            0.17  ...              0              0              0              0              0              0              0              0              0              0\n",
       "14800          63   6920.0             4         30.0         0.630            0.16             2         30.0         0.295            0.19  ...              0              0              0              0              0              0              0              0              0              0\n",
       "14801          21   1250.0             1         27.0         0.111            0.20             4         31.0         0.400            0.15  ...              0              0              0              0              0              0              0              0              0              0\n",
       "...           ...      ...           ...          ...           ...             ...           ...          ...           ...             ...  ...            ...            ...            ...            ...            ...            ...            ...            ...            ...            ...\n",
       "19298          12    730.0             3         33.0         0.416            0.14             2         35.0         0.179            0.17  ...              0              0              0              0              0              0              0              0              0              0\n",
       "19299          70  14660.0             2         35.0         0.259            0.18             4         33.0         0.485            0.14  ...              0              0              0              0              0              0              0              0              0              0\n",
       "19300           9   4170.0             4         24.0         0.500            0.17             3         46.0         0.386            0.17  ...              0              0              0              0              0              0              0              0              0              0\n",
       "19301          14   1480.0             4         35.0         0.435            0.15             2         47.0         0.215            0.16  ...              0              0              0              0              0              0              0              0              0              0\n",
       "19302          11   2530.0             4         45.0         0.675            0.12             4         39.0         0.428            0.13  ...              0              0              0              0              0              0              0              0              0              0\n",
       "\n",
       "[4506 rows x 1238 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "intense-float",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target_com         5.000000\n",
       "depth              8.000000\n",
       "target_per       257.000000\n",
       "threshold          0.130000\n",
       "総収益           131080.000000\n",
       "投資金額           82820.640075\n",
       "出現数              227.000000\n",
       "購買予測数            828.206401\n",
       "利益率              158.269726\n",
       "購買的中率             12.315771\n",
       "的中数              102.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_score_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "biblical-estonia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    2899\n",
       "0.9     385\n",
       "0.1     309\n",
       "0.8     158\n",
       "0.2     149\n",
       "0.4     145\n",
       "0.3     128\n",
       "0.7     123\n",
       "0.6     113\n",
       "0.5      97\n",
       "Name: proba_1, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test_df['proba_1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "coordinate-uganda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4279\n",
       "1     227\n",
       "Name: test, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test_df['test'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accomplished-closure",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
