{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "miniature-president",
   "metadata": {},
   "source": [
    "# asiyaのprobaモデルを作成したが，なんか結果が違うのでこのバグについて検証を行うノートブック"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "arbitrary-pricing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "compliant-delaware",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\takuma\\nabepy\\env\\lib\\site-packages\\xgboost\\compat.py:31: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn\n",
    "from pandas import DataFrame\n",
    "from tqdm import tqdm\n",
    "from imblearn.under_sampling import RandomUnderSampler #アンダーサンプリング用\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "# 機械学習用\n",
    "from sklearn.cluster import KMeans #クラスタリング用\n",
    "from sklearn.decomposition import PCA  #次元削減用\n",
    "from sklearn.ensemble import RandomForestClassifier#ランダムフォレスト\n",
    "from copy import deepcopy as cp\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "import time\n",
    "import datetime\n",
    "import os #ディレクトリ作成用\n",
    "import xgboost as xgb\n",
    "import sys\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine #書き込みのエンジンをpostgreに変えるのに使う。\n",
    "\n",
    "from datetime import date, timedelta\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from sklearn.preprocessing import StandardScaler#モデルの評価用に標準化する関数\n",
    "import scipy.stats#モデルの評価用に標準化する関数\n",
    "#必要なモジュールのインポート\n",
    "import chromedriver_binary\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from sklearn import preprocessing\n",
    "import requests #クローリングのためのモジュール\n",
    "from bs4 import BeautifulSoup as bs4#HTMLから特定の情報を抜き出すためのモジュール\n",
    "from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outside-shoot",
   "metadata": {},
   "source": [
    "# 一番初めのいい感じになったやつ（サンプルのシートもこれから出力）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "conservative-fitting",
   "metadata": {
    "code_folding": [
     0,
     214,
     218,
     296
    ]
   },
   "outputs": [],
   "source": [
    "def pred_race_former_asiya_proba(date):\n",
    "    race_df=pd.DataFrame(index=[], columns=[])\n",
    "    for i in range(12):\n",
    "        rno=i+1\n",
    "        #まず初めに１ページの情報を抜き出す機能\n",
    "        url='http://www.boatrace.jp/owpc/pc/race/racelist?rno={}&jcd=21&hd={}'.format(rno,date)\n",
    "        response=requests.get(url)#対象のURLをget\n",
    "        response.encoding = response.apparent_encoding\n",
    "        start_page=bs4(response.text, 'html.parser')\n",
    "        racers_div=start_page.select_one(\".is-tableFixed__3rdadd\")\n",
    "        racers_sep_row=racers_div.find_all('tbody') \n",
    "        index=0\n",
    "        race_racers_data=[0]*6\n",
    "        if len(racers_sep_row)==6:\n",
    "            for racer_html in racers_sep_row:\n",
    "                racer_row_ex_td=racer_html.find_all('td')\n",
    "                #選手の登録ID\n",
    "                racer_ID_div=racer_row_ex_td[2].find_all('div')\n",
    "                racer_ID_div=racer_ID_div[0]\n",
    "                racer_ID_div_txt=racer_ID_div.text\n",
    "                start=(racer_ID_div_txt.find('/'))-35\n",
    "                end=(racer_ID_div_txt.find('/')-31)\n",
    "                #racer_ID=racer_ID_div_txt[start:end]#選手の登録ID\n",
    "                racer_ID=racer_ID_div_txt.split('\\n')[0]\n",
    "\n",
    "                #選手のモータ番号\n",
    "                racer_moter_td=racer_row_ex_td[6]\n",
    "                racer_moter_td_text=racer_moter_td.text\n",
    "                #racer_moter_split=racer_moter_td_text.split('\\r')\n",
    "                racer_moter_split=racer_moter_td_text.split('\\n')\n",
    "                #racer_moter_id=racer_moter_split[1][-2:]\n",
    "                racer_moter_id=racer_moter_split[0]\n",
    "                #選手のボート番号\n",
    "                racer_boat_td=racer_row_ex_td[7]\n",
    "                racer_boat_td_text=racer_boat_td.text\n",
    "    #             racer_boat_split=racer_boat_td_text.split('\\r')\n",
    "    #             racer_boat_id=racer_boat_split[1][-2:]\n",
    "                racer_boat_split=racer_boat_td_text.split('\\n')\n",
    "                racer_boat_id=racer_boat_split[0]\n",
    "\n",
    "                racer_data=[racer_ID,racer_moter_id,racer_boat_id]#選手固有のデータを持ったリスト\n",
    "\n",
    "                race_racers_data[index]=racer_data\n",
    "                index+=1\n",
    "        else:\n",
    "            print('欠場選手等の例外が発生していないか確認してください')\n",
    "        #race_racers_dataを一行に変換する\n",
    "        race_row=pd.Series(index=[])#一レースの情報を一行に変換したもの\n",
    "        race_num=rno#ここにはレース番号を入れる変数の値を代入\n",
    "        race_row['number_race']=race_num\n",
    "        for i in range(len(race_racers_data)):\n",
    "            race_row['racer_{}_ID'.format(i+1)]=int(race_racers_data[i][0])\n",
    "            race_row['racer_{}_mo'.format(i+1)]=int(race_racers_data[i][1])\n",
    "            race_row['racer_{}_bo'.format(i+1)]=int(race_racers_data[i][2])\n",
    "        race_df=race_df.append(race_row,ignore_index=True)\n",
    "\n",
    "\n",
    "    ### 学習データと保存してある選手パラメータを結合する\n",
    "    ### 学習データと保存してある選手パラメータを結合する\n",
    "    ### 学習データと保存してある選手パラメータを結合する\n",
    "\n",
    "    #使用するファイルの定義\n",
    "    para_file='21'\n",
    "    para_file_path=\"../../bot_database/racer_para/{}/{}.csv\".format(para_file,para_file)\n",
    "    #/content/drive/My Drive/boatrace_BOT_making/pred_tool/racer_pala_box/20.csv\n",
    "    #result_file_path=\"asiya_result_csv/asiya_result_20{0}.csv\".format(year)\n",
    "    #write_path=\"/content/drive/My Drive/pred_tool/asiya/pred_data/{0}_asiya.csv\".format(date)\n",
    "    #/////////////////////////////////////////////以下データフレームの作成\n",
    "    para_df=pd.read_csv(para_file_path)\n",
    "    para_df=para_df.drop([\"Unnamed: 0\"],axis=1)#csvファイルについている名無しの列を削除\n",
    "    #出力用データフレーム\n",
    "    #pred_race_df=pd.DataFrame(columns=['result_com','number_race','racer_1_ID','racer_2_ID','racer_3_ID','racer_4_ID','racer_5_ID','racer_6_ID','racer_1_rank','racer_1_male','racer_1_age','racer_1_doub','racer_1_ave_st','racer_2_rank','racer_2_male','racer_2_age','racer_2_doub','racer_2_ave_st','racer_3_rank','racer_3_male','racer_3_age','racer_3_doub','racer_3_ave_st','racer_4_rank','racer_4_male','racer_4_age','racer_4_doub','racer_4_ave_st','racer_5_rank','racer_5_male','racer_5_age','racer_5_doub','racer_5_ave_st','racer_6_rank','racer_6_male','racer_6_age','racer_6_doub','racer_6_ave_st'])\n",
    "    pred_race_df=pd.DataFrame(columns=[],index=[])\n",
    "    for index,series in race_df.iterrows():\n",
    "        add_df=pd.DataFrame(columns=['number_race','racer_1_ID','racer_2_ID','racer_3_ID','racer_4_ID','racer_5_ID','racer_6_ID','racer_1_rank','racer_1_male','racer_1_age','racer_1_doub','racer_1_ave_st','racer_2_rank','racer_2_male','racer_2_age','racer_2_doub','racer_2_ave_st','racer_3_rank','racer_3_male','racer_3_age','racer_3_doub','racer_3_ave_st','racer_4_rank','racer_4_male','racer_4_age','racer_4_doub','racer_4_ave_st','racer_5_rank','racer_5_male','racer_5_age','racer_5_doub','racer_5_ave_st','racer_6_rank','racer_6_male','racer_6_age','racer_6_doub','racer_6_ave_st'])\n",
    "        #///////////////////////////////////////レースに出ているレーサーの成績を検索＆取得\n",
    "        ID_1=series['racer_1_ID']\n",
    "        ID_2=series['racer_2_ID']\n",
    "        ID_3=series['racer_3_ID']\n",
    "        ID_4=series['racer_4_ID']\n",
    "        ID_5=series['racer_5_ID']\n",
    "        ID_6=series['racer_6_ID']\n",
    "        racer_1_df=para_df[para_df['racer_ID']==ID_1]\n",
    "        racer_2_df=para_df[para_df['racer_ID']==ID_2]\n",
    "        racer_3_df=para_df[para_df['racer_ID']==ID_3]\n",
    "        racer_4_df=para_df[para_df['racer_ID']==ID_4]\n",
    "        racer_5_df=para_df[para_df['racer_ID']==ID_5]\n",
    "        racer_6_df=para_df[para_df['racer_ID']==ID_6]\n",
    "        if len(racer_1_df)==1:\n",
    "            pass\n",
    "        else:\n",
    "            racer_1_df=para_df[(para_df['racer_doub_win']==0.00) & (para_df['racer_ave_st_time']==0.00)]\n",
    "            print('CAREFULL!!!!    NOT FOUND RACER ')\n",
    "\n",
    "        if len(racer_2_df)==1:\n",
    "            pass\n",
    "        else:\n",
    "            racer_2_df=para_df[(para_df['racer_doub_win']==0.00) & (para_df['racer_ave_st_time']==0.00)]\n",
    "            print('CAREFULL!!!!    NOT FOUND RACER ')\n",
    "\n",
    "        if len(racer_3_df)==1:\n",
    "            pass\n",
    "        else:\n",
    "            racer_3_df=para_df[(para_df['racer_doub_win']==0.00) & (para_df['racer_ave_st_time']==0.00)]\n",
    "            print('CAREFULL!!!!    NOT FOUND RACER ')\n",
    "\n",
    "        if len(racer_4_df)==1:\n",
    "            pass\n",
    "        else:\n",
    "            racer_4_df=para_df[(para_df['racer_doub_win']==0.00) & (para_df['racer_ave_st_time']==0.00)]\n",
    "            print('CAREFULL!!!!    NOT FOUND RACER ')\n",
    "\n",
    "        if len(racer_5_df)==1:\n",
    "            pass\n",
    "        else:\n",
    "            racer_5_df=para_df[(para_df['racer_doub_win']==0.00) & (para_df['racer_ave_st_time']==0.00)]\n",
    "            print('CAREFULL!!!!    NOT FOUND RACER ')\n",
    "\n",
    "\n",
    "        if len(racer_6_df)==1:\n",
    "            pass\n",
    "        else:\n",
    "            racer_6_df=para_df[(para_df['racer_doub_win']==0.00) & (para_df['racer_ave_st_time']==0.00)]\n",
    "            print('CAREFULL!!!!    NOT FOUND RACER ')\n",
    "\n",
    "        #追加していくデータフレームを作成\n",
    "        add_df= pd.DataFrame({'number_race':series['number_race'],\n",
    "                              'racer_1_ID':series['racer_1_ID'],\n",
    "                                'racer_2_ID':series['racer_2_ID'],\n",
    "                                'racer_3_ID':series['racer_3_ID'],\n",
    "                                'racer_4_ID':series['racer_4_ID'],\n",
    "                                'racer_5_ID':series['racer_5_ID'],\n",
    "                                'racer_6_ID':series['racer_6_ID'],\n",
    "                                'racer_1_bo':series['racer_1_bo'],\n",
    "                                'racer_1_mo':series['racer_1_mo'],\n",
    "                                'racer_2_bo':series['racer_2_bo'],\n",
    "                                'racer_2_mo':series['racer_2_mo'],\n",
    "                                'racer_3_bo':series['racer_3_bo'],\n",
    "                                'racer_3_mo':series['racer_3_mo'],\n",
    "                                'racer_4_bo':series['racer_4_bo'],\n",
    "                                'racer_4_mo':series['racer_4_mo'],\n",
    "                                'racer_5_bo':series['racer_5_bo'],\n",
    "                                'racer_5_mo':series['racer_5_mo'],\n",
    "                                'racer_6_bo':series['racer_6_bo'],\n",
    "                                'racer_6_mo':series['racer_6_mo'],\n",
    "                                'racer_1_age':racer_1_df.iat[0,3],\n",
    "                                'racer_1_ave_st':racer_1_df.iat[0,5],\n",
    "                                'racer_1_doub':racer_1_df.iat[0,4],\n",
    "                                'racer_1_rank':racer_1_df.iat[0,1],\n",
    "                                'racer_1_male':racer_1_df.iat[0,2],\n",
    "\n",
    "                                'racer_2_age':racer_2_df.iat[0,3],\n",
    "                                'racer_2_ave_st':racer_2_df.iat[0,5],\n",
    "                                'racer_2_doub':racer_2_df.iat[0,4],\n",
    "                                'racer_2_rank':racer_2_df.iat[0,1],\n",
    "                                'racer_2_male':racer_2_df.iat[0,2],\n",
    "\n",
    "                                'racer_3_age':racer_3_df.iat[0,3],\n",
    "                                'racer_3_ave_st':racer_3_df.iat[0,5],\n",
    "                                'racer_3_doub':racer_3_df.iat[0,4],\n",
    "                                'racer_3_rank':racer_3_df.iat[0,1],\n",
    "                                'racer_3_male':racer_3_df.iat[0,2],\n",
    "\n",
    "                                'racer_4_age':racer_4_df.iat[0,3],\n",
    "                                'racer_4_ave_st':racer_4_df.iat[0,5],\n",
    "                                'racer_4_doub':racer_4_df.iat[0,4],\n",
    "                                'racer_4_rank':racer_4_df.iat[0,1],\n",
    "                                'racer_4_male':racer_4_df.iat[0,2],\n",
    "\n",
    "\n",
    "                                'racer_5_age':racer_5_df.iat[0,3],\n",
    "                                'racer_5_ave_st':racer_5_df.iat[0,5],\n",
    "                                'racer_5_doub':racer_5_df.iat[0,4],\n",
    "                                'racer_5_rank':racer_5_df.iat[0,1],\n",
    "                                'racer_5_male':racer_5_df.iat[0,2],\n",
    "\n",
    "                                'racer_6_age':racer_6_df.iat[0,3],\n",
    "                                'racer_6_ave_st':racer_6_df.iat[0,5],\n",
    "                                'racer_6_doub':racer_6_df.iat[0,4],\n",
    "                                'racer_6_rank':racer_6_df.iat[0,1],\n",
    "                                'racer_6_male':racer_6_df.iat[0,2] }, index=[''])\n",
    "        #//////////////////////////////データフレームにadd_dfを追加していく。\n",
    "        pred_race_df=pred_race_df.append(add_df)\n",
    "    #pred_race_df.to_csv('/content/drive/My Drive/pred_tool/asiya/start_list/{}_starts_asiya.csv'.format(date))\n",
    "    model_df=making_pred_df(pred_race_df)\n",
    "\n",
    "    #保存してあるモデルを読み込む(ついでに予測も行う)\n",
    "    #保存してあるモデルを読み込む(ついでに予測も行う)\n",
    "    #保存してあるモデルを読み込む(ついでに予測も行う)\n",
    "    #保存してあるモデルを読み込む(ついでに予測も行う)\n",
    "    num_race=np.arange(1,13,1)\n",
    "    model3 = pickle.load(open('former_pickle_data/model_com3_dep6_per121.sav', 'rb'))\n",
    "    model4 = pickle.load(open('former_pickle_data/model_com4_dep7_per131.sav', 'rb'))\n",
    "    model5 = pickle.load(open('former_pickle_data/model_com5_dep8_per122.sav', 'rb'))\n",
    "    model7 = pickle.load(open('former_pickle_data/model_com7_dep7_per146.sav', 'rb'))\n",
    "    model13 = pickle.load(open('former_pickle_data/model_com13_dep6_per115.sav', 'rb'))\n",
    "    model14= pickle.load(open('former_pickle_data/model_com14_dep4_per123.sav', 'rb'))\n",
    "    model3_pred=model3.predict_proba(model_df)\n",
    "    model4_pred=model4.predict_proba(model_df)\n",
    "    model5_pred=model5.predict_proba(model_df)\n",
    "    model7_pred=model7.predict_proba(model_df)\n",
    "    model13_pred=model13.predict_proba(model_df)\n",
    "    model14_pred=model14.predict_proba(model_df)\n",
    "    pred_3_df=pd.DataFrame({'num_race':num_race,\n",
    "                            'pred_3':[pred[1] for pred in model3_pred],\n",
    "                            'pred_4':[pred[1] for pred in model4_pred],\n",
    "                            'pred_5':[pred[1] for pred in model5_pred],\n",
    "                            'pred_7':[pred[1] for pred in model7_pred],\n",
    "                            'pred_13':[pred[1] for pred in model13_pred],\n",
    "                            'pred_14':[pred[1] for pred in model14_pred]\n",
    "                            })\n",
    "    #print(\"pred_day_url\",url)\n",
    "    return pred_3_df\n",
    "    #実際のレース結果の取得\n",
    "def daterange(_start, _end):\n",
    "    for n in range((_end - _start).days):\n",
    "        yield _start + timedelta(n)\n",
    "\n",
    "def making_pred_df(df):\n",
    "    pred_race_df=df\n",
    "  #pred_race_df=pred_race_df.drop([\"Unnamed: 0\"],axis=1)#csvファイルについている名無しの列を削除\n",
    "    result_df=pred_race_df\n",
    "    result_df=result_df.drop([\"racer_1_ID\",\"racer_2_ID\",\"racer_3_ID\",\"racer_4_ID\",\"racer_5_ID\",\"racer_6_ID\",],axis=1)#IDはいらないので削除\n",
    "    result_df=result_df.replace(0.0000,{\"racer_1_ave_st_time\":0.22})#新人のave_st_timeを0.22に\n",
    "    result_df=result_df.replace(0.0000,{\"racer_2_ave_st_time\":0.22})\n",
    "    result_df=result_df.replace(0.0000,{\"racer_3_ave_st_time\":0.22})\n",
    "    result_df=result_df.replace(0.0000,{\"racer_4_ave_st_time\":0.22})\n",
    "    result_df=result_df.replace(0.0000,{\"racer_5_ave_st_time\":0.22})\n",
    "    result_df=result_df.replace(0.0000,{\"racer_6_ave_st_time\":0.22})\n",
    "    result_df=result_df.replace(0.0000,{\"racer_1_doub_win\":0.02})#新人の着に絡む確率ave_st_timeを0.02に(新人の半期の偏差から導出)\n",
    "    result_df=result_df.replace(0.0000,{\"racer_2_doub_win\":0.02})\n",
    "    result_df=result_df.replace(0.0000,{\"racer_3_doub_win\":0.02})\n",
    "    result_df=result_df.replace(0.0000,{\"racer_4_doub_win\":0.02})\n",
    "    result_df=result_df.replace(0.0000,{\"racer_5_doub_win\":0.02})\n",
    "    result_df=result_df.replace(0.0000,{\"racer_6_doub_win\":0.02})\n",
    "  #ダミー変数化\n",
    "    result_df_dummie=result_df\n",
    "    race_dummie_df=pd.get_dummies(result_df_dummie['number_race'])#number_raceをダミー化\n",
    "    for column, val in race_dummie_df.iteritems():\n",
    "        result_df_dummie['race_{}'.format(int(column))]=val\n",
    "    result_df_dummie=result_df_dummie.drop('number_race',axis=1)\n",
    "\n",
    "    cols=list(result_df_dummie.columns)\n",
    "    male_cols=[s for s in cols if 'male' in s]#性別を示すカラムを取り出す\n",
    "\n",
    "  #===========================新規、性別の取り出し機能が良くなかったため作り直す\n",
    "    empty_arr=[0]*len(result_df_dummie)\n",
    "    for col in male_cols:\n",
    "        for number in np.arange(0,2,1):\n",
    "            result_df_dummie['{}_{}'.format(col,int(number))]=empty_arr\n",
    "        male_dummie_df=pd.get_dummies(result_df_dummie[col])#性別をダミー化\n",
    "        for column, val in male_dummie_df.iteritems():\n",
    "            result_df_dummie['{}_{}'.format(col,int(column))]=val\n",
    "        result_df_dummie=result_df_dummie.drop('{}'.format(col),axis=1)\n",
    "    \n",
    "    cols=list(result_df_dummie.columns)\n",
    "    moter_cols=[s for s in cols if '_mo' in s]#モーター番号を示すカラムを取り出す\n",
    "    boat_cols=[s for s in cols if '_bo' in s]#ボート番号を示すカラムを取り出す\n",
    "    #boat もmoterも番号は1~99とする\n",
    "    numbers=np.arange(1, 100, 1)\n",
    "    empty_arr=[0]*len(result_df_dummie)\n",
    "    for col in moter_cols:\n",
    "        for number in numbers:\n",
    "            result_df_dummie['{}_{}'.format(col,int(number))]=empty_arr\n",
    "        moter_dummie_df=pd.get_dummies(result_df_dummie[col])#モータ番号をダミー化\n",
    "        for column, val in moter_dummie_df.iteritems():\n",
    "            result_df_dummie['{}_{}'.format(col,int(column))]=val\n",
    "        result_df_dummie=result_df_dummie.drop('{}'.format(col),axis=1)\n",
    "\n",
    "  #boat番号をダミー化\n",
    "    for col in boat_cols:\n",
    "        for number in numbers:\n",
    "            result_df_dummie['{}_{}'.format(col,int(number))]=empty_arr\n",
    "        boat_dummie_df=pd.get_dummies(result_df_dummie[col])#boat番号をダミー化\n",
    "        for column, val in boat_dummie_df.iteritems():\n",
    "            result_df_dummie['{}_{}'.format(col,int(column))]=val\n",
    "        result_df_dummie=result_df_dummie.drop('{}'.format(col),axis=1)\n",
    "    result_df=result_df_dummie\n",
    "\n",
    "\n",
    "\n",
    "  #クラスタリング\n",
    "  #分けてみるクラスタの数は[8,10]の2個\n",
    "  #cluster_target_df　　trainのデータからリザルトと配当金を取り除いたもの\n",
    "    target_num_cluster=[8,10]\n",
    "  #test_clustaring_df=train_has_PCA_df\n",
    "    clustar_target_df=result_df\n",
    "    clustaring_df=clustar_target_df\n",
    "    for num_cluster in target_num_cluster:\n",
    "        pred = KMeans(n_clusters=num_cluster).fit_predict(clustar_target_df)\n",
    "        clustaring_df['num={}'.format(num_cluster)]=pred\n",
    "\n",
    "    model_df=clustaring_df\n",
    "\n",
    "    return model_df\n",
    "\n",
    "def calc_gain(place_num,date):#日付と会場番号をわた洗馬その日のレース結果を返してくれる関数\n",
    "    results=[]\n",
    "    returns=[]\n",
    "    for i in range(12):\n",
    "        rno=i+1\n",
    "        #まず初めに１ページの情報を抜き出す機能\n",
    "        url='http://www.boatrace.jp/owpc/pc/race/raceresult?rno={rno}&jcd={place_num}&hd={date}'.format(rno=rno,place_num=place_num,date=date)\n",
    "        response=requests.get(url)#対象のURLをget\n",
    "        response.encoding = response.apparent_encoding\n",
    "        result_page=bs4(response.text, 'html.parser')\n",
    "        #レース結果格納\n",
    "        result_dev=result_page.select_one(\".numberSet1_row\")\n",
    "        result_com_arr=[result_dev.select(\".numberSet1_number\")[0].string,result_dev.select(\".numberSet1_number\")[1].string,result_dev.select(\".numberSet1_number\")[2].string]\n",
    "        result_com=undo_trans_com(result_com_arr)\n",
    "        #配当金\n",
    "        return_money=result_page.select_one(\".is-payout1\").string\n",
    "        return_money=str(return_money).replace(\"¥\",'')\n",
    "        return_money=str(return_money).replace(\",\",'')\n",
    "        results.append(result_com)\n",
    "        returns.append(return_money)\n",
    "        time.sleep(1)\n",
    "    result_df=pd.DataFrame({'num_race':np.arange(1,13),\n",
    "                  'result_coms':results,\n",
    "                  'return_money':returns})\n",
    "    #print(\"get_result_url\",url)\n",
    "    return result_df\n",
    "\n",
    "        \n",
    "def pred_race_former_asiya_proba_2020(date):\n",
    "    race_df=pd.DataFrame(index=[], columns=[])\n",
    "    for i in range(12):\n",
    "        rno=i+1\n",
    "        #まず初めに１ページの情報を抜き出す機能\n",
    "        url='http://www.boatrace.jp/owpc/pc/race/racelist?rno={}&jcd=21&hd={}'.format(rno,date)\n",
    "        response=requests.get(url)#対象のURLをget\n",
    "        response.encoding = response.apparent_encoding\n",
    "        start_page=bs4(response.text, 'html.parser')\n",
    "        racers_div=start_page.select_one(\".is-tableFixed__3rdadd\")\n",
    "        racers_sep_row=racers_div.find_all('tbody') \n",
    "        index=0\n",
    "        race_racers_data=[0]*6\n",
    "        if len(racers_sep_row)==6:\n",
    "            for racer_html in racers_sep_row:\n",
    "                racer_row_ex_td=racer_html.find_all('td')\n",
    "                #選手の登録ID\n",
    "                racer_ID_div=racer_row_ex_td[2].find_all('div')\n",
    "                racer_ID_div=racer_ID_div[0]\n",
    "                racer_ID_div_txt=racer_ID_div.text\n",
    "                start=(racer_ID_div_txt.find('/'))-35\n",
    "                end=(racer_ID_div_txt.find('/')-31)\n",
    "                #racer_ID=racer_ID_div_txt[start:end]#選手の登録ID\n",
    "                racer_ID=racer_ID_div_txt.split('\\n')[0]\n",
    "\n",
    "                #選手のモータ番号\n",
    "                racer_moter_td=racer_row_ex_td[6]\n",
    "                racer_moter_td_text=racer_moter_td.text\n",
    "                #racer_moter_split=racer_moter_td_text.split('\\r')\n",
    "                racer_moter_split=racer_moter_td_text.split('\\n')\n",
    "                #racer_moter_id=racer_moter_split[1][-2:]\n",
    "                racer_moter_id=racer_moter_split[0]\n",
    "                #選手のボート番号\n",
    "                racer_boat_td=racer_row_ex_td[7]\n",
    "                racer_boat_td_text=racer_boat_td.text\n",
    "    #             racer_boat_split=racer_boat_td_text.split('\\r')\n",
    "    #             racer_boat_id=racer_boat_split[1][-2:]\n",
    "                racer_boat_split=racer_boat_td_text.split('\\n')\n",
    "                racer_boat_id=racer_boat_split[0]\n",
    "\n",
    "                racer_data=[racer_ID,racer_moter_id,racer_boat_id]#選手固有のデータを持ったリスト\n",
    "\n",
    "                race_racers_data[index]=racer_data\n",
    "                index+=1\n",
    "        else:\n",
    "            print('欠場選手等の例外が発生していないか確認してください')\n",
    "        #race_racers_dataを一行に変換する\n",
    "        race_row=pd.Series(index=[])#一レースの情報を一行に変換したもの\n",
    "        race_num=rno#ここにはレース番号を入れる変数の値を代入\n",
    "        race_row['number_race']=race_num\n",
    "        for i in range(len(race_racers_data)):\n",
    "            race_row['racer_{}_ID'.format(i+1)]=int(race_racers_data[i][0])\n",
    "            race_row['racer_{}_mo'.format(i+1)]=int(race_racers_data[i][1])\n",
    "            race_row['racer_{}_bo'.format(i+1)]=int(race_racers_data[i][2])\n",
    "        race_df=race_df.append(race_row,ignore_index=True)\n",
    "\n",
    "\n",
    "    ### 学習データと保存してある選手パラメータを結合する\n",
    "    ### 学習データと保存してある選手パラメータを結合する\n",
    "    ### 学習データと保存してある選手パラメータを結合する\n",
    "\n",
    "    #使用するファイルの定義\n",
    "    para_file='22'\n",
    "    para_file_path=\"../../bot_database/racer_para/{}/{}.csv\".format(para_file,para_file)\n",
    "    #/content/drive/My Drive/boatrace_BOT_making/pred_tool/racer_pala_box/20.csv\n",
    "    #result_file_path=\"asiya_result_csv/asiya_result_20{0}.csv\".format(year)\n",
    "    #write_path=\"/content/drive/My Drive/pred_tool/asiya/pred_data/{0}_asiya.csv\".format(date)\n",
    "    #/////////////////////////////////////////////以下データフレームの作成\n",
    "    para_df=pd.read_csv(para_file_path)\n",
    "    para_df=para_df.drop([\"Unnamed: 0\"],axis=1)#csvファイルについている名無しの列を削除\n",
    "    #出力用データフレーム\n",
    "    #pred_race_df=pd.DataFrame(columns=['result_com','number_race','racer_1_ID','racer_2_ID','racer_3_ID','racer_4_ID','racer_5_ID','racer_6_ID','racer_1_rank','racer_1_male','racer_1_age','racer_1_doub','racer_1_ave_st','racer_2_rank','racer_2_male','racer_2_age','racer_2_doub','racer_2_ave_st','racer_3_rank','racer_3_male','racer_3_age','racer_3_doub','racer_3_ave_st','racer_4_rank','racer_4_male','racer_4_age','racer_4_doub','racer_4_ave_st','racer_5_rank','racer_5_male','racer_5_age','racer_5_doub','racer_5_ave_st','racer_6_rank','racer_6_male','racer_6_age','racer_6_doub','racer_6_ave_st'])\n",
    "    pred_race_df=pd.DataFrame(columns=[],index=[])\n",
    "    for index,series in race_df.iterrows():\n",
    "        add_df=pd.DataFrame(columns=['number_race','racer_1_ID','racer_2_ID','racer_3_ID','racer_4_ID','racer_5_ID','racer_6_ID','racer_1_rank','racer_1_male','racer_1_age','racer_1_doub','racer_1_ave_st','racer_2_rank','racer_2_male','racer_2_age','racer_2_doub','racer_2_ave_st','racer_3_rank','racer_3_male','racer_3_age','racer_3_doub','racer_3_ave_st','racer_4_rank','racer_4_male','racer_4_age','racer_4_doub','racer_4_ave_st','racer_5_rank','racer_5_male','racer_5_age','racer_5_doub','racer_5_ave_st','racer_6_rank','racer_6_male','racer_6_age','racer_6_doub','racer_6_ave_st'])\n",
    "        #///////////////////////////////////////レースに出ているレーサーの成績を検索＆取得\n",
    "        ID_1=series['racer_1_ID']\n",
    "        ID_2=series['racer_2_ID']\n",
    "        ID_3=series['racer_3_ID']\n",
    "        ID_4=series['racer_4_ID']\n",
    "        ID_5=series['racer_5_ID']\n",
    "        ID_6=series['racer_6_ID']\n",
    "        racer_1_df=para_df[para_df['racer_ID']==ID_1]\n",
    "        racer_2_df=para_df[para_df['racer_ID']==ID_2]\n",
    "        racer_3_df=para_df[para_df['racer_ID']==ID_3]\n",
    "        racer_4_df=para_df[para_df['racer_ID']==ID_4]\n",
    "        racer_5_df=para_df[para_df['racer_ID']==ID_5]\n",
    "        racer_6_df=para_df[para_df['racer_ID']==ID_6]\n",
    "        if len(racer_1_df)==1:\n",
    "            pass\n",
    "        else:\n",
    "            racer_1_df=para_df[(para_df['racer_doub_win']==0.00) & (para_df['racer_ave_st_time']==0.00)]\n",
    "            print('CAREFULL!!!!    NOT FOUND RACER ')\n",
    "\n",
    "        if len(racer_2_df)==1:\n",
    "            pass\n",
    "        else:\n",
    "            racer_2_df=para_df[(para_df['racer_doub_win']==0.00) & (para_df['racer_ave_st_time']==0.00)]\n",
    "            print('CAREFULL!!!!    NOT FOUND RACER ')\n",
    "\n",
    "        if len(racer_3_df)==1:\n",
    "            pass\n",
    "        else:\n",
    "            racer_3_df=para_df[(para_df['racer_doub_win']==0.00) & (para_df['racer_ave_st_time']==0.00)]\n",
    "            print('CAREFULL!!!!    NOT FOUND RACER ')\n",
    "\n",
    "        if len(racer_4_df)==1:\n",
    "            pass\n",
    "        else:\n",
    "            racer_4_df=para_df[(para_df['racer_doub_win']==0.00) & (para_df['racer_ave_st_time']==0.00)]\n",
    "            print('CAREFULL!!!!    NOT FOUND RACER ')\n",
    "\n",
    "        if len(racer_5_df)==1:\n",
    "            pass\n",
    "        else:\n",
    "            racer_5_df=para_df[(para_df['racer_doub_win']==0.00) & (para_df['racer_ave_st_time']==0.00)]\n",
    "            print('CAREFULL!!!!    NOT FOUND RACER ')\n",
    "\n",
    "\n",
    "        if len(racer_6_df)==1:\n",
    "            pass\n",
    "        else:\n",
    "            racer_6_df=para_df[(para_df['racer_doub_win']==0.00) & (para_df['racer_ave_st_time']==0.00)]\n",
    "            print('CAREFULL!!!!    NOT FOUND RACER ')\n",
    "\n",
    "        #追加していくデータフレームを作成\n",
    "        add_df= pd.DataFrame({'number_race':series['number_race'],\n",
    "                              'racer_1_ID':series['racer_1_ID'],\n",
    "                                'racer_2_ID':series['racer_2_ID'],\n",
    "                                'racer_3_ID':series['racer_3_ID'],\n",
    "                                'racer_4_ID':series['racer_4_ID'],\n",
    "                                'racer_5_ID':series['racer_5_ID'],\n",
    "                                'racer_6_ID':series['racer_6_ID'],\n",
    "                                'racer_1_bo':series['racer_1_bo'],\n",
    "                                'racer_1_mo':series['racer_1_mo'],\n",
    "                                'racer_2_bo':series['racer_2_bo'],\n",
    "                                'racer_2_mo':series['racer_2_mo'],\n",
    "                                'racer_3_bo':series['racer_3_bo'],\n",
    "                                'racer_3_mo':series['racer_3_mo'],\n",
    "                                'racer_4_bo':series['racer_4_bo'],\n",
    "                                'racer_4_mo':series['racer_4_mo'],\n",
    "                                'racer_5_bo':series['racer_5_bo'],\n",
    "                                'racer_5_mo':series['racer_5_mo'],\n",
    "                                'racer_6_bo':series['racer_6_bo'],\n",
    "                                'racer_6_mo':series['racer_6_mo'],\n",
    "                                'racer_1_age':racer_1_df.iat[0,3],\n",
    "                                'racer_1_ave_st':racer_1_df.iat[0,5],\n",
    "                                'racer_1_doub':racer_1_df.iat[0,4],\n",
    "                                'racer_1_rank':racer_1_df.iat[0,1],\n",
    "                                'racer_1_male':racer_1_df.iat[0,2],\n",
    "\n",
    "                                'racer_2_age':racer_2_df.iat[0,3],\n",
    "                                'racer_2_ave_st':racer_2_df.iat[0,5],\n",
    "                                'racer_2_doub':racer_2_df.iat[0,4],\n",
    "                                'racer_2_rank':racer_2_df.iat[0,1],\n",
    "                                'racer_2_male':racer_2_df.iat[0,2],\n",
    "\n",
    "                                'racer_3_age':racer_3_df.iat[0,3],\n",
    "                                'racer_3_ave_st':racer_3_df.iat[0,5],\n",
    "                                'racer_3_doub':racer_3_df.iat[0,4],\n",
    "                                'racer_3_rank':racer_3_df.iat[0,1],\n",
    "                                'racer_3_male':racer_3_df.iat[0,2],\n",
    "\n",
    "                                'racer_4_age':racer_4_df.iat[0,3],\n",
    "                                'racer_4_ave_st':racer_4_df.iat[0,5],\n",
    "                                'racer_4_doub':racer_4_df.iat[0,4],\n",
    "                                'racer_4_rank':racer_4_df.iat[0,1],\n",
    "                                'racer_4_male':racer_4_df.iat[0,2],\n",
    "\n",
    "\n",
    "                                'racer_5_age':racer_5_df.iat[0,3],\n",
    "                                'racer_5_ave_st':racer_5_df.iat[0,5],\n",
    "                                'racer_5_doub':racer_5_df.iat[0,4],\n",
    "                                'racer_5_rank':racer_5_df.iat[0,1],\n",
    "                                'racer_5_male':racer_5_df.iat[0,2],\n",
    "\n",
    "                                'racer_6_age':racer_6_df.iat[0,3],\n",
    "                                'racer_6_ave_st':racer_6_df.iat[0,5],\n",
    "                                'racer_6_doub':racer_6_df.iat[0,4],\n",
    "                                'racer_6_rank':racer_6_df.iat[0,1],\n",
    "                                'racer_6_male':racer_6_df.iat[0,2] }, index=[''])\n",
    "        #//////////////////////////////データフレームにadd_dfを追加していく。\n",
    "        pred_race_df=pred_race_df.append(add_df)\n",
    "    #pred_race_df.to_csv('/content/drive/My Drive/pred_tool/asiya/start_list/{}_starts_asiya.csv'.format(date))\n",
    "    model_df=making_pred_df(pred_race_df)\n",
    "\n",
    "    #保存してあるモデルを読み込む(ついでに予測も行う)\n",
    "    #保存してあるモデルを読み込む(ついでに予測も行う)\n",
    "    #保存してあるモデルを読み込む(ついでに予測も行う)\n",
    "    #保存してあるモデルを読み込む(ついでに予測も行う)\n",
    "    num_race=np.arange(1,13,1)\n",
    "    model3 = pickle.load(open('former_pickle_data/model_com3_dep6_per121.sav', 'rb'))\n",
    "    model4 = pickle.load(open('former_pickle_data/model_com4_dep7_per131.sav', 'rb'))\n",
    "    model5 = pickle.load(open('former_pickle_data/model_com5_dep8_per122.sav', 'rb'))\n",
    "    model7 = pickle.load(open('former_pickle_data/model_com7_dep7_per146.sav', 'rb'))\n",
    "    model13 = pickle.load(open('former_pickle_data/model_com13_dep6_per115.sav', 'rb'))\n",
    "    model14= pickle.load(open('former_pickle_data/model_com14_dep4_per123.sav', 'rb'))\n",
    "    model3_pred=model3.predict_proba(model_df)\n",
    "    model4_pred=model4.predict_proba(model_df)\n",
    "    model5_pred=model5.predict_proba(model_df)\n",
    "    model7_pred=model7.predict_proba(model_df)\n",
    "    model13_pred=model13.predict_proba(model_df)\n",
    "    model14_pred=model14.predict_proba(model_df)\n",
    "    pred_3_df=pd.DataFrame({'num_race':num_race,\n",
    "                            'pred_3':[pred[1] for pred in model3_pred],\n",
    "                            'pred_4':[pred[1] for pred in model4_pred],\n",
    "                            'pred_5':[pred[1] for pred in model5_pred],\n",
    "                            'pred_7':[pred[1] for pred in model7_pred],\n",
    "                            'pred_13':[pred[1] for pred in model13_pred],\n",
    "                            'pred_14':[pred[1] for pred in model14_pred]\n",
    "                            })\n",
    "    #print(\"pred_day_url\",url)\n",
    "    return pred_3_df\n",
    "    #実際のレース結果の取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "suitable-reconstruction",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-a52e8aa05b0d>:208: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  pred_race_df=pred_race_df.append(add_df)\n",
      "<ipython-input-7-a52e8aa05b0d>:208: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  pred_race_df=pred_race_df.append(add_df)\n",
      "<ipython-input-7-a52e8aa05b0d>:208: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  pred_race_df=pred_race_df.append(add_df)\n",
      "<ipython-input-7-a52e8aa05b0d>:208: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  pred_race_df=pred_race_df.append(add_df)\n",
      "<ipython-input-7-a52e8aa05b0d>:208: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  pred_race_df=pred_race_df.append(add_df)\n",
      "<ipython-input-7-a52e8aa05b0d>:208: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  pred_race_df=pred_race_df.append(add_df)\n",
      "<ipython-input-7-a52e8aa05b0d>:208: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  pred_race_df=pred_race_df.append(add_df)\n",
      "<ipython-input-7-a52e8aa05b0d>:208: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  pred_race_df=pred_race_df.append(add_df)\n",
      "<ipython-input-7-a52e8aa05b0d>:208: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  pred_race_df=pred_race_df.append(add_df)\n",
      "<ipython-input-7-a52e8aa05b0d>:208: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  pred_race_df=pred_race_df.append(add_df)\n",
      "<ipython-input-7-a52e8aa05b0d>:208: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  pred_race_df=pred_race_df.append(add_df)\n",
      "<ipython-input-7-a52e8aa05b0d>:208: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  pred_race_df=pred_race_df.append(add_df)\n",
      "<ipython-input-2-7b2f5552d06e>:264: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df_dummie['{}_{}'.format(col,int(number))]=empty_arr\n",
      "<ipython-input-2-7b2f5552d06e>:264: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df_dummie['{}_{}'.format(col,int(number))]=empty_arr\n",
      "<ipython-input-2-7b2f5552d06e>:264: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df_dummie['{}_{}'.format(col,int(number))]=empty_arr\n",
      "<ipython-input-2-7b2f5552d06e>:264: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df_dummie['{}_{}'.format(col,int(number))]=empty_arr\n",
      "<ipython-input-2-7b2f5552d06e>:264: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df_dummie['{}_{}'.format(col,int(number))]=empty_arr\n",
      "<ipython-input-2-7b2f5552d06e>:264: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df_dummie['{}_{}'.format(col,int(number))]=empty_arr\n",
      "<ipython-input-2-7b2f5552d06e>:264: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df_dummie['{}_{}'.format(col,int(number))]=empty_arr\n",
      "<ipython-input-2-7b2f5552d06e>:264: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df_dummie['{}_{}'.format(col,int(number))]=empty_arr\n",
      "<ipython-input-2-7b2f5552d06e>:264: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df_dummie['{}_{}'.format(col,int(number))]=empty_arr\n",
      "<ipython-input-2-7b2f5552d06e>:264: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df_dummie['{}_{}'.format(col,int(number))]=empty_arr\n",
      "<ipython-input-2-7b2f5552d06e>:264: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df_dummie['{}_{}'.format(col,int(number))]=empty_arr\n",
      "<ipython-input-2-7b2f5552d06e>:264: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df_dummie['{}_{}'.format(col,int(number))]=empty_arr\n",
      "<ipython-input-2-7b2f5552d06e>:273: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df_dummie['{}_{}'.format(col,int(number))]=empty_arr\n",
      "<ipython-input-2-7b2f5552d06e>:273: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df_dummie['{}_{}'.format(col,int(number))]=empty_arr\n",
      "<ipython-input-2-7b2f5552d06e>:273: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df_dummie['{}_{}'.format(col,int(number))]=empty_arr\n",
      "<ipython-input-2-7b2f5552d06e>:273: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df_dummie['{}_{}'.format(col,int(number))]=empty_arr\n",
      "<ipython-input-2-7b2f5552d06e>:273: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df_dummie['{}_{}'.format(col,int(number))]=empty_arr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-7b2f5552d06e>:273: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df_dummie['{}_{}'.format(col,int(number))]=empty_arr\n",
      "<ipython-input-2-7b2f5552d06e>:273: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df_dummie['{}_{}'.format(col,int(number))]=empty_arr\n",
      "<ipython-input-2-7b2f5552d06e>:273: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df_dummie['{}_{}'.format(col,int(number))]=empty_arr\n",
      "<ipython-input-2-7b2f5552d06e>:273: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df_dummie['{}_{}'.format(col,int(number))]=empty_arr\n",
      "<ipython-input-2-7b2f5552d06e>:273: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df_dummie['{}_{}'.format(col,int(number))]=empty_arr\n",
      "<ipython-input-2-7b2f5552d06e>:273: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df_dummie['{}_{}'.format(col,int(number))]=empty_arr\n",
      "<ipython-input-2-7b2f5552d06e>:273: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df_dummie['{}_{}'.format(col,int(number))]=empty_arr\n"
     ]
    }
   ],
   "source": [
    "# date='20210103'#日付を入力\n",
    "\n",
    "# start = datetime.strptime('20210101', '%Y%m%d').date()\n",
    "# end   = datetime.strptime('20211231', '%Y%m%d').date()\n",
    "# start = datetime.strptime('20200101', '%Y%m%d').date()#2020分で検証\n",
    "# end   = datetime.strptime('20201231', '%Y%m%d').date()\n",
    "# start = datetime.strptime('20220101', '%Y%m%d').date()#2022分で検証\n",
    "# end   = datetime.strptime('20220430', '%Y%m%d').date()\n",
    "use_get_df=pd.DataFrame()\n",
    "# for date_i in daterange(start, end):\n",
    "#     date_str=date_i.strftime('%Y%m%d')\n",
    "#     try:\n",
    "date_i = datetime.strptime('2022-01-06', '%Y-%m-%d').date()#2020分で検証\n",
    "date_str=date_i.strftime('%Y%m%d')\n",
    "#pred_df=pred_race_former_asiya_proba(date_str)\n",
    "#pred_df=pred_race_former_asiya_proba_2020(date_str)\n",
    "date=date_str\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# race_df=pd.DataFrame(index=[], columns=[])\n",
    "# for i in range(12):\n",
    "#     rno=i+1\n",
    "#     #まず初めに１ページの情報を抜き出す機能\n",
    "#     url='http://www.boatrace.jp/owpc/pc/race/racelist?rno={}&jcd=21&hd={}'.format(rno,date)\n",
    "#     response=requests.get(url)#対象のURLをget\n",
    "#     response.encoding = response.apparent_encoding\n",
    "#     start_page=bs4(response.text, 'html.parser')\n",
    "#     racers_div=start_page.select_one(\".is-tableFixed__3rdadd\")\n",
    "#     racers_sep_row=racers_div.find_all('tbody') \n",
    "#     index=0\n",
    "#     race_racers_data=[0]*6\n",
    "#     if len(racers_sep_row)==6:\n",
    "#         for racer_html in racers_sep_row:\n",
    "#             racer_row_ex_td=racer_html.find_all('td')\n",
    "#             #選手の登録ID\n",
    "#             racer_ID_div=racer_row_ex_td[2].find_all('div')\n",
    "#             racer_ID_div=racer_ID_div[0]\n",
    "#             racer_ID_div_txt=racer_ID_div.text\n",
    "#             start=(racer_ID_div_txt.find('/'))-35\n",
    "#             end=(racer_ID_div_txt.find('/')-31)\n",
    "#             #racer_ID=racer_ID_div_txt[start:end]#選手の登録ID\n",
    "#             racer_ID=racer_ID_div_txt.split('\\n')[0]\n",
    "\n",
    "#             #選手のモータ番号\n",
    "#             racer_moter_td=racer_row_ex_td[6]\n",
    "#             racer_moter_td_text=racer_moter_td.text\n",
    "#             #racer_moter_split=racer_moter_td_text.split('\\r')\n",
    "#             racer_moter_split=racer_moter_td_text.split('\\n')\n",
    "#             #racer_moter_id=racer_moter_split[1][-2:]\n",
    "#             racer_moter_id=racer_moter_split[0]\n",
    "#             #選手のボート番号\n",
    "#             racer_boat_td=racer_row_ex_td[7]\n",
    "#             racer_boat_td_text=racer_boat_td.text\n",
    "# #             racer_boat_split=racer_boat_td_text.split('\\r')\n",
    "# #             racer_boat_id=racer_boat_split[1][-2:]\n",
    "#             racer_boat_split=racer_boat_td_text.split('\\n')\n",
    "#             racer_boat_id=racer_boat_split[0]\n",
    "\n",
    "#             racer_data=[racer_ID,racer_moter_id,racer_boat_id]#選手固有のデータを持ったリスト\n",
    "\n",
    "#             race_racers_data[index]=racer_data\n",
    "#             index+=1\n",
    "#     else:\n",
    "#         print('欠場選手等の例外が発生していないか確認してください')\n",
    "#     #race_racers_dataを一行に変換する\n",
    "#     race_row=pd.Series(index=[])#一レースの情報を一行に変換したもの\n",
    "#     race_num=rno#ここにはレース番号を入れる変数の値を代入\n",
    "#     race_row['number_race']=race_num\n",
    "#     for i in range(len(race_racers_data)):\n",
    "#         race_row['racer_{}_ID'.format(i+1)]=int(race_racers_data[i][0])\n",
    "#         race_row['racer_{}_mo'.format(i+1)]=int(race_racers_data[i][1])\n",
    "#         race_row['racer_{}_bo'.format(i+1)]=int(race_racers_data[i][2])\n",
    "#     race_df=race_df.append(race_row,ignore_index=True)\n",
    "\n",
    "\n",
    "### 学習データと保存してある選手パラメータを結合する\n",
    "### 学習データと保存してある選手パラメータを結合する\n",
    "### 学習データと保存してある選手パラメータを結合する\n",
    "\n",
    "#使用するファイルの定義\n",
    "para_file='22'\n",
    "para_file_path=\"../../bot_database/racer_para/{}/{}.csv\".format(para_file,para_file)\n",
    "#/content/drive/My Drive/boatrace_BOT_making/pred_tool/racer_pala_box/20.csv\n",
    "#result_file_path=\"asiya_result_csv/asiya_result_20{0}.csv\".format(year)\n",
    "#write_path=\"/content/drive/My Drive/pred_tool/asiya/pred_data/{0}_asiya.csv\".format(date)\n",
    "#/////////////////////////////////////////////以下データフレームの作成\n",
    "para_df=pd.read_csv(para_file_path)\n",
    "para_df=para_df.drop([\"Unnamed: 0\"],axis=1)#csvファイルについている名無しの列を削除\n",
    "#出力用データフレーム\n",
    "#pred_race_df=pd.DataFrame(columns=['result_com','number_race','racer_1_ID','racer_2_ID','racer_3_ID','racer_4_ID','racer_5_ID','racer_6_ID','racer_1_rank','racer_1_male','racer_1_age','racer_1_doub','racer_1_ave_st','racer_2_rank','racer_2_male','racer_2_age','racer_2_doub','racer_2_ave_st','racer_3_rank','racer_3_male','racer_3_age','racer_3_doub','racer_3_ave_st','racer_4_rank','racer_4_male','racer_4_age','racer_4_doub','racer_4_ave_st','racer_5_rank','racer_5_male','racer_5_age','racer_5_doub','racer_5_ave_st','racer_6_rank','racer_6_male','racer_6_age','racer_6_doub','racer_6_ave_st'])\n",
    "pred_race_df=pd.DataFrame(columns=[],index=[])\n",
    "for index,series in race_df.iterrows():\n",
    "    add_df=pd.DataFrame(columns=['number_race','racer_1_ID','racer_2_ID','racer_3_ID','racer_4_ID','racer_5_ID','racer_6_ID','racer_1_rank','racer_1_male','racer_1_age','racer_1_doub','racer_1_ave_st','racer_2_rank','racer_2_male','racer_2_age','racer_2_doub','racer_2_ave_st','racer_3_rank','racer_3_male','racer_3_age','racer_3_doub','racer_3_ave_st','racer_4_rank','racer_4_male','racer_4_age','racer_4_doub','racer_4_ave_st','racer_5_rank','racer_5_male','racer_5_age','racer_5_doub','racer_5_ave_st','racer_6_rank','racer_6_male','racer_6_age','racer_6_doub','racer_6_ave_st'])\n",
    "    #///////////////////////////////////////レースに出ているレーサーの成績を検索＆取得\n",
    "    ID_1=series['racer_1_ID']\n",
    "    ID_2=series['racer_2_ID']\n",
    "    ID_3=series['racer_3_ID']\n",
    "    ID_4=series['racer_4_ID']\n",
    "    ID_5=series['racer_5_ID']\n",
    "    ID_6=series['racer_6_ID']\n",
    "    racer_1_df=para_df[para_df['racer_ID']==ID_1]\n",
    "    racer_2_df=para_df[para_df['racer_ID']==ID_2]\n",
    "    racer_3_df=para_df[para_df['racer_ID']==ID_3]\n",
    "    racer_4_df=para_df[para_df['racer_ID']==ID_4]\n",
    "    racer_5_df=para_df[para_df['racer_ID']==ID_5]\n",
    "    racer_6_df=para_df[para_df['racer_ID']==ID_6]\n",
    "    if len(racer_1_df)==1:\n",
    "        pass\n",
    "    else:\n",
    "        racer_1_df=para_df[(para_df['racer_doub_win']==0.00) & (para_df['racer_ave_st_time']==0.00)]\n",
    "        print('CAREFULL!!!!    NOT FOUND RACER ')\n",
    "\n",
    "    if len(racer_2_df)==1:\n",
    "        pass\n",
    "    else:\n",
    "        racer_2_df=para_df[(para_df['racer_doub_win']==0.00) & (para_df['racer_ave_st_time']==0.00)]\n",
    "        print('CAREFULL!!!!    NOT FOUND RACER ')\n",
    "\n",
    "    if len(racer_3_df)==1:\n",
    "        pass\n",
    "    else:\n",
    "        racer_3_df=para_df[(para_df['racer_doub_win']==0.00) & (para_df['racer_ave_st_time']==0.00)]\n",
    "        print('CAREFULL!!!!    NOT FOUND RACER ')\n",
    "\n",
    "    if len(racer_4_df)==1:\n",
    "        pass\n",
    "    else:\n",
    "        racer_4_df=para_df[(para_df['racer_doub_win']==0.00) & (para_df['racer_ave_st_time']==0.00)]\n",
    "        print('CAREFULL!!!!    NOT FOUND RACER ')\n",
    "\n",
    "    if len(racer_5_df)==1:\n",
    "        pass\n",
    "    else:\n",
    "        racer_5_df=para_df[(para_df['racer_doub_win']==0.00) & (para_df['racer_ave_st_time']==0.00)]\n",
    "        print('CAREFULL!!!!    NOT FOUND RACER ')\n",
    "\n",
    "\n",
    "    if len(racer_6_df)==1:\n",
    "        pass\n",
    "    else:\n",
    "        racer_6_df=para_df[(para_df['racer_doub_win']==0.00) & (para_df['racer_ave_st_time']==0.00)]\n",
    "        print('CAREFULL!!!!    NOT FOUND RACER ')\n",
    "\n",
    "    #追加していくデータフレームを作成\n",
    "    add_df= pd.DataFrame({'number_race':series['number_race'],\n",
    "                          'racer_1_ID':series['racer_1_ID'],\n",
    "                            'racer_2_ID':series['racer_2_ID'],\n",
    "                            'racer_3_ID':series['racer_3_ID'],\n",
    "                            'racer_4_ID':series['racer_4_ID'],\n",
    "                            'racer_5_ID':series['racer_5_ID'],\n",
    "                            'racer_6_ID':series['racer_6_ID'],\n",
    "                            'racer_1_bo':series['racer_1_bo'],\n",
    "                            'racer_1_mo':series['racer_1_mo'],\n",
    "                            'racer_2_bo':series['racer_2_bo'],\n",
    "                            'racer_2_mo':series['racer_2_mo'],\n",
    "                            'racer_3_bo':series['racer_3_bo'],\n",
    "                            'racer_3_mo':series['racer_3_mo'],\n",
    "                            'racer_4_bo':series['racer_4_bo'],\n",
    "                            'racer_4_mo':series['racer_4_mo'],\n",
    "                            'racer_5_bo':series['racer_5_bo'],\n",
    "                            'racer_5_mo':series['racer_5_mo'],\n",
    "                            'racer_6_bo':series['racer_6_bo'],\n",
    "                            'racer_6_mo':series['racer_6_mo'],\n",
    "                            'racer_1_age':racer_1_df.iat[0,3],\n",
    "                            'racer_1_ave_st':racer_1_df.iat[0,5],\n",
    "                            'racer_1_doub':racer_1_df.iat[0,4],\n",
    "                            'racer_1_rank':racer_1_df.iat[0,1],\n",
    "                            'racer_1_male':racer_1_df.iat[0,2],\n",
    "\n",
    "                            'racer_2_age':racer_2_df.iat[0,3],\n",
    "                            'racer_2_ave_st':racer_2_df.iat[0,5],\n",
    "                            'racer_2_doub':racer_2_df.iat[0,4],\n",
    "                            'racer_2_rank':racer_2_df.iat[0,1],\n",
    "                            'racer_2_male':racer_2_df.iat[0,2],\n",
    "\n",
    "                            'racer_3_age':racer_3_df.iat[0,3],\n",
    "                            'racer_3_ave_st':racer_3_df.iat[0,5],\n",
    "                            'racer_3_doub':racer_3_df.iat[0,4],\n",
    "                            'racer_3_rank':racer_3_df.iat[0,1],\n",
    "                            'racer_3_male':racer_3_df.iat[0,2],\n",
    "\n",
    "                            'racer_4_age':racer_4_df.iat[0,3],\n",
    "                            'racer_4_ave_st':racer_4_df.iat[0,5],\n",
    "                            'racer_4_doub':racer_4_df.iat[0,4],\n",
    "                            'racer_4_rank':racer_4_df.iat[0,1],\n",
    "                            'racer_4_male':racer_4_df.iat[0,2],\n",
    "\n",
    "\n",
    "                            'racer_5_age':racer_5_df.iat[0,3],\n",
    "                            'racer_5_ave_st':racer_5_df.iat[0,5],\n",
    "                            'racer_5_doub':racer_5_df.iat[0,4],\n",
    "                            'racer_5_rank':racer_5_df.iat[0,1],\n",
    "                            'racer_5_male':racer_5_df.iat[0,2],\n",
    "\n",
    "                            'racer_6_age':racer_6_df.iat[0,3],\n",
    "                            'racer_6_ave_st':racer_6_df.iat[0,5],\n",
    "                            'racer_6_doub':racer_6_df.iat[0,4],\n",
    "                            'racer_6_rank':racer_6_df.iat[0,1],\n",
    "                            'racer_6_male':racer_6_df.iat[0,2] }, index=[''])\n",
    "    #//////////////////////////////データフレームにadd_dfを追加していく。\n",
    "    pred_race_df=pred_race_df.append(add_df)\n",
    "#pred_race_df.to_csv('/content/drive/My Drive/pred_tool/asiya/start_list/{}_starts_asiya.csv'.format(date))\n",
    "model_df=making_pred_df(pred_race_df)\n",
    "\n",
    "# #保存してあるモデルを読み込む(ついでに予測も行う)\n",
    "# #保存してあるモデルを読み込む(ついでに予測も行う)\n",
    "# #保存してあるモデルを読み込む(ついでに予測も行う)\n",
    "# #保存してあるモデルを読み込む(ついでに予測も行う)\n",
    "num_race=np.arange(1,13,1)\n",
    "model3 = pickle.load(open('former_pickle_data/model_com3_dep6_per121.sav', 'rb'))\n",
    "model4 = pickle.load(open('former_pickle_data/model_com4_dep7_per131.sav', 'rb'))\n",
    "model5 = pickle.load(open('former_pickle_data/model_com5_dep8_per122.sav', 'rb'))\n",
    "model7 = pickle.load(open('former_pickle_data/model_com7_dep7_per146.sav', 'rb'))\n",
    "model13 = pickle.load(open('former_pickle_data/model_com13_dep6_per115.sav', 'rb'))\n",
    "model14= pickle.load(open('former_pickle_data/model_com14_dep4_per123.sav', 'rb'))\n",
    "model3_pred=model3.predict_proba(model_df)\n",
    "model4_pred=model4.predict_proba(model_df)\n",
    "model5_pred=model5.predict_proba(model_df)\n",
    "model7_pred=model7.predict_proba(model_df)\n",
    "model13_pred=model13.predict_proba(model_df)\n",
    "model14_pred=model14.predict_proba(model_df)\n",
    "pred_3_df=pd.DataFrame({'num_race':num_race,\n",
    "                        'pred_3':[pred[1] for pred in model3_pred],\n",
    "                        'pred_4':[pred[1] for pred in model4_pred],\n",
    "                        'pred_5':[pred[1] for pred in model5_pred],\n",
    "                        'pred_7':[pred[1] for pred in model7_pred],\n",
    "                        'pred_13':[pred[1] for pred in model13_pred],\n",
    "                        'pred_14':[pred[1] for pred in model14_pred]\n",
    "                        })\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# #result_df=calc_gain(21,date_str)\n",
    "# result_df=calc_gain(21,date_str)\n",
    "\n",
    "# day_race_df=pd.merge(pred_df, result_df, on='num_race')#予測の内容と配当金，レース結果を結合する\n",
    "# day_race_df['date']=date_i\n",
    "# use_get_df=pd.concat([use_get_df,day_race_df])\n",
    "#use_get_df=use_get_df.append(append_s,ignore_index=True)\n",
    "#display(use_get_df)\n",
    "#use_get_df.to_csv('test_csv/proba_get_use_2020.csv')\n",
    "#use_get_df.to_csv('test_csv/proba_get_use_2022.csv')\n",
    "#     except:\n",
    "#         print('eroor')\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "instant-event",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_3_df.to_csv('test_csv/check/check_1st.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virgin-stupid",
   "metadata": {},
   "source": [
    "# 二回目の，db書き込み機能を追加したもののprobaが全体的に低くなってるバージョン"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "durable-creation",
   "metadata": {
    "code_folding": [
     44,
     51,
     58,
     118,
     231,
     311,
     345,
     366,
     393,
     430,
     453,
     477,
     513,
     522,
     643
    ]
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn\n",
    "from pandas import DataFrame\n",
    "from tqdm import tqdm\n",
    "from imblearn.under_sampling import RandomUnderSampler #アンダーサンプリング用\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "# 機械学習用\n",
    "from sklearn.cluster import KMeans #クラスタリング用\n",
    "from sklearn.decomposition import PCA  #次元削減用\n",
    "from sklearn.ensemble import RandomForestClassifier#ランダムフォレスト\n",
    "from copy import deepcopy as cp\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "import time\n",
    "import datetime\n",
    "import os #ディレクトリ作成用\n",
    "import xgboost as xgb\n",
    "import sys\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine #書き込みのエンジンをpostgreに変えるのに使う。\n",
    "\n",
    "from datetime import date, timedelta\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from sklearn.preprocessing import StandardScaler#モデルの評価用に標準化する関数\n",
    "import scipy.stats#モデルの評価用に標準化する関数\n",
    "#必要なモジュールのインポート\n",
    "import chromedriver_binary\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from sklearn import preprocessing\n",
    "import requests #クローリングのためのモジュール\n",
    "from bs4 import BeautifulSoup as bs4#HTMLから特定の情報を抜き出すためのモジュール\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "#自作のモジュールのインポート\n",
    "\n",
    "def daterange(start, stop, step = timedelta(1)):#日付でfor文を回すためのジェネレータ\n",
    "    current = start\n",
    "    while current < stop:\n",
    "        yield current\n",
    "        current += step\n",
    "\n",
    "\n",
    "def pred_th_trans_com(pred_df,th,target_com):#指定の組のカラムのみを置換。\n",
    "    trans_df=pred_df.copy()\n",
    "    trans_df.loc[trans_df['pred_{}'.format(target_com)] >= th, 'pred_{}'.format(target_com)] = 1\n",
    "    trans_df.loc[~(trans_df['pred_{}'.format(target_com)] >=  th), 'pred_{}'.format(target_com)] = 0\n",
    "    return trans_df\n",
    "\n",
    "\n",
    "def startlist_making(date,place_num):#dateと開催場所を渡してスタートリストを作成する関数\n",
    "    #date='20210227'#日付を入力\n",
    "    race_df=pd.DataFrame(index=[], columns=[])\n",
    "    for i in range(12):\n",
    "        rno=i+1\n",
    "        #まず初めに１ページの情報を抜き出す機能\n",
    "        url='http://www.boatrace.jp/owpc/pc/race/racelist?rno={rno}&jcd={place_num}&hd={date}'.format(rno=rno,place_num=place_num,date=date)\n",
    "        response=requests.get(url)#対象のURLをget\n",
    "        #print(url)\n",
    "        response.encoding = response.apparent_encoding\n",
    "        start_page=bs4(response.text, 'html.parser')\n",
    "        racers_div=start_page.select_one(\".is-tableFixed__3rdadd\")\n",
    "        racers_sep_row=racers_div.find_all('tbody')\n",
    "        index=0\n",
    "        race_racers_data=[0]*6\n",
    "        if len(racers_sep_row)==6:\n",
    "            for racer_html in racers_sep_row:\n",
    "                racer_row_ex_td=racer_html.find_all('td')\n",
    "                #選手の登録ID\n",
    "                racer_ID_div=racer_row_ex_td[2].find_all('div')\n",
    "                racer_ID_div=racer_ID_div[0]\n",
    "                racer_ID_div_txt=racer_ID_div.text\n",
    "                start=(racer_ID_div_txt.find('/'))-35\n",
    "                end=(racer_ID_div_txt.find('/')-31)\n",
    "                #racer_ID=racer_ID_div_txt[start:end]#選手の登録ID\n",
    "                racer_ID=racer_ID_div_txt.split('\\n')[0]\n",
    "\n",
    "                #選手のモータ番号\n",
    "                racer_moter_td=racer_row_ex_td[6]\n",
    "                racer_moter_td_text=racer_moter_td.text\n",
    "                #racer_moter_split=racer_moter_td_text.split('\\r')\n",
    "                racer_moter_split=racer_moter_td_text.split('\\n')\n",
    "                #racer_moter_id=racer_moter_split[1][-2:]\n",
    "                racer_moter_id=racer_moter_split[0]\n",
    "                #選手のボート番号\n",
    "                racer_boat_td=racer_row_ex_td[7]\n",
    "                racer_boat_td_text=racer_boat_td.text\n",
    "    #             racer_boat_split=racer_boat_td_text.split('\\r')\n",
    "    #             racer_boat_id=racer_boat_split[1][-2:]\n",
    "                racer_boat_split=racer_boat_td_text.split('\\n')\n",
    "                racer_boat_id=racer_boat_split[0]\n",
    "\n",
    "                racer_data=[racer_ID,racer_moter_id,racer_boat_id]#選手固有のデータを持ったリスト\n",
    "\n",
    "                race_racers_data[index]=racer_data\n",
    "                index+=1\n",
    "        else:\n",
    "            print('欠場選手等の例外が発生していないか確認してください')\n",
    "        #race_racers_dataを一行に変換する\n",
    "        race_row=pd.Series(index=[])#一レースの情報を一行に変換したもの\n",
    "        race_num=rno#ここにはレース番号を入れる変数の値を代入\n",
    "        race_row['number_race']=race_num\n",
    "        for i in range(len(race_racers_data)):\n",
    "            race_row['racer_{}_ID'.format(i+1)]=int(race_racers_data[i][0])\n",
    "            race_row['racer_{}_mo'.format(i+1)]=int(race_racers_data[i][1])\n",
    "            race_row['racer_{}_bo'.format(i+1)]=int(race_racers_data[i][2])\n",
    "        race_df=race_df.append(race_row,ignore_index=True)\n",
    "    return race_df\n",
    "\n",
    "\n",
    "def concat_param(startlist_df,para_df):\n",
    "    #クローリングしてきたスタートリストと最新の選手のパラメータを結合す。\n",
    "    pred_base_df=pd.DataFrame(columns=['number_race','racer_1_ID','racer_2_ID','racer_3_ID','racer_4_ID','racer_5_ID','racer_6_ID','racer_1_rank','racer_1_male','racer_1_age','racer_1_doub','racer_1_ave_st','racer_2_rank','racer_2_male','racer_2_age','racer_2_doub','racer_2_ave_st','racer_3_rank','racer_3_male','racer_3_age','racer_3_doub','racer_3_ave_st','racer_4_rank','racer_4_male','racer_4_age','racer_4_doub','racer_4_ave_st','racer_5_rank','racer_5_male','racer_5_age','racer_5_doub','racer_5_ave_st','racer_6_rank','racer_6_male','racer_6_age','racer_6_doub','racer_6_ave_st'])\n",
    "    for index,series in startlist_df.iterrows():\n",
    "\n",
    "        #pred_base_df=pd.DataFrame(columns=['date','result_com','money','number_race','racer_1_ID','racer_2_ID','racer_3_ID','racer_4_ID','racer_5_ID','racer_6_ID','racer_1_rank','racer_1_male','racer_1_age','racer_1_doub','racer_1_ave_st','racer_2_rank','racer_2_male','racer_2_age','racer_2_doub','racer_2_ave_st','racer_3_rank','racer_3_male','racer_3_age','racer_3_doub','racer_3_ave_st','racer_4_rank','racer_4_male','racer_4_age','racer_4_doub','racer_4_ave_st','racer_5_rank','racer_5_male','racer_5_age','racer_5_doub','racer_5_ave_st','racer_6_rank','racer_6_male','racer_6_age','racer_6_doub','racer_6_ave_st'])\n",
    "\n",
    "        #///////////////////////////////////////レースに出ているレーサーの成績を検索＆取得\n",
    "        ID_1=series['racer_1_ID']\n",
    "        ID_2=series['racer_2_ID']\n",
    "        ID_3=series['racer_3_ID']\n",
    "        ID_4=series['racer_4_ID']\n",
    "        ID_5=series['racer_5_ID']\n",
    "        ID_6=series['racer_6_ID']\n",
    "        racer_1_df=para_df[para_df['racer_ID']==ID_1]\n",
    "        racer_2_df=para_df[para_df['racer_ID']==ID_2]\n",
    "        racer_3_df=para_df[para_df['racer_ID']==ID_3]\n",
    "        racer_4_df=para_df[para_df['racer_ID']==ID_4]\n",
    "        racer_5_df=para_df[para_df['racer_ID']==ID_5]\n",
    "        racer_6_df=para_df[para_df['racer_ID']==ID_6]\n",
    "        if len(racer_1_df)==1:\n",
    "            pass\n",
    "        else:\n",
    "            racer_1_df=para_df[(para_df['racer_doub_win']==0.00) & (para_df['racer_ave_st_time']==0.00)]\n",
    "            print('CAREFULL!!!!    NOT FOUND RACER ')\n",
    "\n",
    "        if len(racer_2_df)==1:\n",
    "            pass\n",
    "        else:\n",
    "            racer_2_df=para_df[(para_df['racer_doub_win']==0.00) & (para_df['racer_ave_st_time']==0.00)]\n",
    "            print('CAREFULL!!!!    NOT FOUND RACER ')\n",
    "\n",
    "        if len(racer_3_df)==1:\n",
    "            pass\n",
    "        else:\n",
    "            racer_3_df=para_df[(para_df['racer_doub_win']==0.00) & (para_df['racer_ave_st_time']==0.00)]\n",
    "            print('CAREFULL!!!!    NOT FOUND RACER ')\n",
    "\n",
    "        if len(racer_4_df)==1:\n",
    "            pass\n",
    "        else:\n",
    "            racer_4_df=para_df[(para_df['racer_doub_win']==0.00) & (para_df['racer_ave_st_time']==0.00)]\n",
    "            print('CAREFULL!!!!    NOT FOUND RACER ')\n",
    "\n",
    "        if len(racer_5_df)==1:\n",
    "            pass\n",
    "        else:\n",
    "            racer_5_df=para_df[(para_df['racer_doub_win']==0.00) & (para_df['racer_ave_st_time']==0.00)]\n",
    "            print('CAREFULL!!!!    NOT FOUND RACER ')\n",
    "\n",
    "\n",
    "        if len(racer_6_df)==1:\n",
    "            pass\n",
    "        else:\n",
    "            racer_6_df=para_df[(para_df['racer_doub_win']==0.00) & (para_df['racer_ave_st_time']==0.00)]\n",
    "            print('CAREFULL!!!!    NOT FOUND RACER ')\n",
    "\n",
    "        #追加していくデータフレームを作成\n",
    "\n",
    "        add_df= pd.DataFrame({'number_race':series['number_race'],\n",
    "                            'racer_1_ID':series['racer_1_ID'],\n",
    "                            'racer_2_ID':series['racer_2_ID'],\n",
    "                            'racer_3_ID':series['racer_3_ID'],\n",
    "                            'racer_4_ID':series['racer_4_ID'],\n",
    "                            'racer_5_ID':series['racer_5_ID'],\n",
    "                            'racer_6_ID':series['racer_6_ID'],\n",
    "                            'racer_1_bo':series['racer_1_bo'],\n",
    "                            'racer_1_mo':series['racer_1_mo'],\n",
    "                            'racer_2_bo':series['racer_2_bo'],\n",
    "                            'racer_2_mo':series['racer_2_mo'],\n",
    "                            'racer_3_bo':series['racer_3_bo'],\n",
    "                            'racer_3_mo':series['racer_3_mo'],\n",
    "                            'racer_4_bo':series['racer_4_bo'],\n",
    "                            'racer_4_mo':series['racer_4_mo'],\n",
    "                            'racer_5_bo':series['racer_5_bo'],\n",
    "                            'racer_5_mo':series['racer_5_mo'],\n",
    "                            'racer_6_bo':series['racer_6_bo'],\n",
    "                            'racer_6_mo':series['racer_6_mo'],\n",
    "                            'racer_1_rank':racer_1_df.iat[0,1],\n",
    "                            'racer_1_male':racer_1_df.iat[0,2],\n",
    "                            'racer_1_age':racer_1_df.iat[0,3],\n",
    "                            'racer_1_doub':racer_1_df.iat[0,4],\n",
    "                            'racer_1_ave_st':racer_1_df.iat[0,5],\n",
    "                            'racer_2_rank':racer_2_df.iat[0,1],\n",
    "                            'racer_2_male':racer_2_df.iat[0,2],\n",
    "                            'racer_2_age':racer_2_df.iat[0,3],\n",
    "                            'racer_2_doub':racer_2_df.iat[0,4],\n",
    "                            'racer_2_ave_st':racer_2_df.iat[0,5],\n",
    "                            'racer_3_rank':racer_3_df.iat[0,1],\n",
    "                            'racer_3_male':racer_3_df.iat[0,2],\n",
    "                            'racer_3_age':racer_3_df.iat[0,3],\n",
    "                            'racer_3_doub':racer_3_df.iat[0,4],\n",
    "                            'racer_3_ave_st':racer_3_df.iat[0,5],\n",
    "                            'racer_4_rank':racer_4_df.iat[0,1],\n",
    "                            'racer_4_male':racer_4_df.iat[0,2],\n",
    "                            'racer_4_age':racer_4_df.iat[0,3],\n",
    "                            'racer_4_doub':racer_4_df.iat[0,4],\n",
    "                            'racer_4_ave_st':racer_4_df.iat[0,5],\n",
    "                            'racer_5_rank':racer_5_df.iat[0,1],\n",
    "                            'racer_5_male':racer_5_df.iat[0,2],\n",
    "                            'racer_5_age':racer_5_df.iat[0,3],\n",
    "                            'racer_5_doub':racer_5_df.iat[0,4],\n",
    "                            'racer_5_ave_st':racer_5_df.iat[0,5],\n",
    "                            'racer_6_rank':racer_6_df.iat[0,1],\n",
    "                            'racer_6_male':racer_6_df.iat[0,2],\n",
    "                            'racer_6_age':racer_6_df.iat[0,3],\n",
    "                            'racer_6_doub':racer_6_df.iat[0,4],\n",
    "                            'racer_6_ave_st':racer_6_df.iat[0,5] }, index=[''])\n",
    "        #//////////////////////////////データフレームにadd_dfを追加していく。\n",
    "        pred_base_df=pred_base_df.append(add_df)\n",
    "    return pred_base_df #出走データの選手IDをもとに各種パラメータを結合したもの\n",
    "\n",
    "\n",
    "def preddata_making_former_asiya(df):\n",
    "    pred_race_df=df\n",
    "  #pred_race_df=pred_race_df.drop([\"Unnamed: 0\"],axis=1)#csvファイルについている名無しの列を削除\n",
    "    result_df=pred_race_df\n",
    "    result_df=result_df.drop([\"racer_1_ID\",\"racer_2_ID\",\"racer_3_ID\",\"racer_4_ID\",\"racer_5_ID\",\"racer_6_ID\",],axis=1)#IDはいらないので削除\n",
    "    result_df=result_df.replace(0.0000,{\"racer_1_ave_st_time\":0.22})#新人のave_st_timeを0.22に\n",
    "    result_df=result_df.replace(0.0000,{\"racer_2_ave_st_time\":0.22})\n",
    "    result_df=result_df.replace(0.0000,{\"racer_3_ave_st_time\":0.22})\n",
    "    result_df=result_df.replace(0.0000,{\"racer_4_ave_st_time\":0.22})\n",
    "    result_df=result_df.replace(0.0000,{\"racer_5_ave_st_time\":0.22})\n",
    "    result_df=result_df.replace(0.0000,{\"racer_6_ave_st_time\":0.22})\n",
    "    result_df=result_df.replace(0.0000,{\"racer_1_doub_win\":0.02})#新人の着に絡む確率ave_st_timeを0.02に(新人の半期の偏差から導出)\n",
    "    result_df=result_df.replace(0.0000,{\"racer_2_doub_win\":0.02})\n",
    "    result_df=result_df.replace(0.0000,{\"racer_3_doub_win\":0.02})\n",
    "    result_df=result_df.replace(0.0000,{\"racer_4_doub_win\":0.02})\n",
    "    result_df=result_df.replace(0.0000,{\"racer_5_doub_win\":0.02})\n",
    "    result_df=result_df.replace(0.0000,{\"racer_6_doub_win\":0.02})\n",
    "  #ダミー変数化\n",
    "    result_df_dummie=result_df\n",
    "    race_dummie_df=pd.get_dummies(result_df_dummie['number_race'])#number_raceをダミー化\n",
    "    for column, val in race_dummie_df.iteritems():\n",
    "        result_df_dummie['race_{}'.format(int(column))]=val\n",
    "    result_df_dummie=result_df_dummie.drop('number_race',axis=1)\n",
    "\n",
    "    cols=list(result_df_dummie.columns)\n",
    "    male_cols=[s for s in cols if 'male' in s]#性別を示すカラムを取り出す\n",
    "\n",
    "  #===========================新規、性別の取り出し機能が良くなかったため作り直す\n",
    "    empty_arr=[0]*len(result_df_dummie)\n",
    "    for col in male_cols:\n",
    "        for number in np.arange(0,2,1):\n",
    "            result_df_dummie['{}_{}'.format(col,int(number))]=empty_arr\n",
    "        male_dummie_df=pd.get_dummies(result_df_dummie[col])#性別をダミー化\n",
    "        for column, val in male_dummie_df.iteritems():\n",
    "            result_df_dummie['{}_{}'.format(col,int(column))]=val\n",
    "        result_df_dummie=result_df_dummie.drop('{}'.format(col),axis=1)\n",
    "\n",
    "    cols=list(result_df_dummie.columns)\n",
    "    moter_cols=[s for s in cols if '_mo' in s]#モーター番号を示すカラムを取り出す\n",
    "    boat_cols=[s for s in cols if '_bo' in s]#ボート番号を示すカラムを取り出す\n",
    "    #boat もmoterも番号は1~99とする\n",
    "    numbers=np.arange(1, 100, 1)\n",
    "    empty_arr=[0]*len(result_df_dummie)\n",
    "    for col in moter_cols:\n",
    "        for number in numbers:\n",
    "            result_df_dummie['{}_{}'.format(col,int(number))]=empty_arr\n",
    "        moter_dummie_df=pd.get_dummies(result_df_dummie[col])#モータ番号をダミー化\n",
    "        for column, val in moter_dummie_df.iteritems():\n",
    "            result_df_dummie['{}_{}'.format(col,int(column))]=val\n",
    "        result_df_dummie=result_df_dummie.drop('{}'.format(col),axis=1)\n",
    "\n",
    "  #boat番号をダミー化\n",
    "    for col in boat_cols:\n",
    "        for number in numbers:\n",
    "            result_df_dummie['{}_{}'.format(col,int(number))]=empty_arr\n",
    "        boat_dummie_df=pd.get_dummies(result_df_dummie[col])#boat番号をダミー化\n",
    "        for column, val in boat_dummie_df.iteritems():\n",
    "            result_df_dummie['{}_{}'.format(col,int(column))]=val\n",
    "        result_df_dummie=result_df_dummie.drop('{}'.format(col),axis=1)\n",
    "    result_df=result_df_dummie\n",
    "\n",
    "\n",
    "\n",
    "  #クラスタリング\n",
    "  #分けてみるクラスタの数は[8,10]の2個\n",
    "  #cluster_target_df　　trainのデータからリザルトと配当金を取り除いたもの\n",
    "    target_num_cluster=[8,10]\n",
    "  #test_clustaring_df=train_has_PCA_df\n",
    "    clustar_target_df=result_df\n",
    "    clustaring_df=clustar_target_df\n",
    "    for num_cluster in target_num_cluster:\n",
    "        pred = KMeans(n_clusters=num_cluster).fit_predict(clustar_target_df)\n",
    "        clustaring_df['num={}'.format(num_cluster)]=pred\n",
    "\n",
    "    model_df=clustaring_df\n",
    "\n",
    "    return model_df\n",
    "\n",
    "\n",
    "\n",
    "def pickle_predict(pred_race_base_df):#モデルをすべてpickleで読み込んで学習データの加工、予測を行う関数\n",
    "    #==============================================================================\n",
    "    #学習関数で場所ごとにバージョンに対応した学習データを作る\n",
    "    model_df=preddata_making_former_asiya(pred_race_base_df)\n",
    "\n",
    "    #保存してあるモデルを読み込む(ついでに予測も行う)\n",
    "    #保存してあるモデルを読み込む(ついでに予測も行う)\n",
    "    #保存してあるモデルを読み込む(ついでに予測も行う)\n",
    "    #保存してあるモデルを読み込む(ついでに予測も行う)\n",
    "    num_race=np.arange(1,13,1)\n",
    "    model3 = pickle.load(open('former_pickle_data/model_com3_dep6_per121.sav', 'rb'))\n",
    "    model4 = pickle.load(open('former_pickle_data/model_com4_dep7_per131.sav', 'rb'))\n",
    "    model5 = pickle.load(open('former_pickle_data/model_com5_dep8_per122.sav', 'rb'))\n",
    "    model7 = pickle.load(open('former_pickle_data/model_com7_dep7_per146.sav', 'rb'))\n",
    "    model13 = pickle.load(open('former_pickle_data/model_com13_dep6_per115.sav', 'rb'))\n",
    "    model14= pickle.load(open('former_pickle_data/model_com14_dep4_per123.sav', 'rb'))\n",
    "    model3_pred=model3.predict_proba(model_df)\n",
    "    model4_pred=model4.predict_proba(model_df)\n",
    "    model5_pred=model5.predict_proba(model_df)\n",
    "    model7_pred=model7.predict_proba(model_df)\n",
    "    model13_pred=model13.predict_proba(model_df)\n",
    "    model14_pred=model14.predict_proba(model_df)\n",
    "    pred_df=pd.DataFrame({'num_race':num_race,\n",
    "                            'pred_3':[pred[1] for pred in model3_pred],\n",
    "                            'pred_4':[pred[1] for pred in model4_pred],\n",
    "                            'pred_5':[pred[1] for pred in model5_pred],\n",
    "                            'pred_7':[pred[1] for pred in model7_pred],\n",
    "                            'pred_13':[pred[1] for pred in model13_pred],\n",
    "                            'pred_14':[pred[1] for pred in model14_pred]\n",
    "                            })\n",
    "    #print(\"pred_day_url\",url)\n",
    "    return pred_df\n",
    "\n",
    "\n",
    "def trans_com(target_com):\n",
    "    #racers_arr=[1,2,3,4,5,6]\n",
    "    racers_arr=['1','2','3','4','5','6']\n",
    "    result_com=target_com\n",
    "    #result_com+=(racer_1 - 1)*20\n",
    "    racer_1=int(result_com/20)+1\n",
    "    #next_num=result_com%20\n",
    "    next_num=result_com-(int(result_com/20)*20)\n",
    "    racers_arr.remove(str(racer_1))\n",
    "    racer_2=int(racers_arr[int((next_num-1)/4)])\n",
    "    next_num=next_num-int(next_num/4)*4\n",
    "    # if next_num==0:\n",
    "    #     racer_2=racer_2-1\n",
    "    racers_arr.remove(str(racer_2))\n",
    "\n",
    "    racer_3=racers_arr[next_num-1]\n",
    "    out_text='{}-{}-{}|'.format(racer_1,racer_2,racer_3)\n",
    "\n",
    "    return out_text\n",
    "\n",
    "\n",
    "def trans_pred(pred_df,place_name,version,sec_date_txt):#投票時に使えるように予測を３連単の形に変換する関数\n",
    "    num_race=np.arange(1,13,1)\n",
    "    buy_arr=['']*len(num_race)#レースの数\n",
    "    #model_sheet_path=\"/home/ubuntu/bet_bot/bot_database/{place_name}/model_score_{place_name}/use_model/use_model_{place_name}_{V}.csv\".format(place_name=place_name,V=version)#モデルを保存#AWS\n",
    "    #model_sheet_path=\"bot_database/{place_name}/model_score_{place_name}/use_model/{V}/use_model_{place_name}_{date}_{V}.csv\".format(place_name=place_name,V=version,date=sec_date_txt)\n",
    "    model_sheet_path=\"/home/ubuntu/bet_bot/bot_database/{place_name}/model_score_{place_name}/use_model/{V}/use_model_{place_name}_{date}_{V}.csv\".format(place_name=place_name,V=version,date=sec_date_txt)\n",
    "\n",
    "    model_sheet_df=pd.read_csv(model_sheet_path)\n",
    "    target_coms=[int(com) for com in model_sheet_df['target_com'].values]\n",
    "    i=0\n",
    "    for _, row in pred_df.iterrows():\n",
    "        preds=''\n",
    "        for_i=0\n",
    "        for val in row.values:\n",
    "            if val==1:\n",
    "                text= trans_com(target_coms[for_i])\n",
    "                preds+=text\n",
    "            else:\n",
    "                pass\n",
    "            for_i+=1\n",
    "        buy_arr[i]=preds\n",
    "        i+=1\n",
    "    pred_trans_df=pd.DataFrame({'num_race':num_race,\n",
    "                            'buy_com':buy_arr\n",
    "                            })\n",
    "    return pred_trans_df\n",
    "\n",
    "def regulation_pred_proba_scale_v2(pred_df,target_date):\n",
    "    #購買対象のレースの予測値を持ったdfと，その日の日付を渡す\n",
    "    #渡したdfを昨年の予測値でーたにまぜて，予測値の差が見えやすいようにスケーリングする．関数\n",
    "\n",
    "    #year:予測対象のレースが存在する年\n",
    "    pred_df_len=len(pred_df)\n",
    "    pred_proba_df=pred_df.copy()#何も加工をしていないprobaを保存しておく用にコピーを作っておく\n",
    "    pred_proba_df=pred_proba_df.loc[:, pred_proba_df.columns.str.contains('pred')]#予測に関する列のみを抽出\n",
    "    pred_proba_df=pred_proba_df.set_axis([col.replace('pred_','proba_') for col in pred_proba_df.columns],axis=1).copy()#購買金額に関連する列とわかるように名前を振りなおす\n",
    "    #display(pred_proba_df)\n",
    "    \n",
    "    year=target_date.year#予測対象のレースの年情報だけ切り抜く\n",
    "    sample_year=year-1#一年前のprobaのデータに混ぜてスケーリングを行う\n",
    "    sample_proba_df=pd.read_csv('test_csv/proba_get_use_{}.csv'.format(sample_year))\n",
    "    num_race_cal=pred_df['num_race']\n",
    "    #sample_proba_df=pd.read_csv('test_csv/proba_get_use_{}.csv'.format(sample_year))\n",
    "#     num_race=np.arange(1,12)\n",
    "\n",
    "    sample_proba_df=sample_proba_df.loc[:, sample_proba_df.columns.str.contains('pred')]#予測に関する列のみを抽出\n",
    "    concat_target_proba_df=pd.concat([sample_proba_df, pred_df], axis=0)\n",
    "    #probaをスケーリングして最大値1,最小値0にスケーリングする（pickleのモデルを使ってスケール変換機の保存を行う）\n",
    "    for col in sample_proba_df.columns:\n",
    "        concat_target_proba_df[col]=preprocessing.minmax_scale(concat_target_proba_df[col].values)\n",
    "    #trans_target_proba_df=concat_target_proba_df[concat_target_proba_df['date']==target_date].copy()\n",
    "    trans_target_proba_df=concat_target_proba_df[len(concat_target_proba_df)-pred_df_len:].copy()\n",
    "    #trans_proba_df=trans_proba_df.mask(trans_proba_df>=0.5,1)\n",
    "    th=0.8#中心点が0.5とは限らないっぽい，なんとなく見ながら変更をしていく\n",
    "    #trans_target_proba_df=trans_target_proba_df.loc[:, trans_target_proba_df.columns.str.contains('pred')].copy()\n",
    "    trans_target_proba_df.drop('num_race', axis=1)\n",
    "    trans_target_proba_df=trans_target_proba_df.mask(trans_target_proba_df<th,0)#データの中心は変わらないので，0.5未満は購買を行わない\n",
    "    trans_target_proba_df=((trans_target_proba_df-th)*2)\n",
    "    #trans_target_proba_df=(((trans_target_proba_df-th)*2)*10000)昨|日の製作時はここで係数をかけたが，実装時にはやらない.\n",
    "    trans_target_proba_df=trans_target_proba_df.mask(trans_target_proba_df<=0,0)#上記の計算式だと購買を行わないものはみんな-1000となるので０に置換する\n",
    "    trans_target_proba_df['num_race']=num_race_cal\n",
    "    trans_target_proba_df=pd.concat([pred_proba_df,trans_target_proba_df],axis=1)\n",
    "    return trans_target_proba_df\n",
    "\n",
    "def add_BetMoney_BetFlag(regulation_df,bet_coefficient):#スケーリングしたprobaの予測値のdfと，購買金額の係数を渡して，実際の購買金額と，購買を行ったかどうかのフラグを付けてくれる関数\n",
    "    bet_regulation_df=regulation_df.copy()\n",
    "    bet_regulation_df=bet_regulation_df.drop('num_race', axis=1)\n",
    "    bet_regulation_df=bet_regulation_df.set_axis([col.replace('pred_','bet_') for col in bet_regulation_df.columns],axis=1).copy()#購買金額に関連する列とわかるように名前を振りなおす\n",
    "    bet_regulation_df=bet_regulation_df.loc[:, bet_regulation_df.columns.str.contains('bet_')]#購買金額に関する列のみを抽出\n",
    "    \n",
    "    #bet_regulation_df=((bet_regulation_df)*10000)\n",
    "    bet_regulation_df=((bet_regulation_df)*bet_coefficient)\n",
    "    bet_regulation_df=bet_regulation_df.round(-2)#投票時を想定して，桁を百円単位に丸める（四捨五入）\n",
    "    \n",
    "    #bet_proba_df=bet_proba_df.mask(bet_proba_df<=0,0)#上記の計算式だと購買を行わないものはみんな-1000となるので０に置換する\n",
    "    bet_flag_df=regulation_df.copy()\n",
    "    \n",
    "    bet_flag_df=bet_flag_df.drop('num_race', axis=1)\n",
    "    #bet_flag_df=bet_flag_df.mask(bet_flag_df>=th,1).copy()#データの中心は変わらない,かつ中心以上により購買を行ったものにはフラグ付けを行う\n",
    "    bet_flag_df=bet_flag_df.set_axis([col.replace('pred_','buy_flag_') for col in bet_flag_df.columns],axis=1)#購買フラグに関連する列とわかるように名前を振りなおす\n",
    "    bet_flag_df=bet_flag_df.loc[:, bet_flag_df.columns.str.contains('buy_flag_')]#予測の有無に関する列のみを抽出\n",
    "    bet_flag_df=bet_flag_df.mask(bet_flag_df>0,1).copy()#データの中心は変わらない,かつ中心以上により購買を行ったものにはフラグ付けを行う\n",
    "    proba_bet_flag_df=pd.concat([regulation_df,bet_regulation_df],axis=1)\n",
    "    proba_bet_flag_df=pd.concat([proba_bet_flag_df,bet_flag_df],axis=1)\n",
    "    #あたったレースにフラグを付ける＆獲得できた配当金の計算（レース単位でユニーク．前に出てきたものとしょりは　似ているが同じではない．）\n",
    "    return proba_bet_flag_df\n",
    "\n",
    "def bet_race_add_db(total_pred):#投票を行った結果をdbに書き込む関数(レース単位でユニーク)\n",
    "\n",
    "    # connection_config = {\n",
    "    #     'user': 'postgres',\n",
    "    #     'password': 'admin',\n",
    "    #     'host': '127.0.0.1',\n",
    "    #     'port': '5432', # なくてもOK\n",
    "    #     'database': 'boatrace_database'\n",
    "    # }\n",
    "    #ローカル用\n",
    "    # connection_config = {\n",
    "    #     'user': 'postgres',\n",
    "    #     'password': 'Takuma406287',\n",
    "    #     #'host': '127.0.0.1',\n",
    "    #     'host': '127.0.0.1',\n",
    "    #     'port': '5432', # なくてもOK\n",
    "    #     'database': 'boatrace_bot'\n",
    "    # }\n",
    "    engine = create_engine('postgresql://postgres:admin@127.0.0.1:5432/boatrace_database')#.format(**connection_config))\n",
    "    #engine = create_engine('postgresql://watanabe:Takuma406287@127.0.0.1:5432/boatrace_database')#raspi ubuntu server用\n",
    "    total_pred.to_sql(name='bet_log_former_asiya_proba_check_test_2022',schema='proba_test', con=engine, if_exists='append', index=False)\n",
    "    return None\n",
    "\n",
    "\n",
    "def bet_date_add_db(date_txt,place_name,total_pred):#投票を行った結果をdbに書き込む関数(日付単位でユニーク)\n",
    "    log_s=pd.Series({'date':date_txt,\n",
    "                         'place_name':place_name,\n",
    "                         'money':total_pred['total_use'].sum(),\n",
    "                         'money_type':'bet'\n",
    "                        })\n",
    "    log_df=pd.DataFrame(columns=log_s.index)\n",
    "    log_df=log_df.append(log_s, ignore_index=True)\n",
    "    #log_s['date']=datetime.datetime.strptime(pd.to_datetime(log_s['date']), '%Y/%m/%d %H:%M:%S').strftime('%Y/%m/%d')\n",
    "    #log_s['date']=log_s['date'].split()[1]\n",
    "\n",
    "    # connection_config = {\n",
    "    #     'user': 'postgres',\n",
    "    #     'password': 'admin',\n",
    "    #     'host': '127.0.0.1',\n",
    "    #     'port': '5432', # なくてもOK\n",
    "    #     'database': 'boatrace_database'\n",
    "    # }\n",
    "    #ローカル用\n",
    "    # connection_config = {\n",
    "    #     'user': 'postgres',\n",
    "    #     'password': 'Takuma406287',\n",
    "    #     #'host': '127.0.0.1',\n",
    "    #     'host': '127.0.0.1',\n",
    "    #     'port': '5432', # なくてもOK\n",
    "    #     'database': 'boatrace_bot'\n",
    "    # }\n",
    "    engine = create_engine('postgresql://postgres:admin@127.0.0.1:5432/boatrace_database')#.format(**connection_config))\n",
    "    #engine = create_engine('postgresql://watanabe:Takuma406287@127.0.0.1:5432/boatrace_database')#raspi ubuntu server用\n",
    "\n",
    "    #log_df.to_sql(name='former_bet_get_log_t_th05_all',schema='former', con=engine, if_exists='append', index=False)\n",
    "    #log_df.to_sql(name='bet_get_log_t_V4_2_2021',schema='log', con=engine, if_exists='append', index=False)\n",
    "    log_df.to_sql(name='bet_get_log_former_asiya_proba_check_test_2022',schema='proba_test', con=engine, if_exists='append', index=False)\n",
    "    return None\n",
    "\n",
    "\n",
    "def split_pred(row):\n",
    "    pred_coms=row['buy_com'].split(\"|\")\n",
    "    pred_coms.pop(-1)#末尾は必ず空白になるのでこれを削除\n",
    "    pred_coms_split=[0]*len(pred_coms)\n",
    "    for i in range(len(pred_coms)):\n",
    "        pred_coms_split[i]=pred_coms[i].split(\"-\")\n",
    "    return pred_coms_split\n",
    "\n",
    "## ブラウザを移動しながら投票を行う関数＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝\n",
    "def auto_betting(place_num,pred_trans_df,total_pred):\n",
    "    # # place_num:開催会場の番号\n",
    "    # # pred_trans_df:予測結果を３連単の形に直したもの\n",
    "    # # total_pred:合計の予測数\n",
    "    # # bet_1_money:一つの予測のbet金額\n",
    "    # options = Options()\n",
    "    # options.binary_location = '/usr/bin/google-chrome'\n",
    "    # options.add_argument('--headless')#ヘッドレス化\n",
    "    # driver = webdriver.Chrome(ChromeDriverManager().install(),chrome_options=options)\n",
    "    #\n",
    "    #\n",
    "    # #driver = webdriver.Chrome(chrome_options=options)\n",
    "    #\n",
    "    # driver.get(\"https://ib.mbrace.or.jp/\")\n",
    "    #\n",
    "    # # ID/PASSを入力\n",
    "    # member_no = driver.find_element_by_id(\"memberNo\")#会員番号入力フォーム\n",
    "    # member_no.send_keys(\"08706180\")#member_no.send_keys(\"08706180\")\n",
    "    # password = driver.find_element_by_id(\"pin\")\n",
    "    # password.send_keys(\"0219\")#パスワード入力フォーム\n",
    "    # password_2 = driver.find_element_by_id(\"authPassword\")#認証番号入力フォーム\n",
    "    # password_2.send_keys(\"tQ5S8H\")#認証番号\n",
    "    #\n",
    "    # # ログインボタンをクリック\n",
    "    # login_button = driver.find_element_by_id(\"loginButton\")\n",
    "    # login_button.click()\n",
    "    #\n",
    "    # time.sleep(5)\n",
    "    # #最も新しく開かれた別のタブに切り替え\n",
    "    # driver.switch_to.window(driver.window_handles[-1])\n",
    "    #\n",
    "    # #入金機能部分########################################################################################\n",
    "    # #########################################################################################\n",
    "    # #入金のためのタブを開く\n",
    "    # charge_payoff = driver.find_element_by_id(\"gnavi01\")\n",
    "    # charge_payoff.click()\n",
    "    # charge = driver.find_element_by_id(\"charge\")\n",
    "    # charge.click()\n",
    "    # time.sleep(0.3)# 一回htmlが変化するために待つ\n",
    "    # # 入金を行う\n",
    "    # input_money = driver.find_element_by_id(\"chargeInstructAmt\")#金額入力フォーム\n",
    "    # input_money.send_keys(int((total_pred*bet_1_money)/1000))#金額\n",
    "    # #input_money.send_keys(\"0\")#金額\n",
    "    #\n",
    "    # input_money_pass = driver.find_element_by_id(\"chargeBetPassword\")#認証番号入力フォーム\n",
    "    # input_money_pass.send_keys(\"taku02\")\n",
    "    # charge_enter = driver.find_element_by_id(\"executeCharge\")\n",
    "    # charge_enter.click()\n",
    "    # time.sleep(0.3)\n",
    "    #\n",
    "    # final_charge_enter = driver.find_element_by_id(\"ok\")\n",
    "    # final_charge_enter.click()\n",
    "    # time.sleep(0.3)\n",
    "    # close = driver.find_element_by_id(\"closeChargecomp\")#閉じるボタン\n",
    "    # close.click()\n",
    "    #\n",
    "    # #入金完了後の実際のbet部分\n",
    "    # place_buttun=driver.find_element_by_id(\"jyo{}\".format(place_num))#betを行う会場選び\n",
    "    # place_buttun.click()\n",
    "    # time.sleep(0.3)\n",
    "    # for index,row in pred_trans_df.iterrows():\n",
    "    #     race_num=row['num_race']#レース番号\n",
    "    #     split_preds_arr=split_pred(row)\n",
    "    #     if len(split_preds_arr)==0:#予測なしのレースはpass\n",
    "    #         pass\n",
    "    #     else:\n",
    "    #         if race_num<10:#投票するレース選び\n",
    "    #             race_buttun=driver.find_element_by_id(\"selRaceNo0{}\".format(race_num))#betを行う会場選び\n",
    "    #             race_buttun.click()\n",
    "    #             time.sleep(0.3)\n",
    "    #         else:#投票するレース選び\n",
    "    #             race_buttun=driver.find_element_by_id(\"selRaceNo{}\".format(race_num))#betを行う会場選び\n",
    "    #             race_buttun.click()\n",
    "    #             time.sleep(0.3)\n",
    "    #         flag=0\n",
    "    #         for pred in split_preds_arr:#レース内での予測の数betを行う。\n",
    "    #             racer_1st_but=driver.find_element_by_id(\"regbtn_{}_1\".format(pred[0]))#1着予測\n",
    "    #             racer_1st_but.click()\n",
    "    #\n",
    "    #             racer_2nd_but=driver.find_element_by_id(\"regbtn_{}_2\".format(pred[1]))#2着予測\n",
    "    #             racer_2nd_but.click()\n",
    "    #\n",
    "    #             racer_3rd_but=driver.find_element_by_id(\"regbtn_{}_3\".format(pred[2]))#3着予測\n",
    "    #             racer_3rd_but.click()\n",
    "    #\n",
    "    #             # 入金を行う\n",
    "    #             if flag==1:\n",
    "    #                 pass\n",
    "    #             else:\n",
    "    #                 input_com_bet = driver.find_element_by_id(\"amount\")#組一つあたりの金額金額入力フォーム\n",
    "    #                 input_com_bet.send_keys(str(int(bet_1_money/100)))#金額(00が初めからついているので想定金額を100で割る。)\n",
    "    #\n",
    "    #             add_list_but=driver.find_element_by_id(\"regAmountBtn\")#投票リストに追加\n",
    "    #             add_list_but.click()\n",
    "    #             time.sleep(0.3)\n",
    "    #             flag=1\n",
    "    #\n",
    "    # input_end_but=driver.find_elements_by_class_name(\"btnSubmit \")[0]#投票入力完了ボタン\n",
    "    # input_end_but.click()\n",
    "    # time.sleep(0.3)\n",
    "    #\n",
    "    # total_bet = driver.find_element_by_id(\"amount\")#合計の金額の入力フォーム\n",
    "    # total_bet.send_keys(int(total_pred*bet_1_money))#合計金額は全体の組の数×一つのcomあたりの金額\n",
    "    #\n",
    "    # total_bet_pass = driver.find_element_by_id(\"pass\")#合計の金額の入力フォーム\n",
    "    # total_bet_pass.send_keys(\"taku02\")#合計金額は全体の組の数×一つのcomあたりの金額\n",
    "    #\n",
    "    # bet_enter_but=driver.find_element_by_id(\"submitBet\")#投票するボタン\n",
    "    # bet_enter_but.click()\n",
    "    # time.sleep(0.3)\n",
    "    # time.sleep(10)\n",
    "    # ok_but=driver.find_element_by_id(\"ok\")#投票するボタン\n",
    "    # ok_but.click()\n",
    "    #\n",
    "    # time.sleep(0.2)\n",
    "    # close_but=driver.find_element_by_id(\"modifyJyoBetForm\")#場をへんこうして　投票するボタン（閉じる）\n",
    "    # close_but.click()\n",
    "    # driver.quit()#タブを閉じる。\n",
    "\n",
    "    return None\n",
    "\n",
    "def bet(date,place_num,para_df,bet_1_money,verion):#これより上の自動化においてのすべての機能をまとめた関数、クロール、予測、投票までのすべてを行う。\n",
    "    #try:#会場名ごとに、本日の開催があるのか銅貨を判別する\n",
    "    date_txt=date.strftime('%Y%m%d')\n",
    "    now_sec_date=get_season_date(date)#今いる日付が所属する区間の開始日を取得\n",
    "    now_sec_date_txt=now_sec_date.strftime('%Y%m%d')\n",
    "\n",
    "    print(date_txt)\n",
    "    print(place_num)\n",
    "    #try:\n",
    "        #version='V3_1'\n",
    "    place_master=master.get_place_master()\n",
    "    startlist_df=startlist_making(date_txt,place_num)#クローリング\n",
    "    pred_base_df=concat_param(startlist_df,para_df)#選手のパラメータを結合\n",
    "    for i in range(6):#スクレイピングの結果だとなぜかrankのデータ型が変わってしまうので整形する\n",
    "        pred_base_df[\"racer_{}_rank\".format(i+1)]= pred_base_df[\"racer_{}_rank\".format(i+1)].astype(int)\n",
    "    place_name=place_master[place_num]\n",
    "    pred_df=pickle_predict(pred_base_df,date,now_sec_date,place_name,version)\n",
    "    #会場ごとの一日の合計予測数\n",
    "    pred_trans_df=trans_pred(pred_df,place_name,version,now_sec_date_txt)#３連単の形に戻す\n",
    "    total_pred=pred_df.sum().sum()#全体の予測数\n",
    "    total_use=pred_df.sum().sum()*bet_1_money#会場ごとの一日の合計予測数からの使用金額\n",
    "\n",
    "    bet_add_db(date,place_name,total_pred,bet_1_money)#dbにログを書き込む\n",
    "    auto_betting(place_num,pred_trans_df,total_pred,bet_1_money)\n",
    "    print(date,'_bet_',place_name)\n",
    "    # except:\n",
    "    #     print(\"not_found_race_today\")\n",
    "    return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiac-shoot",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#バックテスト用コード\n",
    "para_file='22'\n",
    "para_file_path=\"../../bot_database/racer_para/{}/{}.csv\".format(para_file,para_file)\n",
    "para_df=pd.read_csv(para_file_path)\n",
    "para_df=para_df.drop([\"Unnamed: 0\"],axis=1)#csvファイルについている名無しの列を削除\n",
    "#for pred_date in date_range(date(2021, 1,2), date(2021, 9, 30)):\n",
    "# target_date = datetime.strptime('2022-01-06', '%Y-%m-%d').date()#2020分で検証\n",
    "#以下がコード本体=================================================================================================\n",
    "#以下がコード本体=================================================================================================\n",
    "#以下がコード本体=================================================================================================\n",
    "#now_sec_date_txt=now_sec_date.strftime('%Y%m%d')#今日の日付を文字列に\n",
    "#バックテストのみでの処理\n",
    "place_name='asiya'\n",
    "place_num=21\n",
    "bet_coefficient=10000#投票金額を決定する係数 \n",
    "\n",
    "\n",
    "\n",
    "#date_i= datetime.strptime('2022-01-01', '%Y-%m-%d').date()#2020分で検証\n",
    "\n",
    "\n",
    "\n",
    "start = datetime.strptime('20220101', '%Y%m%d').date()#2020分で検証\n",
    "end   = datetime.strptime('20220501', '%Y%m%d').date()\n",
    "use_get_df=pd.DataFrame()\n",
    "for date_i in daterange(start, end):\n",
    "    try:\n",
    "        #date_i = datetime.strptime('2022-01-06', '%Y-%m-%d').date()#2020分で検証\n",
    "        target_date_txt=date_i.strftime('%Y%m%d')\n",
    "        print(target_date_txt)\n",
    "        startlist_df=startlist_making(target_date_txt,place_num)#クローリング\n",
    "        pred_base_df=concat_param(startlist_df,para_df)#選手のパラメータを結合\n",
    "        for i in range(6):#スクレイピングの結果だとなぜかrankのデータ型が変わってしまうので整形する\n",
    "            pred_base_df[\"racer_{}_rank\".format(i+1)]= pred_base_df[\"racer_{}_rank\".format(i+1)].astype(int)\n",
    "        #place_name=place_master[place_num]\n",
    "        pred_df=pickle_predict(pred_base_df)\n",
    "        proba_ragulated_pred_df=regulation_pred_proba_scale_v2(pred_df,date_i)\n",
    "        trans_proba_bet_df=add_BetMoney_BetFlag(proba_ragulated_pred_df,bet_coefficient)\n",
    "        trans_proba_bet_df\n",
    "        trans_proba_bet_df['date']=target_date_txt\n",
    "        trans_proba_bet_df['place_name']=place_name\n",
    "        trans_proba_bet_df['total_use']=trans_proba_bet_df.loc[:, trans_proba_bet_df.columns.str.contains('bet')].sum(axis=1) \n",
    "        racer_id_df=startlist_df.loc[:, startlist_df.columns.str.contains('ID')].copy()#選手情報に関する列のみを抽出\n",
    "        racer_id_df=racer_id_df.set_axis([col.replace('ID','id') for col in racer_id_df.columns],axis=1).copy()#DBに書き込めるように大文字を取り除く\n",
    "        race_db_df=pd.concat([racer_id_df,trans_proba_bet_df],axis=1)\n",
    "\n",
    "        #会場ごとの一日の合計予測数\n",
    "        #pred_trans_df=trans_pred(pred_df,place_name,version,now_sec_date_txt)#３連単の形に戻す\n",
    "        #total_pred=pred_df.sum().sum()#全体の予測数\n",
    "        #total_use=pred_df.sum().sum()*bet_1_money#会場ごとの一日の合計予測数からの使用金額\n",
    "        bet_race_add_db(race_db_df)\n",
    "\n",
    "        bet_date_add_db(target_date_txt,place_name,race_db_df)#dbにログを書き込む\n",
    "        race_db_df.to_csv(\"test_csv/test_pred/asiya_test_{}.csv\".format(target_date_txt))\n",
    "        #race_db_df.to_csv(\"check.csv\")\n",
    "\n",
    "        #auto_betting(place_num,pred_trans_df,total_pred,bet_1_money)\n",
    "        #print(date,'_bet_',place_name)\n",
    "    except:\n",
    "        print(\"not_found_race_today\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "straight-buyer",
   "metadata": {},
   "source": [
    "# 閾値の変更=0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "middle-dayton",
   "metadata": {
    "code_folding": [
     44,
     51,
     58,
     118,
     237,
     317,
     351,
     372
    ]
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn\n",
    "from pandas import DataFrame\n",
    "from tqdm import tqdm\n",
    "from imblearn.under_sampling import RandomUnderSampler #アンダーサンプリング用\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "# 機械学習用\n",
    "from sklearn.cluster import KMeans #クラスタリング用\n",
    "from sklearn.decomposition import PCA  #次元削減用\n",
    "from sklearn.ensemble import RandomForestClassifier#ランダムフォレスト\n",
    "from copy import deepcopy as cp\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "import time\n",
    "import datetime\n",
    "import os #ディレクトリ作成用\n",
    "import xgboost as xgb\n",
    "import sys\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine #書き込みのエンジンをpostgreに変えるのに使う。\n",
    "\n",
    "from datetime import date, timedelta\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from sklearn.preprocessing import StandardScaler#モデルの評価用に標準化する関数\n",
    "import scipy.stats#モデルの評価用に標準化する関数\n",
    "#必要なモジュールのインポート\n",
    "import chromedriver_binary\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from sklearn import preprocessing\n",
    "import requests #クローリングのためのモジュール\n",
    "from bs4 import BeautifulSoup as bs4#HTMLから特定の情報を抜き出すためのモジュール\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "#自作のモジュールのインポート\n",
    "\n",
    "def daterange(start, stop, step = timedelta(1)):#日付でfor文を回すためのジェネレータ\n",
    "    current = start\n",
    "    while current < stop:\n",
    "        yield current\n",
    "        current += step\n",
    "\n",
    "\n",
    "def pred_th_trans_com(pred_df,th,target_com):#指定の組のカラムのみを置換。\n",
    "    trans_df=pred_df.copy()\n",
    "    trans_df.loc[trans_df['pred_{}'.format(target_com)] >= th, 'pred_{}'.format(target_com)] = 1\n",
    "    trans_df.loc[~(trans_df['pred_{}'.format(target_com)] >=  th), 'pred_{}'.format(target_com)] = 0\n",
    "    return trans_df\n",
    "\n",
    "\n",
    "def startlist_making(date,place_num):#dateと開催場所を渡してスタートリストを作成する関数\n",
    "    #date='20210227'#日付を入力\n",
    "    race_df=pd.DataFrame(index=[], columns=[])\n",
    "    for i in range(12):\n",
    "        rno=i+1\n",
    "        #まず初めに１ページの情報を抜き出す機能\n",
    "        url='http://www.boatrace.jp/owpc/pc/race/racelist?rno={rno}&jcd={place_num}&hd={date}'.format(rno=rno,place_num=place_num,date=date)\n",
    "        response=requests.get(url)#対象のURLをget\n",
    "        #print(url)\n",
    "        response.encoding = response.apparent_encoding\n",
    "        start_page=bs4(response.text, 'html.parser')\n",
    "        racers_div=start_page.select_one(\".is-tableFixed__3rdadd\")\n",
    "        racers_sep_row=racers_div.find_all('tbody')\n",
    "        index=0\n",
    "        race_racers_data=[0]*6\n",
    "        if len(racers_sep_row)==6:\n",
    "            for racer_html in racers_sep_row:\n",
    "                racer_row_ex_td=racer_html.find_all('td')\n",
    "                #選手の登録ID\n",
    "                racer_ID_div=racer_row_ex_td[2].find_all('div')\n",
    "                racer_ID_div=racer_ID_div[0]\n",
    "                racer_ID_div_txt=racer_ID_div.text\n",
    "                start=(racer_ID_div_txt.find('/'))-35\n",
    "                end=(racer_ID_div_txt.find('/')-31)\n",
    "                #racer_ID=racer_ID_div_txt[start:end]#選手の登録ID\n",
    "                racer_ID=racer_ID_div_txt.split('\\n')[0]\n",
    "\n",
    "                #選手のモータ番号\n",
    "                racer_moter_td=racer_row_ex_td[6]\n",
    "                racer_moter_td_text=racer_moter_td.text\n",
    "                #racer_moter_split=racer_moter_td_text.split('\\r')\n",
    "                racer_moter_split=racer_moter_td_text.split('\\n')\n",
    "                #racer_moter_id=racer_moter_split[1][-2:]\n",
    "                racer_moter_id=racer_moter_split[0]\n",
    "                #選手のボート番号\n",
    "                racer_boat_td=racer_row_ex_td[7]\n",
    "                racer_boat_td_text=racer_boat_td.text\n",
    "    #             racer_boat_split=racer_boat_td_text.split('\\r')\n",
    "    #             racer_boat_id=racer_boat_split[1][-2:]\n",
    "                racer_boat_split=racer_boat_td_text.split('\\n')\n",
    "                racer_boat_id=racer_boat_split[0]\n",
    "\n",
    "                racer_data=[racer_ID,racer_moter_id,racer_boat_id]#選手固有のデータを持ったリスト\n",
    "\n",
    "                race_racers_data[index]=racer_data\n",
    "                index+=1\n",
    "        else:\n",
    "            print('欠場選手等の例外が発生していないか確認してください')\n",
    "        #race_racers_dataを一行に変換する\n",
    "        race_row=pd.Series(index=[])#一レースの情報を一行に変換したもの\n",
    "        race_num=rno#ここにはレース番号を入れる変数の値を代入\n",
    "        race_row['number_race']=race_num\n",
    "        for i in range(len(race_racers_data)):\n",
    "            race_row['racer_{}_ID'.format(i+1)]=int(race_racers_data[i][0])\n",
    "            race_row['racer_{}_mo'.format(i+1)]=int(race_racers_data[i][1])\n",
    "            race_row['racer_{}_bo'.format(i+1)]=int(race_racers_data[i][2])\n",
    "        race_df=race_df.append(race_row,ignore_index=True)\n",
    "    return race_df\n",
    "\n",
    "\n",
    "def concat_param(startlist_df,para_df):\n",
    "    #クローリングしてきたスタートリストと最新の選手のパラメータを結合す。\n",
    "    pred_base_df=pd.DataFrame()\n",
    "    add_df=pd.DataFrame(columns=['number_race','racer_1_ID','racer_2_ID','racer_3_ID','racer_4_ID','racer_5_ID','racer_6_ID','racer_1_rank','racer_1_male','racer_1_age','racer_1_doub','racer_1_ave_st','racer_2_rank','racer_2_male','racer_2_age','racer_2_doub','racer_2_ave_st','racer_3_rank','racer_3_male','racer_3_age','racer_3_doub','racer_3_ave_st','racer_4_rank','racer_4_male','racer_4_age','racer_4_doub','racer_4_ave_st','racer_5_rank','racer_5_male','racer_5_age','racer_5_doub','racer_5_ave_st','racer_6_rank','racer_6_male','racer_6_age','racer_6_doub','racer_6_ave_st'])\n",
    "    for index,series in startlist_df.iterrows():\n",
    "\n",
    "        #pred_base_df=pd.DataFrame(columns=['date','result_com','money','number_race','racer_1_ID','racer_2_ID','racer_3_ID','racer_4_ID','racer_5_ID','racer_6_ID','racer_1_rank','racer_1_male','racer_1_age','racer_1_doub','racer_1_ave_st','racer_2_rank','racer_2_male','racer_2_age','racer_2_doub','racer_2_ave_st','racer_3_rank','racer_3_male','racer_3_age','racer_3_doub','racer_3_ave_st','racer_4_rank','racer_4_male','racer_4_age','racer_4_doub','racer_4_ave_st','racer_5_rank','racer_5_male','racer_5_age','racer_5_doub','racer_5_ave_st','racer_6_rank','racer_6_male','racer_6_age','racer_6_doub','racer_6_ave_st'])\n",
    "\n",
    "        #///////////////////////////////////////レースに出ているレーサーの成績を検索＆取得\n",
    "        ID_1=series['racer_1_ID']\n",
    "        ID_2=series['racer_2_ID']\n",
    "        ID_3=series['racer_3_ID']\n",
    "        ID_4=series['racer_4_ID']\n",
    "        ID_5=series['racer_5_ID']\n",
    "        ID_6=series['racer_6_ID']\n",
    "        racer_1_df=para_df[para_df['racer_ID']==ID_1]\n",
    "        racer_2_df=para_df[para_df['racer_ID']==ID_2]\n",
    "        racer_3_df=para_df[para_df['racer_ID']==ID_3]\n",
    "        racer_4_df=para_df[para_df['racer_ID']==ID_4]\n",
    "        racer_5_df=para_df[para_df['racer_ID']==ID_5]\n",
    "        racer_6_df=para_df[para_df['racer_ID']==ID_6]\n",
    "        if len(racer_1_df)==1:\n",
    "            pass\n",
    "        else:\n",
    "            racer_1_df=para_df[(para_df['racer_doub_win']==0.00) & (para_df['racer_ave_st_time']==0.00)]\n",
    "            print('CAREFULL!!!!    NOT FOUND RACER ')\n",
    "\n",
    "        if len(racer_2_df)==1:\n",
    "            pass\n",
    "        else:\n",
    "            racer_2_df=para_df[(para_df['racer_doub_win']==0.00) & (para_df['racer_ave_st_time']==0.00)]\n",
    "            print('CAREFULL!!!!    NOT FOUND RACER ')\n",
    "\n",
    "        if len(racer_3_df)==1:\n",
    "            pass\n",
    "        else:\n",
    "            racer_3_df=para_df[(para_df['racer_doub_win']==0.00) & (para_df['racer_ave_st_time']==0.00)]\n",
    "            print('CAREFULL!!!!    NOT FOUND RACER ')\n",
    "\n",
    "        if len(racer_4_df)==1:\n",
    "            pass\n",
    "        else:\n",
    "            racer_4_df=para_df[(para_df['racer_doub_win']==0.00) & (para_df['racer_ave_st_time']==0.00)]\n",
    "            print('CAREFULL!!!!    NOT FOUND RACER ')\n",
    "\n",
    "        if len(racer_5_df)==1:\n",
    "            pass\n",
    "        else:\n",
    "            racer_5_df=para_df[(para_df['racer_doub_win']==0.00) & (para_df['racer_ave_st_time']==0.00)]\n",
    "            print('CAREFULL!!!!    NOT FOUND RACER ')\n",
    "\n",
    "\n",
    "        if len(racer_6_df)==1:\n",
    "            pass\n",
    "        else:\n",
    "            racer_6_df=para_df[(para_df['racer_doub_win']==0.00) & (para_df['racer_ave_st_time']==0.00)]\n",
    "            print('CAREFULL!!!!    NOT FOUND RACER ')\n",
    "\n",
    "        #追加していくデータフレームを作成\n",
    "\n",
    "        add_df= pd.DataFrame({'number_race':series['number_race'],\n",
    "                          'racer_1_ID':series['racer_1_ID'],\n",
    "                            'racer_2_ID':series['racer_2_ID'],\n",
    "                            'racer_3_ID':series['racer_3_ID'],\n",
    "                            'racer_4_ID':series['racer_4_ID'],\n",
    "                            'racer_5_ID':series['racer_5_ID'],\n",
    "                            'racer_6_ID':series['racer_6_ID'],\n",
    "                            'racer_1_bo':series['racer_1_bo'],\n",
    "                            'racer_1_mo':series['racer_1_mo'],\n",
    "                            'racer_2_bo':series['racer_2_bo'],\n",
    "                            'racer_2_mo':series['racer_2_mo'],\n",
    "                            'racer_3_bo':series['racer_3_bo'],\n",
    "                            'racer_3_mo':series['racer_3_mo'],\n",
    "                            'racer_4_bo':series['racer_4_bo'],\n",
    "                            'racer_4_mo':series['racer_4_mo'],\n",
    "                            'racer_5_bo':series['racer_5_bo'],\n",
    "                            'racer_5_mo':series['racer_5_mo'],\n",
    "                            'racer_6_bo':series['racer_6_bo'],\n",
    "                            'racer_6_mo':series['racer_6_mo'],\n",
    "                            'racer_1_age':racer_1_df.iat[0,3],\n",
    "                            'racer_1_ave_st':racer_1_df.iat[0,5],\n",
    "                            'racer_1_doub':racer_1_df.iat[0,4],\n",
    "                            'racer_1_rank':racer_1_df.iat[0,1],\n",
    "                            'racer_1_male':racer_1_df.iat[0,2],\n",
    "\n",
    "                            'racer_2_age':racer_2_df.iat[0,3],\n",
    "                            'racer_2_ave_st':racer_2_df.iat[0,5],\n",
    "                            'racer_2_doub':racer_2_df.iat[0,4],\n",
    "                            'racer_2_rank':racer_2_df.iat[0,1],\n",
    "                            'racer_2_male':racer_2_df.iat[0,2],\n",
    "\n",
    "                            'racer_3_age':racer_3_df.iat[0,3],\n",
    "                            'racer_3_ave_st':racer_3_df.iat[0,5],\n",
    "                            'racer_3_doub':racer_3_df.iat[0,4],\n",
    "                            'racer_3_rank':racer_3_df.iat[0,1],\n",
    "                            'racer_3_male':racer_3_df.iat[0,2],\n",
    "\n",
    "                            'racer_4_age':racer_4_df.iat[0,3],\n",
    "                            'racer_4_ave_st':racer_4_df.iat[0,5],\n",
    "                            'racer_4_doub':racer_4_df.iat[0,4],\n",
    "                            'racer_4_rank':racer_4_df.iat[0,1],\n",
    "                            'racer_4_male':racer_4_df.iat[0,2],\n",
    "\n",
    "\n",
    "                            'racer_5_age':racer_5_df.iat[0,3],\n",
    "                            'racer_5_ave_st':racer_5_df.iat[0,5],\n",
    "                            'racer_5_doub':racer_5_df.iat[0,4],\n",
    "                            'racer_5_rank':racer_5_df.iat[0,1],\n",
    "                            'racer_5_male':racer_5_df.iat[0,2],\n",
    "\n",
    "                            'racer_6_age':racer_6_df.iat[0,3],\n",
    "                            'racer_6_ave_st':racer_6_df.iat[0,5],\n",
    "                            'racer_6_doub':racer_6_df.iat[0,4],\n",
    "                            'racer_6_rank':racer_6_df.iat[0,1],\n",
    "                            'racer_6_male':racer_6_df.iat[0,2] }, index=[''])\n",
    "        #//////////////////////////////データフレームにadd_dfを追加していく。\n",
    "        pred_base_df=pred_base_df.append(add_df)\n",
    "    return pred_base_df #出走データの選手IDをもとに各種パラメータを結合したもの\n",
    "\n",
    "def preddata_making_former_asiya(df):\n",
    "    pred_race_df=df\n",
    "  #pred_race_df=pred_race_df.drop([\"Unnamed: 0\"],axis=1)#csvファイルについている名無しの列を削除\n",
    "    result_df=pred_race_df\n",
    "    result_df=result_df.drop([\"racer_1_ID\",\"racer_2_ID\",\"racer_3_ID\",\"racer_4_ID\",\"racer_5_ID\",\"racer_6_ID\",],axis=1)#IDはいらないので削除\n",
    "    result_df=result_df.replace(0.0000,{\"racer_1_ave_st_time\":0.22})#新人のave_st_timeを0.22に\n",
    "    result_df=result_df.replace(0.0000,{\"racer_2_ave_st_time\":0.22})\n",
    "    result_df=result_df.replace(0.0000,{\"racer_3_ave_st_time\":0.22})\n",
    "    result_df=result_df.replace(0.0000,{\"racer_4_ave_st_time\":0.22})\n",
    "    result_df=result_df.replace(0.0000,{\"racer_5_ave_st_time\":0.22})\n",
    "    result_df=result_df.replace(0.0000,{\"racer_6_ave_st_time\":0.22})\n",
    "    result_df=result_df.replace(0.0000,{\"racer_1_doub_win\":0.02})#新人の着に絡む確率ave_st_timeを0.02に(新人の半期の偏差から導出)\n",
    "    result_df=result_df.replace(0.0000,{\"racer_2_doub_win\":0.02})\n",
    "    result_df=result_df.replace(0.0000,{\"racer_3_doub_win\":0.02})\n",
    "    result_df=result_df.replace(0.0000,{\"racer_4_doub_win\":0.02})\n",
    "    result_df=result_df.replace(0.0000,{\"racer_5_doub_win\":0.02})\n",
    "    result_df=result_df.replace(0.0000,{\"racer_6_doub_win\":0.02})\n",
    "  #ダミー変数化\n",
    "    result_df_dummie=result_df\n",
    "    race_dummie_df=pd.get_dummies(result_df_dummie['number_race'])#number_raceをダミー化\n",
    "    for column, val in race_dummie_df.iteritems():\n",
    "        result_df_dummie['race_{}'.format(int(column))]=val\n",
    "    result_df_dummie=result_df_dummie.drop('number_race',axis=1)\n",
    "\n",
    "    cols=list(result_df_dummie.columns)\n",
    "    male_cols=[s for s in cols if 'male' in s]#性別を示すカラムを取り出す\n",
    "\n",
    "  #===========================新規、性別の取り出し機能が良くなかったため作り直す\n",
    "    empty_arr=[0]*len(result_df_dummie)\n",
    "    for col in male_cols:\n",
    "        for number in np.arange(0,2,1):\n",
    "            result_df_dummie['{}_{}'.format(col,int(number))]=empty_arr\n",
    "        male_dummie_df=pd.get_dummies(result_df_dummie[col])#性別をダミー化\n",
    "        for column, val in male_dummie_df.iteritems():\n",
    "            result_df_dummie['{}_{}'.format(col,int(column))]=val\n",
    "        result_df_dummie=result_df_dummie.drop('{}'.format(col),axis=1)\n",
    "\n",
    "    cols=list(result_df_dummie.columns)\n",
    "    moter_cols=[s for s in cols if '_mo' in s]#モーター番号を示すカラムを取り出す\n",
    "    boat_cols=[s for s in cols if '_bo' in s]#ボート番号を示すカラムを取り出す\n",
    "    #boat もmoterも番号は1~99とする\n",
    "    numbers=np.arange(1, 100, 1)\n",
    "    empty_arr=[0]*len(result_df_dummie)\n",
    "    for col in moter_cols:\n",
    "        for number in numbers:\n",
    "            result_df_dummie['{}_{}'.format(col,int(number))]=empty_arr\n",
    "        moter_dummie_df=pd.get_dummies(result_df_dummie[col])#モータ番号をダミー化\n",
    "        for column, val in moter_dummie_df.iteritems():\n",
    "            result_df_dummie['{}_{}'.format(col,int(column))]=val\n",
    "        result_df_dummie=result_df_dummie.drop('{}'.format(col),axis=1)\n",
    "\n",
    "  #boat番号をダミー化\n",
    "    for col in boat_cols:\n",
    "        for number in numbers:\n",
    "            result_df_dummie['{}_{}'.format(col,int(number))]=empty_arr\n",
    "        boat_dummie_df=pd.get_dummies(result_df_dummie[col])#boat番号をダミー化\n",
    "        for column, val in boat_dummie_df.iteritems():\n",
    "            result_df_dummie['{}_{}'.format(col,int(column))]=val\n",
    "        result_df_dummie=result_df_dummie.drop('{}'.format(col),axis=1)\n",
    "    result_df=result_df_dummie\n",
    "\n",
    "\n",
    "\n",
    "  #クラスタリング\n",
    "  #分けてみるクラスタの数は[8,10]の2個\n",
    "  #cluster_target_df　　trainのデータからリザルトと配当金を取り除いたもの\n",
    "    target_num_cluster=[8,10]\n",
    "  #test_clustaring_df=train_has_PCA_df\n",
    "    clustar_target_df=result_df\n",
    "    clustaring_df=clustar_target_df\n",
    "    for num_cluster in target_num_cluster:\n",
    "        pred = KMeans(n_clusters=num_cluster).fit_predict(clustar_target_df)\n",
    "        clustaring_df['num={}'.format(num_cluster)]=pred\n",
    "\n",
    "    model_df=clustaring_df\n",
    "\n",
    "    return model_df\n",
    "\n",
    "\n",
    "\n",
    "def pickle_predict(pred_race_base_df):#モデルをすべてpickleで読み込んで学習データの加工、予測を行う関数\n",
    "    #==============================================================================\n",
    "    #学習関数で場所ごとにバージョンに対応した学習データを作る\n",
    "    model_df=preddata_making_former_asiya(pred_race_base_df)\n",
    "\n",
    "    #保存してあるモデルを読み込む(ついでに予測も行う)\n",
    "    #保存してあるモデルを読み込む(ついでに予測も行う)\n",
    "    #保存してあるモデルを読み込む(ついでに予測も行う)\n",
    "    #保存してあるモデルを読み込む(ついでに予測も行う)\n",
    "    num_race=np.arange(1,13,1)\n",
    "    model3 = pickle.load(open('former_pickle_data/model_com3_dep6_per121.sav', 'rb'))\n",
    "    model4 = pickle.load(open('former_pickle_data/model_com4_dep7_per131.sav', 'rb'))\n",
    "    model5 = pickle.load(open('former_pickle_data/model_com5_dep8_per122.sav', 'rb'))\n",
    "    model7 = pickle.load(open('former_pickle_data/model_com7_dep7_per146.sav', 'rb'))\n",
    "    model13 = pickle.load(open('former_pickle_data/model_com13_dep6_per115.sav', 'rb'))\n",
    "    model14= pickle.load(open('former_pickle_data/model_com14_dep4_per123.sav', 'rb'))\n",
    "    model3_pred=model3.predict_proba(model_df)\n",
    "    model4_pred=model4.predict_proba(model_df)\n",
    "    model5_pred=model5.predict_proba(model_df)\n",
    "    model7_pred=model7.predict_proba(model_df)\n",
    "    model13_pred=model13.predict_proba(model_df)\n",
    "    model14_pred=model14.predict_proba(model_df)\n",
    "    pred_df=pd.DataFrame({'num_race':num_race,\n",
    "                            'pred_3':[pred[1] for pred in model3_pred],\n",
    "                            'pred_4':[pred[1] for pred in model4_pred],\n",
    "                            'pred_5':[pred[1] for pred in model5_pred],\n",
    "                            'pred_7':[pred[1] for pred in model7_pred],\n",
    "                            'pred_13':[pred[1] for pred in model13_pred],\n",
    "                            'pred_14':[pred[1] for pred in model14_pred]\n",
    "                            })\n",
    "    #print(\"pred_day_url\",url)\n",
    "    return pred_df\n",
    "\n",
    "\n",
    "def trans_com(target_com):\n",
    "    #racers_arr=[1,2,3,4,5,6]\n",
    "    racers_arr=['1','2','3','4','5','6']\n",
    "    result_com=target_com\n",
    "    #result_com+=(racer_1 - 1)*20\n",
    "    racer_1=int(result_com/20)+1\n",
    "    #next_num=result_com%20\n",
    "    next_num=result_com-(int(result_com/20)*20)\n",
    "    racers_arr.remove(str(racer_1))\n",
    "    racer_2=int(racers_arr[int((next_num-1)/4)])\n",
    "    next_num=next_num-int(next_num/4)*4\n",
    "    # if next_num==0:\n",
    "    #     racer_2=racer_2-1\n",
    "    racers_arr.remove(str(racer_2))\n",
    "\n",
    "    racer_3=racers_arr[next_num-1]\n",
    "    out_text='{}-{}-{}|'.format(racer_1,racer_2,racer_3)\n",
    "\n",
    "    return out_text\n",
    "\n",
    "\n",
    "def trans_pred(pred_df,place_name,version,sec_date_txt):#投票時に使えるように予測を３連単の形に変換する関数\n",
    "    num_race=np.arange(1,13,1)\n",
    "    buy_arr=['']*len(num_race)#レースの数\n",
    "    #model_sheet_path=\"/home/ubuntu/bet_bot/bot_database/{place_name}/model_score_{place_name}/use_model/use_model_{place_name}_{V}.csv\".format(place_name=place_name,V=version)#モデルを保存#AWS\n",
    "    #model_sheet_path=\"bot_database/{place_name}/model_score_{place_name}/use_model/{V}/use_model_{place_name}_{date}_{V}.csv\".format(place_name=place_name,V=version,date=sec_date_txt)\n",
    "    model_sheet_path=\"/home/ubuntu/bet_bot/bot_database/{place_name}/model_score_{place_name}/use_model/{V}/use_model_{place_name}_{date}_{V}.csv\".format(place_name=place_name,V=version,date=sec_date_txt)\n",
    "\n",
    "    model_sheet_df=pd.read_csv(model_sheet_path)\n",
    "    target_coms=[int(com) for com in model_sheet_df['target_com'].values]\n",
    "    i=0\n",
    "    for _, row in pred_df.iterrows():\n",
    "        preds=''\n",
    "        for_i=0\n",
    "        for val in row.values:\n",
    "            if val==1:\n",
    "                text= trans_com(target_coms[for_i])\n",
    "                preds+=text\n",
    "            else:\n",
    "                pass\n",
    "            for_i+=1\n",
    "        buy_arr[i]=preds\n",
    "        i+=1\n",
    "    pred_trans_df=pd.DataFrame({'num_race':num_race,\n",
    "                            'buy_com':buy_arr\n",
    "                            })\n",
    "    return pred_trans_df\n",
    "\n",
    "def regulation_pred_proba_scale_v2(pred_df,target_date):\n",
    "    #購買対象のレースの予測値を持ったdfと，その日の日付を渡す\n",
    "    #渡したdfを昨年の予測値でーたにまぜて，予測値の差が見えやすいようにスケーリングする．関数\n",
    "\n",
    "    #year:予測対象のレースが存在する年\n",
    "    pred_df_len=len(pred_df)\n",
    "    pred_proba_df=pred_df.copy()#何も加工をしていないprobaを保存しておく用にコピーを作っておく\n",
    "    pred_proba_df=pred_proba_df.loc[:, pred_proba_df.columns.str.contains('pred')]#予測に関する列のみを抽出\n",
    "    pred_proba_df=pred_proba_df.set_axis([col.replace('pred_','proba_') for col in pred_proba_df.columns],axis=1).copy()#購買金額に関連する列とわかるように名前を振りなおす\n",
    "    #display(pred_proba_df)\n",
    "    \n",
    "    year=target_date.year#予測対象のレースの年情報だけ切り抜く\n",
    "    sample_year=year-1#一年前のprobaのデータに混ぜてスケーリングを行う\n",
    "    sample_proba_df=pd.read_csv('test_csv/proba_get_use_{}.csv'.format(sample_year))\n",
    "    num_race_cal=pred_df['num_race']\n",
    "    #sample_proba_df=pd.read_csv('test_csv/proba_get_use_{}.csv'.format(sample_year))\n",
    "#     num_race=np.arange(1,12)\n",
    "\n",
    "    sample_proba_df=sample_proba_df.loc[:, sample_proba_df.columns.str.contains('pred')]#予測に関する列のみを抽出\n",
    "    concat_target_proba_df=pd.concat([sample_proba_df, pred_df], axis=0)\n",
    "    #probaをスケーリングして最大値1,最小値0にスケーリングする（pickleのモデルを使ってスケール変換機の保存を行う）\n",
    "    for col in sample_proba_df.columns:\n",
    "        concat_target_proba_df[col]=preprocessing.minmax_scale(concat_target_proba_df[col].values)\n",
    "    #trans_target_proba_df=concat_target_proba_df[concat_target_proba_df['date']==target_date].copy()\n",
    "    trans_target_proba_df=concat_target_proba_df[len(concat_target_proba_df)-pred_df_len:].copy()\n",
    "    #trans_proba_df=trans_proba_df.mask(trans_proba_df>=0.5,1)\n",
    "    th=0.9#中心点が0.5とは限らないっぽい，なんとなく見ながら変更をしていく\n",
    "    #trans_target_proba_df=trans_target_proba_df.loc[:, trans_target_proba_df.columns.str.contains('pred')].copy()\n",
    "    trans_target_proba_df.drop('num_race', axis=1)\n",
    "    trans_target_proba_df=trans_target_proba_df.mask(trans_target_proba_df<th,0)#データの中心は変わらないので，0.5未満は購買を行わない\n",
    "    trans_target_proba_df=((trans_target_proba_df-th)*2)\n",
    "    #trans_target_proba_df=(((trans_target_proba_df-th)*2)*10000)昨|日の製作時はここで係数をかけたが，実装時にはやらない.\n",
    "    trans_target_proba_df=trans_target_proba_df.mask(trans_target_proba_df<=0,0)#上記の計算式だと購買を行わないものはみんな-1000となるので０に置換する\n",
    "    trans_target_proba_df['num_race']=num_race_cal\n",
    "    trans_target_proba_df=pd.concat([pred_proba_df,trans_target_proba_df],axis=1)\n",
    "    return trans_target_proba_df\n",
    "\n",
    "def add_BetMoney_BetFlag(regulation_df,bet_coefficient):#スケーリングしたprobaの予測値のdfと，購買金額の係数を渡して，実際の購買金額と，購買を行ったかどうかのフラグを付けてくれる関数\n",
    "    bet_regulation_df=regulation_df.copy()\n",
    "    bet_regulation_df=bet_regulation_df.drop('num_race', axis=1)\n",
    "    bet_regulation_df=bet_regulation_df.set_axis([col.replace('pred_','bet_') for col in bet_regulation_df.columns],axis=1).copy()#購買金額に関連する列とわかるように名前を振りなおす\n",
    "    bet_regulation_df=bet_regulation_df.loc[:, bet_regulation_df.columns.str.contains('bet_')]#購買金額に関する列のみを抽出\n",
    "    \n",
    "    #bet_regulation_df=((bet_regulation_df)*10000)\n",
    "    bet_regulation_df=((bet_regulation_df)*bet_coefficient)\n",
    "    bet_regulation_df=bet_regulation_df.round(-2)#投票時を想定して，桁を百円単位に丸める（四捨五入）\n",
    "    \n",
    "    #bet_proba_df=bet_proba_df.mask(bet_proba_df<=0,0)#上記の計算式だと購買を行わないものはみんな-1000となるので０に置換する\n",
    "    bet_flag_df=regulation_df.copy()\n",
    "    \n",
    "    bet_flag_df=bet_flag_df.drop('num_race', axis=1)\n",
    "    #bet_flag_df=bet_flag_df.mask(bet_flag_df>=th,1).copy()#データの中心は変わらない,かつ中心以上により購買を行ったものにはフラグ付けを行う\n",
    "    bet_flag_df=bet_flag_df.set_axis([col.replace('pred_','buy_flag_') for col in bet_flag_df.columns],axis=1)#購買フラグに関連する列とわかるように名前を振りなおす\n",
    "    bet_flag_df=bet_flag_df.loc[:, bet_flag_df.columns.str.contains('buy_flag_')]#予測の有無に関する列のみを抽出\n",
    "    bet_flag_df=bet_flag_df.mask(bet_flag_df>0,1).copy()#データの中心は変わらない,かつ中心以上により購買を行ったものにはフラグ付けを行う\n",
    "    proba_bet_flag_df=pd.concat([regulation_df,bet_regulation_df],axis=1)\n",
    "    proba_bet_flag_df=pd.concat([proba_bet_flag_df,bet_flag_df],axis=1)\n",
    "    #あたったレースにフラグを付ける＆獲得できた配当金の計算（レース単位でユニーク．前に出てきたものとしょりは　似ているが同じではない．）\n",
    "    return proba_bet_flag_df\n",
    "\n",
    "def bet_race_add_db(total_pred):#投票を行った結果をdbに書き込む関数(レース単位でユニーク)\n",
    "\n",
    "    # connection_config = {\n",
    "    #     'user': 'postgres',\n",
    "    #     'password': 'admin',\n",
    "    #     'host': '127.0.0.1',\n",
    "    #     'port': '5432', # なくてもOK\n",
    "    #     'database': 'boatrace_database'\n",
    "    # }\n",
    "    #ローカル用\n",
    "    # connection_config = {\n",
    "    #     'user': 'postgres',\n",
    "    #     'password': 'Takuma406287',\n",
    "    #     #'host': '127.0.0.1',\n",
    "    #     'host': '127.0.0.1',\n",
    "    #     'port': '5432', # なくてもOK\n",
    "    #     'database': 'boatrace_bot'\n",
    "    # }\n",
    "    engine = create_engine('postgresql://postgres:admin@127.0.0.1:5432/boatrace_database')#.format(**connection_config))\n",
    "    #engine = create_engine('postgresql://watanabe:Takuma406287@127.0.0.1:5432/boatrace_database')#raspi ubuntu server用\n",
    "    total_pred.to_sql(name='bet_log_former_asiya_proba_test_2022_th07',schema='proba_test', con=engine, if_exists='append', index=False)\n",
    "    return None\n",
    "\n",
    "\n",
    "def bet_date_add_db(date_txt,place_name,total_pred):#投票を行った結果をdbに書き込む関数(日付単位でユニーク)\n",
    "    log_s=pd.Series({'date':date_txt,\n",
    "                         'place_name':place_name,\n",
    "                         'money':total_pred['total_use'].sum(),\n",
    "                         'money_type':'bet'\n",
    "                        })\n",
    "    log_df=pd.DataFrame(columns=log_s.index)\n",
    "    log_df=log_df.append(log_s, ignore_index=True)\n",
    "    #log_s['date']=datetime.datetime.strptime(pd.to_datetime(log_s['date']), '%Y/%m/%d %H:%M:%S').strftime('%Y/%m/%d')\n",
    "    #log_s['date']=log_s['date'].split()[1]\n",
    "\n",
    "    # connection_config = {\n",
    "    #     'user': 'postgres',\n",
    "    #     'password': 'admin',\n",
    "    #     'host': '127.0.0.1',\n",
    "    #     'port': '5432', # なくてもOK\n",
    "    #     'database': 'boatrace_database'\n",
    "    # }\n",
    "    #ローカル用\n",
    "    # connection_config = {\n",
    "    #     'user': 'postgres',\n",
    "    #     'password': 'Takuma406287',\n",
    "    #     #'host': '127.0.0.1',\n",
    "    #     'host': '127.0.0.1',\n",
    "    #     'port': '5432', # なくてもOK\n",
    "    #     'database': 'boatrace_bot'\n",
    "    # }\n",
    "    engine = create_engine('postgresql://postgres:admin@127.0.0.1:5432/boatrace_database')#.format(**connection_config))\n",
    "    #engine = create_engine('postgresql://watanabe:Takuma406287@127.0.0.1:5432/boatrace_database')#raspi ubuntu server用\n",
    "\n",
    "    #log_df.to_sql(name='former_bet_get_log_t_th05_all',schema='former', con=engine, if_exists='append', index=False)\n",
    "    #log_df.to_sql(name='bet_get_log_t_V4_2_2021',schema='log', con=engine, if_exists='append', index=False)\n",
    "    log_df.to_sql(name='bet_get_log_former_asiya_proba_test_2022_th07',schema='proba_test', con=engine, if_exists='append', index=False)\n",
    "    return None\n",
    "\n",
    "\n",
    "def split_pred(row):\n",
    "    pred_coms=row['buy_com'].split(\"|\")\n",
    "    pred_coms.pop(-1)#末尾は必ず空白になるのでこれを削除\n",
    "    pred_coms_split=[0]*len(pred_coms)\n",
    "    for i in range(len(pred_coms)):\n",
    "        pred_coms_split[i]=pred_coms[i].split(\"-\")\n",
    "    return pred_coms_split\n",
    "\n",
    "## ブラウザを移動しながら投票を行う関数＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝\n",
    "def auto_betting(place_num,pred_trans_df,total_pred):\n",
    "    # # place_num:開催会場の番号\n",
    "    # # pred_trans_df:予測結果を３連単の形に直したもの\n",
    "    # # total_pred:合計の予測数\n",
    "    # # bet_1_money:一つの予測のbet金額\n",
    "    # options = Options()\n",
    "    # options.binary_location = '/usr/bin/google-chrome'\n",
    "    # options.add_argument('--headless')#ヘッドレス化\n",
    "    # driver = webdriver.Chrome(ChromeDriverManager().install(),chrome_options=options)\n",
    "    #\n",
    "    #\n",
    "    # #driver = webdriver.Chrome(chrome_options=options)\n",
    "    #\n",
    "    # driver.get(\"https://ib.mbrace.or.jp/\")\n",
    "    #\n",
    "    # # ID/PASSを入力\n",
    "    # member_no = driver.find_element_by_id(\"memberNo\")#会員番号入力フォーム\n",
    "    # member_no.send_keys(\"08706180\")#member_no.send_keys(\"08706180\")\n",
    "    # password = driver.find_element_by_id(\"pin\")\n",
    "    # password.send_keys(\"0219\")#パスワード入力フォーム\n",
    "    # password_2 = driver.find_element_by_id(\"authPassword\")#認証番号入力フォーム\n",
    "    # password_2.send_keys(\"tQ5S8H\")#認証番号\n",
    "    #\n",
    "    # # ログインボタンをクリック\n",
    "    # login_button = driver.find_element_by_id(\"loginButton\")\n",
    "    # login_button.click()\n",
    "    #\n",
    "    # time.sleep(5)\n",
    "    # #最も新しく開かれた別のタブに切り替え\n",
    "    # driver.switch_to.window(driver.window_handles[-1])\n",
    "    #\n",
    "    # #入金機能部分########################################################################################\n",
    "    # #########################################################################################\n",
    "    # #入金のためのタブを開く\n",
    "    # charge_payoff = driver.find_element_by_id(\"gnavi01\")\n",
    "    # charge_payoff.click()\n",
    "    # charge = driver.find_element_by_id(\"charge\")\n",
    "    # charge.click()\n",
    "    # time.sleep(0.3)# 一回htmlが変化するために待つ\n",
    "    # # 入金を行う\n",
    "    # input_money = driver.find_element_by_id(\"chargeInstructAmt\")#金額入力フォーム\n",
    "    # input_money.send_keys(int((total_pred*bet_1_money)/1000))#金額\n",
    "    # #input_money.send_keys(\"0\")#金額\n",
    "    #\n",
    "    # input_money_pass = driver.find_element_by_id(\"chargeBetPassword\")#認証番号入力フォーム\n",
    "    # input_money_pass.send_keys(\"taku02\")\n",
    "    # charge_enter = driver.find_element_by_id(\"executeCharge\")\n",
    "    # charge_enter.click()\n",
    "    # time.sleep(0.3)\n",
    "    #\n",
    "    # final_charge_enter = driver.find_element_by_id(\"ok\")\n",
    "    # final_charge_enter.click()\n",
    "    # time.sleep(0.3)\n",
    "    # close = driver.find_element_by_id(\"closeChargecomp\")#閉じるボタン\n",
    "    # close.click()\n",
    "    #\n",
    "    # #入金完了後の実際のbet部分\n",
    "    # place_buttun=driver.find_element_by_id(\"jyo{}\".format(place_num))#betを行う会場選び\n",
    "    # place_buttun.click()\n",
    "    # time.sleep(0.3)\n",
    "    # for index,row in pred_trans_df.iterrows():\n",
    "    #     race_num=row['num_race']#レース番号\n",
    "    #     split_preds_arr=split_pred(row)\n",
    "    #     if len(split_preds_arr)==0:#予測なしのレースはpass\n",
    "    #         pass\n",
    "    #     else:\n",
    "    #         if race_num<10:#投票するレース選び\n",
    "    #             race_buttun=driver.find_element_by_id(\"selRaceNo0{}\".format(race_num))#betを行う会場選び\n",
    "    #             race_buttun.click()\n",
    "    #             time.sleep(0.3)\n",
    "    #         else:#投票するレース選び\n",
    "    #             race_buttun=driver.find_element_by_id(\"selRaceNo{}\".format(race_num))#betを行う会場選び\n",
    "    #             race_buttun.click()\n",
    "    #             time.sleep(0.3)\n",
    "    #         flag=0\n",
    "    #         for pred in split_preds_arr:#レース内での予測の数betを行う。\n",
    "    #             racer_1st_but=driver.find_element_by_id(\"regbtn_{}_1\".format(pred[0]))#1着予測\n",
    "    #             racer_1st_but.click()\n",
    "    #\n",
    "    #             racer_2nd_but=driver.find_element_by_id(\"regbtn_{}_2\".format(pred[1]))#2着予測\n",
    "    #             racer_2nd_but.click()\n",
    "    #\n",
    "    #             racer_3rd_but=driver.find_element_by_id(\"regbtn_{}_3\".format(pred[2]))#3着予測\n",
    "    #             racer_3rd_but.click()\n",
    "    #\n",
    "    #             # 入金を行う\n",
    "    #             if flag==1:\n",
    "    #                 pass\n",
    "    #             else:\n",
    "    #                 input_com_bet = driver.find_element_by_id(\"amount\")#組一つあたりの金額金額入力フォーム\n",
    "    #                 input_com_bet.send_keys(str(int(bet_1_money/100)))#金額(00が初めからついているので想定金額を100で割る。)\n",
    "    #\n",
    "    #             add_list_but=driver.find_element_by_id(\"regAmountBtn\")#投票リストに追加\n",
    "    #             add_list_but.click()\n",
    "    #             time.sleep(0.3)\n",
    "    #             flag=1\n",
    "    #\n",
    "    # input_end_but=driver.find_elements_by_class_name(\"btnSubmit \")[0]#投票入力完了ボタン\n",
    "    # input_end_but.click()\n",
    "    # time.sleep(0.3)\n",
    "    #\n",
    "    # total_bet = driver.find_element_by_id(\"amount\")#合計の金額の入力フォーム\n",
    "    # total_bet.send_keys(int(total_pred*bet_1_money))#合計金額は全体の組の数×一つのcomあたりの金額\n",
    "    #\n",
    "    # total_bet_pass = driver.find_element_by_id(\"pass\")#合計の金額の入力フォーム\n",
    "    # total_bet_pass.send_keys(\"taku02\")#合計金額は全体の組の数×一つのcomあたりの金額\n",
    "    #\n",
    "    # bet_enter_but=driver.find_element_by_id(\"submitBet\")#投票するボタン\n",
    "    # bet_enter_but.click()\n",
    "    # time.sleep(0.3)\n",
    "    # time.sleep(10)\n",
    "    # ok_but=driver.find_element_by_id(\"ok\")#投票するボタン\n",
    "    # ok_but.click()\n",
    "    #\n",
    "    # time.sleep(0.2)\n",
    "    # close_but=driver.find_element_by_id(\"modifyJyoBetForm\")#場をへんこうして　投票するボタン（閉じる）\n",
    "    # close_but.click()\n",
    "    # driver.quit()#タブを閉じる。\n",
    "\n",
    "    return None\n",
    "\n",
    "def bet(date,place_num,para_df,bet_1_money,verion):#これより上の自動化においてのすべての機能をまとめた関数、クロール、予測、投票までのすべてを行う。\n",
    "    #try:#会場名ごとに、本日の開催があるのか銅貨を判別する\n",
    "    date_txt=date.strftime('%Y%m%d')\n",
    "    now_sec_date=get_season_date(date)#今いる日付が所属する区間の開始日を取得\n",
    "    now_sec_date_txt=now_sec_date.strftime('%Y%m%d')\n",
    "\n",
    "    print(date_txt)\n",
    "    print(place_num)\n",
    "    #try:\n",
    "        #version='V3_1'\n",
    "    place_master=master.get_place_master()\n",
    "    startlist_df=startlist_making(date_txt,place_num)#クローリング\n",
    "    pred_base_df=concat_param(startlist_df,para_df)#選手のパラメータを結合\n",
    "    for i in range(6):#スクレイピングの結果だとなぜかrankのデータ型が変わってしまうので整形する\n",
    "        pred_base_df[\"racer_{}_rank\".format(i+1)]= pred_base_df[\"racer_{}_rank\".format(i+1)].astype(int)\n",
    "    place_name=place_master[place_num]\n",
    "    pred_df=pickle_predict(pred_base_df,date,now_sec_date,place_name,version)\n",
    "    #会場ごとの一日の合計予測数\n",
    "    pred_trans_df=trans_pred(pred_df,place_name,version,now_sec_date_txt)#３連単の形に戻す\n",
    "    total_pred=pred_df.sum().sum()#全体の予測数\n",
    "    total_use=pred_df.sum().sum()*bet_1_money#会場ごとの一日の合計予測数からの使用金額\n",
    "\n",
    "    bet_add_db(date,place_name,total_pred,bet_1_money)#dbにログを書き込む\n",
    "    auto_betting(place_num,pred_trans_df,total_pred,bet_1_money)\n",
    "    print(date,'_bet_',place_name)\n",
    "    # except:\n",
    "    #     print(\"not_found_race_today\")\n",
    "    return None\n",
    "\n",
    "\n",
    "\n",
    "#バックテスト用コード\n",
    "para_file='22'\n",
    "para_file_path=\"../../bot_database/racer_para/{}/{}.csv\".format(para_file,para_file)\n",
    "para_df=pd.read_csv(para_file_path)\n",
    "para_df=para_df.drop([\"Unnamed: 0\"],axis=1)#csvファイルについている名無しの列を削除\n",
    "#for pred_date in date_range(date(2021, 1,2), date(2021, 9, 30)):\n",
    "# target_date = datetime.strptime('2022-01-06', '%Y-%m-%d').date()#2020分で検証\n",
    "#以下がコード本体=================================================================================================\n",
    "#以下がコード本体=================================================================================================\n",
    "#以下がコード本体=================================================================================================\n",
    "#now_sec_date_txt=now_sec_date.strftime('%Y%m%d')#今日の日付を文字列に\n",
    "#バックテストのみでの処理\n",
    "place_name='asiya'\n",
    "place_num=21\n",
    "bet_coefficient=10000#投票金額を決定する係数 \n",
    "\n",
    "\n",
    "\n",
    "#date_i= datetime.strptime('2022-01-01', '%Y-%m-%d').date()#2020分で検証\n",
    "\n",
    "\n",
    "\n",
    "start = datetime.strptime('20210101', '%Y%m%d').date()#2020分で検証\n",
    "end   = datetime.strptime('20220501', '%Y%m%d').date()\n",
    "use_get_df=pd.DataFrame()\n",
    "for date_i in daterange(start, end):\n",
    "    try:\n",
    "        #date_i = datetime.strptime('2022-01-06', '%Y-%m-%d').date()#2020分で検証\n",
    "        target_date_txt=date_i.strftime('%Y%m%d')\n",
    "        print(target_date_txt)\n",
    "        startlist_df=startlist_making(target_date_txt,place_num)#クローリング\n",
    "        pred_base_df=concat_param(startlist_df,para_df)#選手のパラメータを結合\n",
    "        for i in range(6):#スクレイピングの結果だとなぜかrankのデータ型が変わってしまうので整形する\n",
    "            pred_base_df[\"racer_{}_rank\".format(i+1)]= pred_base_df[\"racer_{}_rank\".format(i+1)].astype(int)\n",
    "        #place_name=place_master[place_num]\n",
    "        pred_df=pickle_predict(pred_base_df)\n",
    "        proba_ragulated_pred_df=regulation_pred_proba_scale_v2(pred_df,date_i)\n",
    "        trans_proba_bet_df=add_BetMoney_BetFlag(proba_ragulated_pred_df,bet_coefficient)\n",
    "        trans_proba_bet_df['date']=target_date_txt\n",
    "        trans_proba_bet_df['place_name']=place_name\n",
    "        trans_proba_bet_df['total_use']=trans_proba_bet_df.loc[:, trans_proba_bet_df.columns.str.contains('bet')].sum(axis=1) \n",
    "        racer_id_df=startlist_df.loc[:, startlist_df.columns.str.contains('ID')].copy()#選手情報に関する列のみを抽出\n",
    "        racer_id_df=racer_id_df.set_axis([col.replace('ID','id') for col in racer_id_df.columns],axis=1).copy()#DBに書き込めるように大文字を取り除く\n",
    "        race_db_df=pd.concat([racer_id_df,trans_proba_bet_df],axis=1)\n",
    "\n",
    "        #会場ごとの一日の合計予測数\n",
    "        #pred_trans_df=trans_pred(pred_df,place_name,version,now_sec_date_txt)#３連単の形に戻す\n",
    "        #total_pred=pred_df.sum().sum()#全体の予測数\n",
    "        #total_use=pred_df.sum().sum()*bet_1_money#会場ごとの一日の合計予測数からの使用金額\n",
    "        bet_race_add_db(race_db_df)\n",
    "\n",
    "        bet_date_add_db(target_date_txt,place_name,race_db_df)#dbにログを書き込む\n",
    "        race_db_df.to_csv(\"test_csv/test_pred/asiya_test_{}.csv\".format(target_date_txt))\n",
    "        #race_db_df.to_csv(\"check.csv\")\n",
    "\n",
    "        #auto_betting(place_num,pred_trans_df,total_pred,bet_1_money)\n",
    "        #print(date,'_bet_',place_name)\n",
    "    except:\n",
    "        print(\"not_found_race_today\")\n",
    "        \n",
    "#==========================================================================================================\n",
    "#==========================================================================================================\n",
    "#==========================================================================================================\n",
    "#==========================================================================================================\n",
    "#==========================================================================================================\n",
    "#==========================================================================================================\n",
    "#==========================================================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn\n",
    "from pandas import DataFrame\n",
    "from tqdm import tqdm\n",
    "from imblearn.under_sampling import RandomUnderSampler #アンダーサンプリング用\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "# 機械学習用\n",
    "from sklearn.cluster import KMeans #クラスタリング用\n",
    "from sklearn.decomposition import PCA  #次元削減用\n",
    "from sklearn.ensemble import RandomForestClassifier#ランダムフォレスト\n",
    "from copy import deepcopy as cp\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "import time\n",
    "import datetime\n",
    "import os #ディレクトリ作成用\n",
    "import xgboost as xgb\n",
    "import sys\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine #書き込みのエンジンをpostgreに変えるのに使う。\n",
    "\n",
    "from datetime import date, timedelta\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from sklearn.preprocessing import StandardScaler#モデルの評価用に標準化する関数\n",
    "import scipy.stats#モデルの評価用に標準化する関数\n",
    "#必要なモジュールのインポート\n",
    "import chromedriver_binary\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from sklearn import preprocessing\n",
    "import requests #クローリングのためのモジュール\n",
    "from bs4 import BeautifulSoup as bs4#HTMLから特定の情報を抜き出すためのモジュール\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "def undo_trans_com(target_com_arr):\n",
    "    racers_arr=['1','2','3','4','5','6']\n",
    "    result_com=0\n",
    "    result_com+=20*racers_arr.index(target_com_arr[0])\n",
    "    racers_arr.pop(racers_arr.index(target_com_arr[0]))\n",
    "    result_com+=4*racers_arr.index(target_com_arr[1])\n",
    "    racers_arr.pop(racers_arr.index(target_com_arr[1]))\n",
    "    result_com+=racers_arr.index(target_com_arr[2])+1\n",
    "    return result_com\n",
    "\n",
    "def daterange(_start, _end):\n",
    "    for n in range((_end - _start).days):\n",
    "        yield _start + timedelta(n)\n",
    "        \n",
    "def calc_gain(place_name,place_num,target_date_txt):#DBからレースのベット情報，webからレースの結果情報を取得してきて，的中の判別と，それによる配当金情報を追加して集計用のdfを作成する\n",
    "    #公式サイトからレース結果と配当金額を取ってくる\n",
    "    results=[]\n",
    "    returns=[]\n",
    "    for i in range(12):\n",
    "        rno=i+1\n",
    "        #まず初めに１ページの情報を抜き出す機能\n",
    "        url='http://www.boatrace.jp/owpc/pc/race/raceresult?rno={rno}&jcd={place_num}&hd={date}'.format(rno=rno,place_num=place_num,date=target_date_txt)\n",
    "        response=requests.get(url)#対象のURLをget\n",
    "        response.encoding = response.apparent_encoding\n",
    "        result_page=bs4(response.text, 'html.parser')\n",
    "        #レース結果格納\n",
    "        result_dev=result_page.select_one(\".numberSet1_row\")\n",
    "        result_com_arr=[result_dev.select(\".numberSet1_number\")[0].string,result_dev.select(\".numberSet1_number\")[1].string,result_dev.select(\".numberSet1_number\")[2].string]\n",
    "        result_com=undo_trans_com(result_com_arr)\n",
    "        #配当金\n",
    "        return_money=result_page.select_one(\".is-payout1\").string\n",
    "        return_money=str(return_money).replace(\"¥\",'')\n",
    "        return_money=str(return_money).replace(\",\",'')\n",
    "\n",
    "\n",
    "        results.append(result_com)\n",
    "        returns.append(return_money)\n",
    "        time.sleep(1)\n",
    "    print(url)\n",
    "    result_df=pd.DataFrame({'num_race':np.arange(1,13),\n",
    "                  'result_coms':results,\n",
    "                  'return_money':returns})\n",
    "    #=========================================================================================================\n",
    "    \n",
    "    #DBから行った購買の情報を取ってくる===========================================================================\n",
    "    #DB接続設定\n",
    "    # connection_config = {\n",
    "    #     'user': 'postgres',\n",
    "    #     'password': 'admin',\n",
    "    #     'host': '127.0.0.1',\n",
    "    #     'port': '5432', # なくてもOK\n",
    "    #     'database': 'boatrace_database'\n",
    "    # }\n",
    "    #ローカル用\n",
    "    # connection_config = {\n",
    "    #     'user': 'postgres',\n",
    "    #     'password': 'Takuma406287',\n",
    "    #     #'host': '127.0.0.1',\n",
    "    #     'host': '127.0.0.1',\n",
    "    #     'port': '5432', # なくてもOK\n",
    "    #     'database': 'boatrace_bot'\n",
    "    # }\n",
    "    engine = create_engine('postgresql://postgres:admin@127.0.0.1:5432/boatrace_database')#.format(**connection_config))#デスクトップ(ローカル)用\n",
    "    #engine = create_engine('postgresql://watanabe:Takuma406287@127.0.0.1:5432/boatrace_database')#raspi ubuntu server用\n",
    "    sql=\"\"\"\n",
    "    SELECT\n",
    "    *\n",
    "    FROM\n",
    "        proba_test.bet_log_former_asiya_proba_test_2022_th07 b\n",
    "    WHERE\n",
    "        b.date=cast({target_date} AS text)\n",
    "        AND b.place_name='{place_name}'\n",
    "    ;\n",
    "    \"\"\".format(target_date=target_date_txt,place_name=place_name)\n",
    "    target_bet_df=pd.read_sql_query(sql, engine)\n",
    "    #========================================================================================================\n",
    "    preds_df=target_bet_df.loc[:, target_bet_df.columns.str.contains('pred')]#予測に関する部分のみ切り抜き\n",
    "    preds=[pred_com.replace(\"pred_\",'') for pred_com in preds_df.columns]\n",
    "    total_df=target_bet_df.copy()\n",
    "    total_df['result_coms']=result_df['result_coms']\n",
    "    total_df['return_money']=result_df['return_money']\n",
    "    total_df['return_money']=total_df['return_money'].astype(int)#型変換\n",
    "    flags=[0]*12\n",
    "    gets=[0]*12\n",
    "    #予測の正誤判定路のフラグカラムづくり\n",
    "    \n",
    "    i=0\n",
    "    for index,row in total_df.iterrows():\n",
    "        for pred in preds:\n",
    "            if (int(row['buy_flag_{}'.format(pred)]==1)) and (int(pred) == row['result_coms']):\n",
    "                flags[i]=1\n",
    "                gets[i]=(row['return_money']/100)*row['bet_{}'.format(pred)]\n",
    "            else:\n",
    "                pass\n",
    "        i+=1\n",
    "    total_df['flags']=flags\n",
    "    total_df['gets']=gets\n",
    "    #total_df.to_csv('check.csv')\n",
    "    return total_df\n",
    "\n",
    "\n",
    "def get_race_add_db(total_pred):#レース結果dbに書き込む関数(レース単位でユニーク，名前から誤解されそうだが，実際に自分のやったことの要素は入っていない)\n",
    "    \n",
    "    #DB書き込み用dfの作成\n",
    "    log_df=pd.DataFrame({'place_name':total_pred['place_name'].values,\n",
    "                         'date': total_pred['date'].values,\n",
    "                         'num_race':  total_pred['num_race'].values,\n",
    "                         'result_coms':  total_pred['result_coms'].values,\n",
    "                         'return_money':total_pred['return_money'].values#得られた金額\n",
    "                        })\n",
    "    \n",
    "    \n",
    "        #DB接続設定\n",
    "    # connection_config = {\n",
    "    #     'user': 'postgres',\n",
    "    #     'password': 'admin',\n",
    "    #     'host': '127.0.0.1',\n",
    "    #     'port': '5432', # なくてもOK\n",
    "    #     'database': 'boatrace_database'\n",
    "    # }\n",
    "    #ローカル用\n",
    "    # connection_config = {\n",
    "    #     'user': 'postgres',\n",
    "    #     'password': 'Takuma406287',\n",
    "    #     #'host': '127.0.0.1',\n",
    "    #     'host': '127.0.0.1',\n",
    "    #     'port': '5432', # なくてもOK\n",
    "    #     'database': 'boatrace_bot'\n",
    "    # }\n",
    "    engine = create_engine('postgresql://postgres:admin@127.0.0.1:5432/boatrace_database')#.format(**connection_config))#デスクトップ(ローカル)用\n",
    "    #engine = create_engine('postgresql://watanabe:Takuma406287@127.0.0.1:5432/boatrace_database')#raspi ubuntu server用\n",
    "    log_df.to_sql(name='result_log_former_asiya_proba_test_2022_th07',schema='proba_test', con=engine, if_exists='append', index=False)\n",
    "    return None\n",
    "    \n",
    "    \n",
    "def get_date_add_db(total_pred):#投票を行った結果をdbに書き込む関数(日付単位でユニーク)\n",
    "    #DB書き込み用dfの作成\n",
    "    log_s=pd.Series({'date': total_pred['date'].value_counts().index[0],\n",
    "                         'place_name':total_pred['place_name'].value_counts().index[0],\n",
    "                         'money':int(total_pred['gets'].sum()),#得られた金額\n",
    "                         'money_type':'get'\n",
    "                        })\n",
    "    log_df=pd.DataFrame(columns=log_s.index)\n",
    "    log_df=log_df.append(log_s, ignore_index=True)\n",
    "    #display(log_s)\n",
    "        #DB接続設定\n",
    "    # connection_config = {\n",
    "    #     'user': 'postgres',\n",
    "    #     'password': 'admin',\n",
    "    #     'host': '127.0.0.1',\n",
    "    #     'port': '5432', # なくてもOK\n",
    "    #     'database': 'boatrace_database'\n",
    "    # }\n",
    "    #ローカル用\n",
    "    # connection_config = {\n",
    "    #     'user': 'postgres',\n",
    "    #     'password': 'Takuma406287',\n",
    "    #     #'host': '127.0.0.1',\n",
    "    #     'host': '127.0.0.1',\n",
    "    #     'port': '5432', # なくてもOK\n",
    "    #     'database': 'boatrace_bot'\n",
    "    # }\n",
    "    engine = create_engine('postgresql://postgres:admin@127.0.0.1:5432/boatrace_database')#.format(**connection_config))#デスクトップ(ローカル)用\n",
    "    #engine = create_engine('postgresql://watanabe:Takuma406287@127.0.0.1:5432/boatrace_database')#raspi ubuntu server用\n",
    "    log_df.to_sql(name='bet_get_log_former_asiya_proba_test_2022_th07',schema='proba_test', con=engine, if_exists='append', index=False)\n",
    "    return None\n",
    "\n",
    "\n",
    "#target_date = datetime.strptime('2022-04-30', '%Y-%m-%d').date()#2020分で検証\n",
    "place_name='asiya'\n",
    "place_num=21\n",
    "#以下がコード本体=================================================================================================\n",
    "#以下がコード本体=================================================================================================\n",
    "#以下がコード本体=================================================================================================\n",
    "#now_sec_date_txt=now_sec_date.strftime('%Y%m%d')#今日の日付を文字列に\n",
    "#バックテストのみでの処理\n",
    "\n",
    "#bet_coefficient=10000#投票金額を決定する係数 \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "start = datetime.strptime('20210101', '%Y%m%d').date()#2020分で検証\n",
    "end   = datetime.strptime('20220501', '%Y%m%d').date()\n",
    "for date_i in daterange(start, end):\n",
    "    try:\n",
    "        target_date_txt=date_i.strftime('%Y%m%d')\n",
    "        print(target_date_txt,\",\",place_name,\"==============================================\")\n",
    "        bet_get_log_df=calc_gain(place_name,place_num,target_date_txt)\n",
    "        get_race_add_db(bet_get_log_df)\n",
    "        get_date_add_db(bet_get_log_df)\n",
    "    except:\n",
    "        print(\"not_found_race_today\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
