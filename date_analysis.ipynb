{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn\n",
    "from pandas import DataFrame\n",
    "from tqdm import tqdm\n",
    "from imblearn.under_sampling import RandomUnderSampler #アンダーサンプリング用\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "# 機械学習用\n",
    "from sklearn.cluster import KMeans #クラスタリング用\n",
    "from sklearn.decomposition import PCA  #次元削減用\n",
    "from sklearn.ensemble import RandomForestClassifier#ランダムフォレスト\n",
    "from copy import deepcopy as cp\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "import time\n",
    "import datetime\n",
    "import os #ディレクトリ作成用\n",
    "import xgboost as xgb\n",
    "import sys\n",
    "\n",
    "\n",
    "#自作のモジュールのインポート\n",
    "import module.master as master\n",
    "import module.graph as graph\n",
    "import module.trans_text_code as trans\n",
    "import module.data_making as making\n",
    "import module.model_analysis as model_analysis#今回メインで使うモデル分析用のモジュール\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler#モデルの評価用に標準化する関数\n",
    "import scipy.stats#モデルの評価用に標準化する関数\n",
    "\n",
    "pd.set_option('display.width',400)#勝手に改行コードを入れられるのを防ぐ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデルの評価を入れる箱作り"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "place_master=master.get_place_master()\n",
    "for place in place_master.items():\n",
    "    #print(place[0],place[1],'\\n')\n",
    "    place_name=place[1]\n",
    "    dir_path=\"../bot_database/{place_name}/model_analysis_{place_name}/\".format(place_name=place_name)#作成したデータの書き込み先#使用するデータの読み込み\n",
    "    if os.path.exists(dir_path)==False:\n",
    "        os.makedirs(dir_path)\n",
    "    else:\n",
    "        pass\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# いったん全会場で分析する(csvだけ作っておく。)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#データ格納用のディレクトリ作り\n",
    "version='V2_1'#バージョン\n",
    "years=[2019.2020]\n",
    "\n",
    "place_master=master.get_place_master()\n",
    "for place in tqdm(place_master.items()):\n",
    "    place_name=place[1]\n",
    "    ################################################========================================================================================================================\n",
    "    ################################################========================================================================================================================\n",
    "    ################################################========================================================================================================================\n",
    "    ################################################========================================================================================================================\n",
    "    #各会場の成績の良かったモデルのスコアの読み込み\n",
    "    dir_path = \"../bot_database/{place_name}/{place_name}_train/train_{place_name}.csv\".format(place_name=place_name)#学習のためのベースになるリザルトデータ\n",
    "    result_base_df=pd.read_csv(dir_path)\n",
    "    result_base_df=result_base_df.drop([\"Unnamed: 0\"],axis=1)\n",
    "\n",
    "    model_dir_path = \"../bot_database/{place_name}/model_score_{place_name}/use_model/use_model_{place_name}_{V}.csv\".format(place_name=place_name,V=version)#使用するモデルのパラメータ読み込み\n",
    "    use_model_df=pd.read_csv(model_dir_path)\n",
    "    use_model_df=use_model_df.drop([\"Unnamed: 0\"],axis=1)\n",
    "    for year in years:\n",
    "        model_analysis.ym_analysis(result_base_df,use_model_df,place_name,version,year)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #model_analysis.use_model_para(good_score_df,place_name,version)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
