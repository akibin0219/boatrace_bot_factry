{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "answering-citation",
   "metadata": {},
   "source": [
    "# 運用時の過去レースデータ入れ替え用のスクリプト，今までの機能がまとめて入っている"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "checked-comfort",
   "metadata": {},
   "source": [
    "### （具体的に）\n",
    "HTML_data.ipynb<br>\n",
    "↓<br>\n",
    "trans_text_code.ipynb<br>\n",
    "↓<br>\n",
    "making_train_data.ipynb<br>\n",
    "### これらの機能がひとまとめになっている"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "plain-diary",
   "metadata": {},
   "source": [
    "## 三カ月に一回，このスクリプトを実行してメンテナンス用データの取得を行う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "colored-quest",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from matplotlib import pyplot as plt\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import seaborn\n",
    "from pandas import DataFrame\n",
    "from tqdm import tqdm\n",
    "from imblearn.under_sampling import RandomUnderSampler #アンダーサンプリング用\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "# 機械学習用\n",
    "from sklearn.cluster import KMeans #クラスタリング用\n",
    "from sklearn.ensemble import RandomForestClassifier#ランダムフォレスト\n",
    "from copy import deepcopy as cp\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import time\n",
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import os #ディレクトリ作成用\n",
    "import sys\n",
    "import codecs\n",
    "#自作のモジュールのインポート\n",
    "sys.path.append(\"..\")\n",
    "import module.master as master\n",
    "#import module.trans_text_code as trans#ロバストじゃないので今回で書き換えた"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "nonprofit-worst",
   "metadata": {
    "code_folding": [
     22,
     70,
     104
    ]
   },
   "outputs": [],
   "source": [
    "def get_season_date(now_date):#日付(datetime型)を渡すと，その日付で購買予測を行う際に使用するデータの区間を返す関数\n",
    "    use_data_year=now_date.year\n",
    "    if (now_date.month>=1)and(now_date.month<4):\n",
    "        use_data_month=1\n",
    "    elif (now_date.month>=4)and(now_date.month<7):\n",
    "        use_data_month=4\n",
    "    elif (now_date.month>=7)and(now_date.month<10):\n",
    "        use_data_month=7\n",
    "    elif (now_date.month>=10):\n",
    "        use_data_month=10\n",
    "    else:\n",
    "        print('what???????')\n",
    "    use_data_date=datetime.datetime(year=use_data_year, month=use_data_month,day=1)\n",
    "    return use_data_date\n",
    "\n",
    "def del_file(f_path):#受取ったパスにファイルがあれば削除して新ファイル生成，なければファイル生成だけ行う\n",
    "    if os.path.exists(f_path)==False:\n",
    "        pass\n",
    "    else:\n",
    "        os.remove('{f_path}'.format(f_path=f_path))\n",
    "    return None\n",
    "    \n",
    "def making_HTML_txt(now_ym):#現在の日付からクローリングを行って学習データを作成する関数,前年分の学習データが存在する前提で実行（今の年度分しか行ってくれない．）\n",
    "    print('HTMLのテキストファイルののためにクローリング中========================================================')\n",
    "    data_ym=get_season_date(now_ym)#区間の始まり日付を取得する\n",
    "    html_ym=data_ym- datetime.timedelta(days=1)#HTML収集時用の日付データ，区間の一日前までのHTMLを取得する（年マタギ防止時の問題防止のため）\n",
    "    print('now_ym(今日の日付):',now_ym)\n",
    "    print('data_ym(メンテナンス区間開始日の日付):',data_ym)\n",
    "    print('HTML_ym(クローリング最終日の日付)',html_ym)\n",
    "    for place in tqdm(place_master.items()):\n",
    "        place_num=place[0]\n",
    "        place_name=place[1]\n",
    "        url_list=[]\n",
    "        year=html_ym.year\n",
    "        txt_months=['01','02','03','04','05','06','07','08','09','10','11','12']\n",
    "        months=txt_months[:html_ym.month]\n",
    "        days=['01','02','03','04','05','06','07','08','09','10','11','12','13','14','15','16','17','18','19','20','21','22','23','24','25','26','27','28','29','30','31']\n",
    "        txt_f_path=\"../bot_database/{name}/{name}_result_txt/{year}_result_{name}.txt\".format(year=year,name=place_name)\n",
    "        del_file(txt_f_path)#前のメンテナンス時の区間のものがあったら一回消す(追記モードのため，消さないとおかしくなってしまう)\n",
    "        for month in months:\n",
    "            for day in days:\n",
    "                url=\"http://www1.mbrace.or.jp/od2/K/{year}{month}/{place_num}/{day}.html\".format(year=year,month=month,place_num=place_num,day=day)\n",
    "\n",
    "                #print('スクレイピング中',url)\n",
    "                HTML_res=requests.get(url)\n",
    "                HTML_res.encoding = HTML_res.apparent_encoding  # この行を追加\n",
    "                file_path=\"../bot_database/{name}/{name}_result_txt/{year}_result_{name}.txt\".format(year=year,name=place_name)\n",
    "\n",
    "                if HTML_res.status_code==200:#URLが存在するときのみスクレイピングを行う。\n",
    "                    HTML_doc=HTML_res.content#pip install chardet 要　文字化け防止\n",
    "                    date=datetime.date(int(year),int(month),int(day))\n",
    "                    #HTML=BeautifulSoup(HTML_doc,'lxml')#pip install lxmlでインストール要\n",
    "                    HTML=BeautifulSoup(HTML_doc,'html.parser')#pip install lxmlでインストール要\n",
    "                    result_data_text=[]\n",
    "                    for HTML in HTML.find_all('pre'):\n",
    "                        result_data_text.append(HTML.get_text())\n",
    "                    result_data_text[0]='\\n'\n",
    "                    with open(file_path,'a') as f:\n",
    "                        for i in range(len(result_data_text)):\n",
    "                            if(i==1):\n",
    "                                print('date:{}\\n'.format(date),file=f)\n",
    "                                print(result_data_text[i][:924],file=f)\n",
    "                            else:\n",
    "                                print(result_data_text[i][:924],file=f)\n",
    "                                print('\\n',file=f)\n",
    "                    time.sleep(2)\n",
    "                else:\n",
    "                     pass\n",
    "    return None\n",
    "\n",
    "def result_text_trans(now_ym):#HTMLのテキストファイルの文字コードをutf-8にまとめて変換する関数\n",
    "    print('HTMLのテキストファイルの文字コードを変換中========================================================')\n",
    "    place_master=master.get_place_master()\n",
    "    for place in place_master.items():\n",
    "        place_name=place[1]\n",
    "        dir_path = \"../bot_database/{place_name}/{place_name}_result_txt_utf8/\".format(place_name=place_name)\n",
    "        if os.path.exists(dir_path)==False:\n",
    "            os.makedirs(dir_path)\n",
    "        else:\n",
    "            pass\n",
    "    #テキストファイルの文字コードの変換==========================================================\n",
    "    data_ym=get_season_date(now_ym)#区間の始まり日付を取得する\n",
    "    html_ym=data_ym- datetime.timedelta(days=1)#HTML収集時用の日付データ，区間の一日前までのHTMLを取得する（年マタギ防止時の問題防止のため）\n",
    "    print('now_ym(今日の日付):',now_ym)\n",
    "    print('HTML_ym(クローリング最終日の日付)',html_ym)\n",
    "    end_year=html_ym.year\n",
    "    years=['{}'.format(year) for year in np.arange(2012,end_year+1)]#エンコード方式を変更する元テキストファイルがある年度(クローリング結果)\n",
    "    for place in tqdm(place_master.items()):\n",
    "        place_name=place[1]\n",
    "        url_list=[]\n",
    "        for year in years:\n",
    "            read_fpath=\"../bot_database/{place_name}/{place_name}_result_txt/{year}_result_{place_name}.txt\".format(place_name=place_name,year=year)\n",
    "            write_fpath=\"../bot_database/{place_name}/{place_name}_result_txt_utf8/{year}_result_{place_name}_utf8.txt\".format(place_name=place_name,year=year)\n",
    "            try:\n",
    "                sf = codecs.open(read_fpath, 'r', encoding='shift-jis')\n",
    "                uf = codecs.open(write_fpath, 'w', encoding='utf-8')\n",
    "                for line in sf:\n",
    "                    uf.write(line)\n",
    "                sf.close()\n",
    "                uf.close()\n",
    "            except FileNotFoundError:\n",
    "                print('file_not_found_error!!!!!!!!!!',place_name,year)\n",
    "    return None\n",
    "\n",
    "def result_csv_make(now_ym):#HTMLのテキストファイルから必要な情報をぬきだして　csvに変換する関数\n",
    "    #ディレクトリを作っておく\n",
    "    print('HTMLのテキストファイルからresult_csvを製作中========================================================')\n",
    "    data_ym=get_season_date(now_ym)#区間の始まり日付を取得する\n",
    "    html_ym=data_ym- datetime.timedelta(days=1)#HTML収集時用の日付データ，区間の一日前までのHTMLを取得する（年マタギ防止時の問題防止のため）\n",
    "    print('now_ym(今日の日付):',now_ym)\n",
    "    print('HTML_ym(クローリング最終日の日付)',html_ym)\n",
    "    end_year=html_ym.year\n",
    "    years=['{}'.format(year) for year in np.arange(2012,end_year+1)]#エンコード方式を変更する元テキストファイルがある年度(クローリング結果)\n",
    "    place_master=master.get_place_master()\n",
    "    for place in place_master.items():\n",
    "        place_name=place[1]\n",
    "        dir_path = \"../bot_database/{place_name}/{place_name}_result_csv/\".format(place_name=place_name)\n",
    "        if os.path.exists(dir_path)==False:\n",
    "            os.makedirs(dir_path)\n",
    "        else:\n",
    "            pass\n",
    "    for place in tqdm(place_master.items()):\n",
    "        place_name=place[1]\n",
    "        #print(place_name,'\\n')\n",
    "        #years=['2012','2013','2014','2015','2016','2017','2018','2019','2020']\n",
    "        place=place_name\n",
    "        date='2222-22-22'\n",
    "        racer_1 = 0  # 同着レースを見つけるための印付け\n",
    "        racer_2 = 0  # 同着レースを見つけるための印付け\n",
    "        racer_3 = 0  # 同着レースを見つけるための印付け\n",
    "        for year in years:\n",
    "            train_data_df=pd.DataFrame(columns=['date','result_com','number_race','racer_1_ID','racer_2_ID','racer_3_ID','racer_4_ID','racer_5_ID','racer_6_ID'])\n",
    "            #read_resultdata_path = \"{}_result_txt/{}_result_{}.txt\".format(place,year,place)\n",
    "            read_resultdata_path = \"../bot_database/{place_name}/{place_name}_result_txt_utf8/{year}_result_{place_name}_utf8.txt\".format(place_name=place_name,year=year)\n",
    "            #write_file_path=\"{}_result_csv2/{}_result_{}.csv\".format(place,year,place)\n",
    "            write_file_path=\"../bot_database/{place_name}/{place_name}_result_csv/{place_name}_result_{year}.csv\".format(year=year,place_name=place_name)\n",
    "            try:\n",
    "                resultdata = open(read_resultdata_path, \"r\", encoding=\"utf-8_sig\")\n",
    "                money=0\n",
    "                normal_race=0\n",
    "                get_money=0\n",
    "                for line in resultdata:\n",
    "                # print(line[:12])\n",
    "                # print(line[4:5]) #レースを示す\"R\"の入っている位置\n",
    "                # print(line[3:4])#レースの番号が入っている位置\n",
    "                # print(line[2:4])#着の情報が入っている位置\n",
    "                # print(line[6:7])#艇番号の入っている位置\n",
    "                # print(line[8:12])#登録暗号４桁の入っている位置\n",
    "                # ////////////////////////////////以下レース番号の取得\n",
    "                    if line[0]=='d':\n",
    "                        date=line[5:15]\n",
    "                    if line[4:5] == \"R\":\n",
    "                        if line[2:4]==\"10\":\n",
    "                            number_race=line[2:4]\n",
    "                        elif line[2:4]==\"11\":\n",
    "                            number_race=line[2:4]\n",
    "                        elif line[2:4]==\"12\":\n",
    "                            number_race=line[2:4]\n",
    "                        else:\n",
    "                            number_race = line[3:4]\n",
    "                        racer_1 = 0  # 同着レースを見つけるための印付け\n",
    "                        racer_2 = 0  # 同着レースを見つけるための印付け\n",
    "                        racer_3 = 0  # 同着レースを見つけるための印付け\n",
    "            # //////////////////////////////以下着順獲得\n",
    "                # racer_1st=0#同着レースを見つけるための印付け\n",
    "                # racer_2st=0#同着レースを見つけるための印付け\n",
    "                    if line[2:4] == \"01\":\n",
    "                        racer_1 = int(line[6:7])\n",
    "                    elif line[2:4] == \"02\":\n",
    "                        racer_2 = int(line[6:7])\n",
    "                    elif line[2:4] == \"03\":\n",
    "                        racer_3 = int(line[6:7])\n",
    "\n",
    "            # //////////////////////////////////以下選手の登録番号取得\n",
    "                    if line[6:7] == \"1\":\n",
    "                        racer_1_ID = int(line[8:12])\n",
    "                        racer_1_b=int(line[22:24])#ボート番号\n",
    "                        racer_1_m=int(line[27:29])#モータ番号\n",
    "                    elif line[6:7] == \"2\":\n",
    "                        racer_2_ID = int(line[8:12])\n",
    "                        racer_2_b=int(line[22:24])\n",
    "                        racer_2_m=int(line[27:29])\n",
    "                    elif line[6:7] == \"3\":\n",
    "                        racer_3_ID = int(line[8:12])\n",
    "                        racer_3_b=int(line[22:24])\n",
    "                        racer_3_m=int(line[27:29])\n",
    "                    elif line[6:7] == \"4\":\n",
    "                        racer_4_ID = int(line[8:12])\n",
    "                        racer_4_b=int(line[22:24])\n",
    "                        racer_4_m=int(line[27:29])\n",
    "                    elif line[6:7] == \"5\":\n",
    "                        racer_5_ID = int(line[8:12])\n",
    "                        racer_5_b=int(line[22:24])\n",
    "                        racer_5_m=int(line[27:29])\n",
    "                    elif line[6:7] == \"6\":\n",
    "                        racer_6_ID = int(line[8:12])\n",
    "                        racer_6_b=int(line[22:24])\n",
    "                        racer_6_m=int(line[27:29])\n",
    "            # //////////////////以下着順の組み合わせの選別\n",
    "                    if racer_1!=0 and racer_2!=0 and racer_3!=0: \n",
    "                        if line[2:4] == \"06\":\n",
    "                            racers_arr=['1','2','3','4','5','6']\n",
    "                            result_com=0\n",
    "                            result_com+=(racer_1 - 1)*20\n",
    "                            #racers_arr=racers_arr.remove(str(racer_1))\n",
    "                            racers_arr.remove(str(racer_1))\n",
    "                            index_2=racers_arr.index(str(racer_2))\n",
    "                            result_com+=index_2*4\n",
    "                            #racers_arr=racers_arr.remove(str(racer_2))\n",
    "                            racers_arr.remove(str(racer_2))\n",
    "                            index_3=racers_arr.index(str(racer_3))\n",
    "                            result_com+=(index_3+1)\n",
    "            # /////////////////////////////////以下取り出した情報をdataframe化\n",
    "                 #レースの配当金の情報を追加する\n",
    "                    if line[8:9] == \"３\":\n",
    "                        if get_money==0:\n",
    "                            money=line[23:29]\n",
    "                            try:\n",
    "                                money=int(money)\n",
    "                                get_money=1\n",
    "                            except ValueError:\n",
    "                                print('Error')\n",
    "                                get_money=0\n",
    "                # /////////////////////////////////以下取り出した情報をdataframe化\n",
    "                    if line[2:4] == \"06\":#フライング、事故が発生したレースを除外するために6(全員着を得ている)があるときのみ書き込み\n",
    "                        normal_race=1\n",
    "                        money=0\n",
    "                        get_money=0\n",
    "                    if (money!=0) and (normal_race==1):#フライング、事故が発生したレースを除外するために6(全員着を得ている)があるときのみ書き込み\n",
    "                        add_dict = {'date':date,\"result_com\": result_com,\"money\":money, \"number_race\": number_race, \"racer_1_ID\": racer_1_ID, \"racer_2_ID\": racer_2_ID,\"racer_3_ID\": racer_3_ID, \"racer_4_ID\": racer_4_ID, \"racer_5_ID\": racer_5_ID, \"racer_6_ID\": racer_6_ID,'racer_1_b':racer_1_b,'racer_1_m':racer_1_m,'racer_2_b':racer_2_b,'racer_2_m':racer_2_m,'racer_3_b':racer_3_b,'racer_3_m':racer_3_m,'racer_4_b':racer_4_b,'racer_4_m':racer_4_m,'racer_5_b':racer_5_b,'racer_5_m':racer_5_m,'racer_6_b':racer_6_b,'racer_6_m':racer_6_m}\n",
    "                        add_df = pd.DataFrame(add_dict, index=[''])\n",
    "                        train_data_df = train_data_df.append(add_df)\n",
    "                        money=0\n",
    "                        normal_race=0\n",
    "                #//////////////////////////////////////CSVファイルへ出力\n",
    "                train_data_df.to_csv(write_file_path)\n",
    "            except FileNotFoundError:\n",
    "                print('file_not_found_error!!!!!!!!!!',place_name,year)\n",
    "    return None\n",
    "\n",
    "def train_csv_make(now_ym):#今の区間までのhtmlから作成したレースデータcsvに別でダウンロードした半期の選手データを結合する,選手データは手動で配置\n",
    "    #ディレクトリを作っておく\n",
    "    print('result_csvと結合してtrainデータを製作中========================================================')\n",
    "    data_ym=get_season_date(now_ym)#区間の始まり日付を取得する\n",
    "    html_ym=data_ym- datetime.timedelta(days=1)#HTML収集時用の日付データ，区間の一日前までのHTMLを取得する（年マタギ防止時の問題防止のため）\n",
    "    print('now_ym(今日の日付):',now_ym)\n",
    "    print('HTML_ym(クローリング最終日の日付)',html_ym)\n",
    "    end_year=html_ym.year\n",
    "    years=['{}'.format(year) for year in np.arange(2012,end_year+1)]#エンコード方式を変更する元テキストファイルがある年度(クローリング結果)\n",
    "    place_master=master.get_place_master()\n",
    "    for place in tqdm(place_master.items()):\n",
    "        place_name=place[1]\n",
    "        dir_path = \"../bot_database/{place_name}/{place_name}_train/\".format(place_name=place_name)\n",
    "        if os.path.exists(dir_path)==False:\n",
    "            os.makedirs(dir_path)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        dir_path2 = \"../bot_database/{place_name}/{place_name}_train/train_by_year/\".format(place_name=place_name)\n",
    "        if os.path.exists(dir_path2)==False:\n",
    "            os.makedirs(dir_path2)\n",
    "        else:\n",
    "            pass\n",
    "        train_data_df=pd.DataFrame(columns=['date','result_com','money','number_race','racer_1_ID','racer_2_ID','racer_3_ID','racer_4_ID','racer_5_ID','racer_6_ID','racer_1_rank','racer_1_male','racer_1_age','racer_1_doub','racer_1_ave_st','racer_2_rank','racer_2_male','racer_2_age','racer_2_doub','racer_2_ave_st','racer_3_rank','racer_3_male','racer_3_age','racer_3_doub','racer_3_ave_st','racer_4_rank','racer_4_male','racer_4_age','racer_4_doub','racer_4_ave_st','racer_5_rank','racer_5_male','racer_5_age','racer_5_doub','racer_5_ave_st','racer_6_rank','racer_6_male','racer_6_age','racer_6_doub','racer_6_ave_st'])\n",
    "        #years=[\"12\",\"13\",\"14\",\"15\",\"16\",\"17\",\"18\",\"19\",\"20\"]\n",
    "        para_year=['{}'.format(year)[-2:]for year in np.arange(2012,end_year+1)]#パラメータシート読み込み用に年度を加工（下二桁）\n",
    "        place=place_name\n",
    "        write_train_file_path=\"../bot_database/{place_name}/{place_name}_train/train_{place_name}.csv\".format(place_name=place_name)\n",
    "        for year in para_year:\n",
    "            #使用するファイルの定義\n",
    "            para_file_path=\"../bot_database/racer_para/{year}/{year}.csv\".format(year=year)\n",
    "            result_file_path=\"../bot_database/{place_name}/{place_name}_result_csv/{place_name}_result_20{year}.csv\".format(place_name=place_name,year=year)\n",
    "            write_train_by_year_file_path=\"../bot_database/{place_name}/{place_name}_train/train_by_year/train_20{year}_{place_name}.csv\".format(place_name=place_name,year=year)#作成したデータの書き込み先\n",
    "            try:\n",
    "                #/////////////////////////////////////////////以下データフレームの作成\n",
    "                train_data_by_year_df=pd.DataFrame(columns=['date','result_com','money','number_race','racer_1_ID','racer_2_ID','racer_3_ID','racer_4_ID','racer_5_ID','racer_6_ID','racer_1_rank','racer_1_male','racer_1_age','racer_1_doub','racer_1_ave_st','racer_2_rank','racer_2_male','racer_2_age','racer_2_doub','racer_2_ave_st','racer_3_rank','racer_3_male','racer_3_age','racer_3_doub','racer_3_ave_st','racer_4_rank','racer_4_male','racer_4_age','racer_4_doub','racer_4_ave_st','racer_5_rank','racer_5_male','racer_5_age','racer_5_doub','racer_5_ave_st','racer_6_rank','racer_6_male','racer_6_age','racer_6_doub','racer_6_ave_st'])\n",
    "                para_df=pd.read_csv(para_file_path)\n",
    "                para_df=para_df.drop([\"Unnamed: 0\"],axis=1)#csvファイルについている名無しの列を削除\n",
    "                result_df=pd.read_csv(result_file_path)\n",
    "                result_df=result_df.drop([\"Unnamed: 0\"],axis=1)#csvファイルについている名無しの列を削除\n",
    "\n",
    "                ####==========================================\n",
    "                resultdata = open(result_file_path, \"r\", encoding=\"utf-8_sig\")\n",
    "                money=0\n",
    "                normal_race=0\n",
    "                get_money=0\n",
    "                for index,series in result_df.iterrows():\n",
    "                    add_df=pd.DataFrame(columns=['date','result_com','money','number_race','racer_1_ID','racer_2_ID','racer_3_ID','racer_4_ID','racer_5_ID','racer_6_ID','racer_1_rank','racer_1_male','racer_1_age','racer_1_doub','racer_1_ave_st','racer_2_rank','racer_2_male','racer_2_age','racer_2_doub','racer_2_ave_st','racer_3_rank','racer_3_male','racer_3_age','racer_3_doub','racer_3_ave_st','racer_4_rank','racer_4_male','racer_4_age','racer_4_doub','racer_4_ave_st','racer_5_rank','racer_5_male','racer_5_age','racer_5_doub','racer_5_ave_st','racer_6_rank','racer_6_male','racer_6_age','racer_6_doub','racer_6_ave_st'])\n",
    "                    #///////////////////////////////////////レースに出ているレーサーの成績を検索＆取得\n",
    "                    ID_1=series['racer_1_ID']\n",
    "                    ID_2=series['racer_2_ID']\n",
    "                    ID_3=series['racer_3_ID']\n",
    "                    ID_4=series['racer_4_ID']\n",
    "                    ID_5=series['racer_5_ID']\n",
    "                    ID_6=series['racer_6_ID']\n",
    "                    racer_1_df=para_df[para_df['racer_ID']==ID_1]\n",
    "                    racer_2_df=para_df[para_df['racer_ID']==ID_2]\n",
    "                    racer_3_df=para_df[para_df['racer_ID']==ID_3]\n",
    "                    racer_4_df=para_df[para_df['racer_ID']==ID_4]\n",
    "                    racer_5_df=para_df[para_df['racer_ID']==ID_5]\n",
    "                    racer_6_df=para_df[para_df['racer_ID']==ID_6]\n",
    "\n",
    "                    if series['result_com']==40:\n",
    "                        pass#同着のデータは削除\n",
    "                    #追加していくデータフレームを作成\n",
    "                    else:\n",
    "                        add_df= pd.DataFrame({'date':series['date'],\n",
    "                                                'result_com':series['result_com'],\n",
    "                                                'money':series['money'],\n",
    "                                                'number_race':series['number_race'],\n",
    "                                                'racer_1_ID':series['racer_1_ID'],\n",
    "                                                'racer_2_ID':series['racer_2_ID'],\n",
    "                                                'racer_3_ID':series['racer_3_ID'],\n",
    "                                                'racer_4_ID':series['racer_4_ID'],\n",
    "                                                'racer_5_ID':series['racer_5_ID'],\n",
    "                                                'racer_6_ID':series['racer_6_ID'],\n",
    "                                                'racer_1_bo':series['racer_1_b'],\n",
    "                                                'racer_1_mo':series['racer_1_m'],\n",
    "                                                'racer_2_bo':series['racer_2_b'],\n",
    "                                                'racer_2_mo':series['racer_2_m'],\n",
    "                                                'racer_3_bo':series['racer_3_b'],\n",
    "                                                'racer_3_mo':series['racer_3_m'],\n",
    "                                                'racer_4_bo':series['racer_4_b'],\n",
    "                                                'racer_4_mo':series['racer_4_m'],\n",
    "                                                'racer_5_bo':series['racer_5_b'],\n",
    "                                                'racer_5_mo':series['racer_5_m'],\n",
    "                                                'racer_6_bo':series['racer_6_b'],\n",
    "                                                'racer_6_mo':series['racer_6_m'],\n",
    "                                                'racer_1_rank':racer_1_df.iat[0,1],\n",
    "                                                'racer_1_male':racer_1_df.iat[0,2],\n",
    "                                                'racer_1_age':racer_1_df.iat[0,3],\n",
    "                                                'racer_1_doub':racer_1_df.iat[0,4],\n",
    "                                                'racer_1_ave_st':racer_1_df.iat[0,5],\n",
    "                                                'racer_2_rank':racer_2_df.iat[0,1],\n",
    "                                                'racer_2_male':racer_2_df.iat[0,2],\n",
    "                                                'racer_2_age':racer_2_df.iat[0,3],\n",
    "                                                'racer_2_doub':racer_2_df.iat[0,4],\n",
    "                                                'racer_2_ave_st':racer_2_df.iat[0,5],\n",
    "                                                'racer_3_rank':racer_3_df.iat[0,1],\n",
    "                                                'racer_3_male':racer_3_df.iat[0,2],\n",
    "                                                'racer_3_age':racer_3_df.iat[0,3],\n",
    "                                                'racer_3_doub':racer_3_df.iat[0,4],\n",
    "                                                'racer_3_ave_st':racer_3_df.iat[0,5],\n",
    "                                                'racer_4_rank':racer_4_df.iat[0,1],\n",
    "                                                'racer_4_male':racer_4_df.iat[0,2],\n",
    "                                                'racer_4_age':racer_4_df.iat[0,3],\n",
    "                                                'racer_4_doub':racer_4_df.iat[0,4],\n",
    "                                                'racer_4_ave_st':racer_4_df.iat[0,5],\n",
    "                                                'racer_5_rank':racer_5_df.iat[0,1],\n",
    "                                                'racer_5_male':racer_5_df.iat[0,2],\n",
    "                                                'racer_5_age':racer_5_df.iat[0,3],\n",
    "                                                'racer_5_doub':racer_5_df.iat[0,4],\n",
    "                                                'racer_5_ave_st':racer_5_df.iat[0,5],\n",
    "                                                'racer_6_rank':racer_6_df.iat[0,1],\n",
    "                                                'racer_6_male':racer_6_df.iat[0,2],\n",
    "                                                'racer_6_age':racer_6_df.iat[0,3],\n",
    "                                                'racer_6_doub':racer_6_df.iat[0,4],\n",
    "                                                'racer_6_ave_st':racer_6_df.iat[0,5] }, index=[''])\n",
    "                    #//////////////////////////////データフレームにadd_dfを追加していく。\n",
    "                    train_data_by_year_df=train_data_by_year_df.append(add_df)\n",
    "                    train_data_df=train_data_df.append(add_df)\n",
    "                train_data_by_year_df.to_csv(write_train_by_year_file_path)\n",
    "            except FileNotFoundError:\n",
    "\n",
    "                print('file_not_found_error!!!!!!!!!!',place_name,year)\n",
    "        train_data_df.to_csv(write_train_file_path,encoding=\"utf-8_sig\")\n",
    "    return None #何も返さない"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "changed-english",
   "metadata": {},
   "outputs": [],
   "source": [
    "place_master=master.get_place_master()\n",
    "for place in place_master.items():\n",
    "    #print(place[0],place[1],'\\n')\n",
    "    dir_path = \"../bot_database/{}/{}_result_txt\".format(place[1],place[1])\n",
    "    if os.path.exists(dir_path)==False:\n",
    "        os.makedirs(dir_path)\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suspected-salad",
   "metadata": {},
   "source": [
    "## 一下にすべての機能をまとめる（これをさらに一つの関数にまとめてもいいかも）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "nominated-formula",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-20 ======================================\n",
      "HTMLのテキストファイルののためにクローリング中========================================================\n",
      "now_ym(今日の日付): 2021-10-20\n",
      "data_ym(メンテナンス区間開始日の日付): 2021-10-01 00:00:00\n",
      "HTML_ym(クローリング最終日の日付) 2021-09-30 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 24/24 [5:53:30<00:00, 883.77s/it]\n",
      "  0%|                                                                                           | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTMLのテキストファイルの文字コードを変換中========================================================\n",
      "now_ym(今日の日付): 2021-10-20\n",
      "HTML_ym(クローリング最終日の日付) 2021-09-30 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|████████████████████████████████████████████▍                                     | 13/24 [00:07<00:06,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_not_found_error!!!!!!!!!! naruto 2015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [00:13<00:00,  1.79it/s]\n",
      "  0%|                                                                                           | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTMLのテキストファイルからresult_csvを製作中========================================================\n",
      "now_ym(今日の日付): 2021-10-20\n",
      "HTML_ym(クローリング最終日の日付) 2021-09-30 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|████████████████████████████████████████████▍                                     | 13/24 [07:57<06:41, 36.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_not_found_error!!!!!!!!!! naruto 2015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [14:37<00:00, 36.55s/it]\n",
      "  0%|                                                                                           | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result_csvと結合してtrainデータを製作中========================================================\n",
      "now_ym(今日の日付): 2021-10-20\n",
      "HTML_ym(クローリング最終日の日付) 2021-09-30 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|██████████████████████████████████████████▊                                    | 13/24 [1:07:17<56:17, 307.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_not_found_error!!!!!!!!!! naruto 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 24/24 [2:04:37<00:00, 311.57s/it]\n"
     ]
    }
   ],
   "source": [
    "today=datetime.date.today()#今日の日付の取得\n",
    "print(today,'======================================')\n",
    "making_HTML_txt(today)#クローリング，テキストファイルの生成\n",
    "result_text_trans(today)#文字コードの変換とutf-8b版の出力\n",
    "result_csv_make(today)#HTMLのテキストファイルから必要な情報をぬきだして　csvに変換する関数\n",
    "train_csv_make(today)#今の区間までのhtmlから作成したレースデータcsvに別でダウンロードした半期の選手データを結合する,選手データは手動で配置\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bearing-occasions",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "magnetic-performance",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "overall-tuition",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 機能作成，チェック"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "anticipated-development",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['12', '13', '14', '15', '16', '17', '18', '19', '20', '21']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "para_year=['{}'.format(year)[-2:]for year in np.arange(2012,end_year+1)]#エンコード方式を変更する元テキストファイルがある年度(クローリング結果)\n",
    "para_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eleven-hardwood",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_ym=get_season_date(now_ym)#区間の始まり日付を取得する\n",
    "html_ym=data_ym- datetime.timedelta(days=1)#HTML収集時用の日付データ，区間の一日前までのHTMLを取得する（年マタギ防止時の問題防止のため）\n",
    "print('now_ym(今日の日付):',now_ym)\n",
    "print('HTML_ym(クローリング最終日の日付)',html_ym)\n",
    "end_year=html_ym.year\n",
    "years=['{}'.format(year) for year in np.arange(2012,end_year+1)]#エンコード方式を変更する元テキストファイルがある年度(クローリング結果)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "working-posting",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/24 [00:23<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-3c43bd958983>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[1;31m#print('スクレイピング中',url)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m             \u001b[0mHTML_res\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m             \u001b[0mHTML_res\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mHTML_res\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapparent_encoding\u001b[0m  \u001b[1;31m# この行を追加\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[0mfile_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"../bot_database/{name}/{name}_result_txt/{year}_result_{name}.txt\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myear\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0myear\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mplace_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\takuma\\nabepy\\env\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'allow_redirects'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'get'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\takuma\\nabepy\\env\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\takuma\\nabepy\\env\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    540\u001b[0m         }\n\u001b[0;32m    541\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m         \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\takuma\\nabepy\\env\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    653\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    654\u001b[0m         \u001b[1;31m# Send the request\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 655\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    656\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    657\u001b[0m         \u001b[1;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\takuma\\nabepy\\env\\lib\\site-packages\\requests\\adapters.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    437\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mchunked\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 439\u001b[1;33m                 resp = conn.urlopen(\n\u001b[0m\u001b[0;32m    440\u001b[0m                     \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m                     \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\takuma\\nabepy\\env\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    697\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m             \u001b[1;31m# Make the request on the httplib connection object.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m             httplib_response = self._make_request(\n\u001b[0m\u001b[0;32m    700\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\takuma\\nabepy\\env\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    443\u001b[0m                     \u001b[1;31m# Python 3 (including for exceptions like SystemExit).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    444\u001b[0m                     \u001b[1;31m# Otherwise it looks like a bug in the code.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 445\u001b[1;33m                     \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    446\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSocketError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\takuma\\nabepy\\env\\lib\\site-packages\\urllib3\\packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;32mc:\\users\\takuma\\nabepy\\env\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    438\u001b[0m                 \u001b[1;31m# Python 3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m                     \u001b[0mhttplib_response\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m                     \u001b[1;31m# Remove the TypeError from the exception chain in\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\http\\client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1345\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1346\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1347\u001b[1;33m                 \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1348\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\http\\client.py\u001b[0m in \u001b[0;36mbegin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    305\u001b[0m         \u001b[1;31m# read until we get a non-100 response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 307\u001b[1;33m             \u001b[0mversion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    266\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 268\u001b[1;33m         \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"iso-8859-1\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    269\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"status line\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    667\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    668\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 669\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    670\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    671\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "loaded-proceeding",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mature-storage",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#for year in years:\n",
    "    \n",
    "    print(year,'年目が終了')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "isolated-alias",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
