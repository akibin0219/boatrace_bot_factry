{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "patient-efficiency",
   "metadata": {},
   "source": [
    "# V4系列で，バージョンごとに最終的な評価値を出す．(区間５カ月は行わない予定)\n",
    "なんとなくどの　パラメータを可変していけば何が変わるのかの感覚がつかめたので，その感覚を大事にしながら総当たりでパラメータを可変していく．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "caroline-dream",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import seaborn\n",
    "from pandas import DataFrame\n",
    "from tqdm import tqdm\n",
    "from imblearn.under_sampling import RandomUnderSampler #アンダーサンプリング用\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "# 機械学習用\n",
    "from sklearn.cluster import KMeans #クラスタリング用\n",
    "from sklearn.ensemble import RandomForestClassifier#ランダムフォレスト\n",
    "from copy import deepcopy as cp\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import time\n",
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import os #ディレクトリ作成用\n",
    "import xgboost as xgb\n",
    "import sys\n",
    "#自作のモジュールのインポート\n",
    "sys.path.append(\"..\")\n",
    "import module.master as master\n",
    "import module.modeling_scores as modeling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "right-causing",
   "metadata": {},
   "source": [
    "## 関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "hydraulic-cover",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def gainth_analysis(score_df,test_type='final'):\n",
    "    \n",
    "    gainth_arr=[100,110,120,140,160]\n",
    "    index_arr=[0,1,2,3,4]\n",
    "    cols=[\"gain_th\",\"num_com\",\"num_model(row)\"]\n",
    "    gainth_df=pd.DataFrame(columns=cols)\n",
    "    def make_series(target_df):\n",
    "        num_com=len(target_df['target_com'].value_counts().index)\n",
    "        num_model=len(target_df)\n",
    "        return num_com,num_model\n",
    "    for gainth,i in zip(gainth_arr,index_arr):\n",
    "        append_s=pd.Series(index=cols,dtype='object')\n",
    "        if (i==0):\n",
    "            target_df=score_df[score_df[\"gain_{}\".format(test_type)]<gainth]\n",
    "            num_com,num_model=make_series(target_df)\n",
    "            append_s['gain_th']=\"100未満\"\n",
    "            append_s['num_com']=num_com\n",
    "            append_s['num_model(row)']=num_model\n",
    "        elif (i==4):\n",
    "            target_df=score_df[score_df[\"gain_{}\".format(test_type)]>=gainth]\n",
    "            num_com,num_model=make_series(target_df)\n",
    "            append_s['gain_th']=\"150以上\"\n",
    "            append_s['num_com']=num_com\n",
    "            append_s['num_model(row)']=num_model\n",
    "        else:\n",
    "            target_df=score_df[(score_df[\"gain_{}\".format(test_type)]<gainth_arr[i])&(score_df[\"gain_{}\".format(test_type)]>=gainth_arr[i-1])]\n",
    "            num_com,num_model=make_series(target_df)\n",
    "            append_s['gain_th']=\"{}以上_{}未満\".format(gainth_arr[i-1],gainth_arr[i])\n",
    "            append_s['num_com']=num_com\n",
    "            append_s['num_model(row)']=num_model\n",
    "        gainth_df=gainth_df.append(append_s,ignore_index=True)\n",
    "    return gainth_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "communist-authorization",
   "metadata": {},
   "source": [
    "## バージョンごとに1DF 出力する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "centered-spelling",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version:V4_1_______mode:recent===================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 25/25 [54:07<00:00, 129.88s/it]\n",
      "  0%|                                                                                           | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version:V4_1_______mode:period===================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 25/25 [54:33<00:00, 130.94s/it]\n",
      "  0%|                                                                                           | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version:V4_2_______mode:recent===================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 25/25 [54:11<00:00, 130.06s/it]\n",
      "  0%|                                                                                           | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version:V4_2_______mode:period===================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 25/25 [54:49<00:00, 131.59s/it]\n",
      "  0%|                                                                                           | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version:V4_3_______mode:recent===================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 25/25 [3:30:18<00:00, 504.75s/it]\n",
      "  0%|                                                                                           | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version:V4_3_______mode:period===================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 25/25 [3:53:18<00:00, 559.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n",
      "elapsed time::39680.50764346123==================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# #きめのパラメータ\n",
    "# place_name='asiya'\n",
    "# plus_m_th=2\n",
    "# num_hit_th=3\n",
    "# versions=['V4_1','V4_2','V4_3']\n",
    "# modes=['asiya_model_score_','asiya_model_score_period_']#モードは直近三カ月と，昨年同月の二種類\n",
    "# mode_types=['recent','period']#モードは直近三カ月と，昨年同月の二種類,modesと一緒にzipで回す\n",
    "# #きめじゃないパラメータの範囲設定(ループの数に注意！！)\n",
    "# gain_ths=np.arange(80, 180,4)\n",
    "# gain_std_ths=np.arange(10, 250,15)\n",
    "# hit_per_ths=np.arange(0,20,2)\n",
    "# hit_std_ths=np.arange(0, 2.0, 0.4)\n",
    "# time_sta = time.time()\n",
    "\n",
    "\n",
    "\n",
    "# #コード本文\n",
    "# for version in versions:\n",
    "#     for mode,mode_type in zip(modes,mode_types):\n",
    "#         analysis_v_df=pd.DataFrame(columns=['minus_model_per_mean','num_plus_com_mean','num_plus_model_mean','gain_th','gain_std_th','hit_per_th','hit_std_th'])\n",
    "#         print('version:{}_______mode:{}==================================================='.format(version,mode_type))\n",
    "#         #こっから下はバージョン，モードごと\n",
    "#         for gain_th in tqdm(gain_ths):\n",
    "#             for gain_std_th in gain_std_ths:\n",
    "#                 for hit_per_th in hit_per_ths:\n",
    "#                     for hit_std_th in hit_std_ths:\n",
    "#                         append_s=pd.Series(dtype='object')\n",
    "#                         for i in range(4):\n",
    "#                             now_ym=datetime.datetime(year=2020, month=1+(i*3),day=1).strftime('%Y%m%d')\n",
    "#                             dir_path='../../bot_database/{place_name}/model_score_{place_name}/v4_score/{version}/{mode}st{now_ym}_finalM3_{version}.csv'.format(place_name=place_name,mode=mode,now_ym=now_ym,version=version)\n",
    "#                             model_score_df=pd.read_csv(dir_path, encoding='utf_8_sig')\n",
    "#                             model_score_df=model_score_df.drop([\"Unnamed: 0\"],axis=1)\n",
    "#                             #決めのパラメータでいったん切り落とし\n",
    "#                             model_score_df=model_score_df[model_score_df['plus_month_num_test']>=plus_m_th].copy()#収益がプラスだった月の数で切り捨てる\n",
    "#                             model_score_df=model_score_df[model_score_df['num_hit_test']>=num_hit_th].copy()#的中した予測の数で切り捨てる，大体一カ月に一件くらいをイメージ\n",
    "#                             #可変していくパラメータ\n",
    "#                             target_df=model_score_df[model_score_df['gain_test']>=gain_th].copy()\n",
    "#                             target_df=target_df[target_df['gain_std_test']<=gain_std_th].copy()\n",
    "#                             target_df=target_df[target_df['buy_hit_per_test']>=hit_per_th].copy()\n",
    "#                             target_df=target_df[target_df['buy_hit_per_std_test']<=hit_std_th].copy()\n",
    "#                             analysis_df=gainth_analysis(target_df,test_type='final')\n",
    "#                             minus_df=analysis_df.loc[:'100以上_110未満'].copy()\n",
    "#                             plus_df=analysis_df.loc['100以上_110未満':].copy()\n",
    "#                             try:\n",
    "#                                 minus_model_per=(minus_df['num_model(row)'].sum()/analysis_df['num_model(row)'].sum())*100\n",
    "#                             except ZeroDivisionError:\n",
    "#                                 minus_model_per=100\n",
    "#                             append_s['st_{}_minus_per(model)'.format(now_ym)]=minus_model_per\n",
    "#                             append_s['st_{}_num_plus_com'.format(now_ym)]=plus_df['num_com'].sum()\n",
    "#                             append_s['st_{}_num_plus_model(row)'.format(now_ym)]=plus_df['num_model(row)'].sum()\n",
    "#                         append_s['gain_th']=gain_th\n",
    "#                         append_s['gain_std_th']=gain_std_th\n",
    "#                         append_s['hit_per_th']=hit_per_th\n",
    "#                         append_s['hit_std_th']=hit_std_th\n",
    "#                         analysis_v_df=analysis_v_df.append(append_s,ignore_index=True)\n",
    "#         analysis_v_df['minus_model_per_mean']=((analysis_v_df['st_20200101_minus_per(model)']+analysis_v_df['st_20200401_minus_per(model)']+analysis_v_df['st_20200701_minus_per(model)']+analysis_v_df['st_20201001_minus_per(model)'])/4)        \n",
    "#         analysis_v_df['num_plus_com_mean']=((analysis_v_df['st_20200101_num_plus_com']+analysis_v_df['st_20200401_num_plus_com']+analysis_v_df['st_20200701_num_plus_com']+analysis_v_df['st_20201001_num_plus_com'])/4)        \n",
    "#         analysis_v_df['num_plus_model_mean']=((analysis_v_df['st_20200101_num_plus_model(row)']+analysis_v_df['st_20200401_num_plus_model(row)']+analysis_v_df['st_20200701_num_plus_model(row)']+analysis_v_df['st_20201001_num_plus_model(row)'])/4)        \n",
    "#         csv_path='../../bot_database/{place_name}/model_score_{place_name}/v4_score/{version}/{mode_type}_total_analysis.csv'.format(place_name=place_name,mode_type=mode_type,version=version)\n",
    "#         analysis_v_df.to_csv(csv_path)\n",
    "\n",
    "# time_end = time.time()\n",
    "# # 経過時間（秒）\n",
    "# tim = time_end- time_sta\n",
    "\n",
    "# print('DONE')\n",
    "# print('elapsed time::{}=================================================================================================='.format(tim))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unexpected-breach",
   "metadata": {},
   "source": [
    "## きめのパラメータの変更"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fallen-google",
   "metadata": {},
   "source": [
    "## hit も可変していく，num_plus_monthに関しては3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "durable-empty",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version:V4_1_______mode:recent===================================================\n"
     ]
    }
   ],
   "source": [
    "#きめのパラメータ\n",
    "place_name='asiya'\n",
    "plus_m_th=3\n",
    "versions=['V4_1','V4_2']#,'V4_3']\n",
    "modes=['asiya_model_score_','asiya_model_score_period_']#モードは直近三カ月と，昨年同月の二種類\n",
    "mode_types=['recent','period']#モードは直近三カ月と，昨年同月の二種類,modesと一緒にzipで回す\n",
    "#きめじゃないパラメータの範囲設定(ループの数に注意！！)\n",
    "gain_ths=np.arange(80, 180,4)\n",
    "gain_std_ths=np.arange(10, 250,15)\n",
    "hit_per_ths=np.arange(0,20,2)\n",
    "hit_std_ths=np.arange(0, 2.0, 0.4)\n",
    "num_hit_ths=[3,5,8,10,13,15]\n",
    "time_sta = time.time()\n",
    "\n",
    "\n",
    "\n",
    "#コード本文\n",
    "for version in versions:\n",
    "    for mode,mode_type in zip(modes,mode_types):\n",
    "        analysis_v_df=pd.DataFrame(columns=['minus_model_per_mean','num_plus_com_mean','num_plus_model_mean','gain_th','gain_std_th','hit_per_th','hit_std_th'])\n",
    "        print('version:{}_______mode:{}==================================================='.format(version,mode_type))\n",
    "        #こっから下はバージョン，モードごと\n",
    "        for num_hit_th in num_hit_ths:\n",
    "            for gain_th in tqdm(gain_ths):\n",
    "                for gain_std_th in gain_std_ths:\n",
    "                    for hit_per_th in hit_per_ths:\n",
    "                        for hit_std_th in hit_std_ths:\n",
    "                            append_s=pd.Series(dtype='object')\n",
    "                            for i in range(4):\n",
    "                                now_ym=datetime.datetime(year=2020, month=1+(i*3),day=1).strftime('%Y%m%d')\n",
    "                                dir_path='../../bot_database/{place_name}/model_score_{place_name}/v4_score/{version}/{mode}st{now_ym}_finalM3_{version}.csv'.format(place_name=place_name,mode=mode,now_ym=now_ym,version=version)\n",
    "                                model_score_df=pd.read_csv(dir_path, encoding='utf_8_sig')\n",
    "                                model_score_df=model_score_df.drop([\"Unnamed: 0\"],axis=1)\n",
    "                                #決めのパラメータでいったん切り落とし\n",
    "                                model_score_df=model_score_df[model_score_df['plus_month_num_test']>=plus_m_th].copy()#収益がプラスだった月の数で切り捨てる\n",
    "                                model_score_df=model_score_df[model_score_df['num_hit_test']>=num_hit_th].copy()#的中した予測の数で切り捨てる,これも可変していく方針に変更した\n",
    "                                #可変していくパラメータ\n",
    "                                target_df=model_score_df[model_score_df['gain_test']>=gain_th].copy()\n",
    "                                target_df=target_df[target_df['gain_std_test']<=gain_std_th].copy()\n",
    "                                target_df=target_df[target_df['buy_hit_per_test']>=hit_per_th].copy()\n",
    "                                target_df=target_df[target_df['buy_hit_per_std_test']<=hit_std_th].copy()\n",
    "                                analysis_df=gainth_analysis(target_df,test_type='final')\n",
    "                                minus_df=analysis_df.loc[:'100以上_110未満'].copy()\n",
    "                                plus_df=analysis_df.loc['100以上_110未満':].copy()\n",
    "                                try:\n",
    "                                    minus_model_per=(minus_df['num_model(row)'].sum()/analysis_df['num_model(row)'].sum())*100\n",
    "                                except ZeroDivisionError:\n",
    "                                    minus_model_per=100\n",
    "                                append_s['st_{}_minus_per(model)'.format(now_ym)]=minus_model_per\n",
    "                                append_s['st_{}_num_plus_com'.format(now_ym)]=plus_df['num_com'].sum()\n",
    "                                append_s['st_{}_num_plus_model(row)'.format(now_ym)]=plus_df['num_model(row)'].sum()\n",
    "                            append_s['num_hit_th']=num_hit_th\n",
    "                            append_s['gain_th']=gain_th\n",
    "                            append_s['gain_std_th']=gain_std_th\n",
    "                            append_s['hit_per_th']=hit_per_th\n",
    "                            append_s['hit_std_th']=hit_std_th\n",
    "                            analysis_v_df=analysis_v_df.append(append_s,ignore_index=True)\n",
    "        analysis_v_df['minus_model_per_mean']=((analysis_v_df['st_20200101_minus_per(model)']+analysis_v_df['st_20200401_minus_per(model)']+analysis_v_df['st_20200701_minus_per(model)']+analysis_v_df['st_20201001_minus_per(model)'])/4)        \n",
    "        analysis_v_df['num_plus_com_mean']=((analysis_v_df['st_20200101_num_plus_com']+analysis_v_df['st_20200401_num_plus_com']+analysis_v_df['st_20200701_num_plus_com']+analysis_v_df['st_20201001_num_plus_com'])/4)        \n",
    "        analysis_v_df['num_plus_model_mean']=((analysis_v_df['st_20200101_num_plus_model(row)']+analysis_v_df['st_20200401_num_plus_model(row)']+analysis_v_df['st_20200701_num_plus_model(row)']+analysis_v_df['st_20201001_num_plus_model(row)'])/4)        \n",
    "        csv_path='../../bot_database/{place_name}/model_score_{place_name}/v4_score/{version}/{version}_2_{mode_type}_pM{plus_month}_total_analysis.csv'.format(place_name=place_name,mode_type=mode_type,version=version,plus_month=plus_m_th,num_hit=num_hit_th)\n",
    "        analysis_v_df.to_csv(csv_path)\n",
    "\n",
    "time_end = time.time()\n",
    "# 経過時間（秒）\n",
    "tim = time_end- time_sta\n",
    "\n",
    "print('DONE')\n",
    "print('elapsed time::{}=================================================================================================='.format(tim))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interesting-omaha",
   "metadata": {},
   "source": [
    "## plus_monthを２に減らした"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smaller-bubble",
   "metadata": {},
   "outputs": [],
   "source": [
    "#きめのパラメータ\n",
    "place_name='asiya'\n",
    "plus_m_th=2\n",
    "versions=['V4_1','V4_2']#,'V4_3']\n",
    "modes=['asiya_model_score_','asiya_model_score_period_']#モードは直近三カ月と，昨年同月の二種類\n",
    "mode_types=['recent','period']#モードは直近三カ月と，昨年同月の二種類,modesと一緒にzipで回す\n",
    "#きめじゃないパラメータの範囲設定(ループの数に注意！！)\n",
    "gain_ths=np.arange(80, 180,4)\n",
    "gain_std_ths=np.arange(10, 250,15)\n",
    "hit_per_ths=np.arange(0,20,2)\n",
    "hit_std_ths=np.arange(0, 2.0, 0.4)\n",
    "num_hit_ths=[3,5,8,10,13,15]\n",
    "time_sta = time.time()\n",
    "\n",
    "\n",
    "\n",
    "#コード本文\n",
    "for version in versions:\n",
    "    for mode,mode_type in zip(modes,mode_types):\n",
    "        analysis_v_df=pd.DataFrame(columns=['minus_model_per_mean','num_plus_com_mean','num_plus_model_mean','gain_th','gain_std_th','hit_per_th','hit_std_th'])\n",
    "        print('version:{}_______mode:{}==================================================='.format(version,mode_type))\n",
    "        #こっから下はバージョン，モードごと\n",
    "        for num_hit_th in num_hit_ths:\n",
    "            for gain_th in tqdm(gain_ths):\n",
    "                for gain_std_th in gain_std_ths:\n",
    "                    for hit_per_th in hit_per_ths:\n",
    "                        for hit_std_th in hit_std_ths:\n",
    "                            append_s=pd.Series(dtype='object')\n",
    "                            for i in range(4):\n",
    "                                now_ym=datetime.datetime(year=2020, month=1+(i*3),day=1).strftime('%Y%m%d')\n",
    "                                dir_path='../../bot_database/{place_name}/model_score_{place_name}/v4_score/{version}/{mode}st{now_ym}_finalM3_{version}.csv'.format(place_name=place_name,mode=mode,now_ym=now_ym,version=version)\n",
    "                                model_score_df=pd.read_csv(dir_path, encoding='utf_8_sig')\n",
    "                                model_score_df=model_score_df.drop([\"Unnamed: 0\"],axis=1)\n",
    "                                #決めのパラメータでいったん切り落とし\n",
    "                                model_score_df=model_score_df[model_score_df['plus_month_num_test']>=plus_m_th].copy()#収益がプラスだった月の数で切り捨てる\n",
    "                                model_score_df=model_score_df[model_score_df['num_hit_test']>=num_hit_th].copy()#的中した予測の数で切り捨てる,これも可変していく方針に変更した\n",
    "                                #可変していくパラメータ\n",
    "                                target_df=model_score_df[model_score_df['gain_test']>=gain_th].copy()\n",
    "                                target_df=target_df[target_df['gain_std_test']<=gain_std_th].copy()\n",
    "                                target_df=target_df[target_df['buy_hit_per_test']>=hit_per_th].copy()\n",
    "                                target_df=target_df[target_df['buy_hit_per_std_test']<=hit_std_th].copy()\n",
    "                                analysis_df=gainth_analysis(target_df,test_type='final')\n",
    "                                minus_df=analysis_df.loc[:'100以上_110未満'].copy()\n",
    "                                plus_df=analysis_df.loc['100以上_110未満':].copy()\n",
    "                                try:\n",
    "                                    minus_model_per=(minus_df['num_model(row)'].sum()/analysis_df['num_model(row)'].sum())*100\n",
    "                                except ZeroDivisionError:\n",
    "                                    minus_model_per=100\n",
    "                                append_s['st_{}_minus_per(model)'.format(now_ym)]=minus_model_per\n",
    "                                append_s['st_{}_num_plus_com'.format(now_ym)]=plus_df['num_com'].sum()\n",
    "                                append_s['st_{}_num_plus_model(row)'.format(now_ym)]=plus_df['num_model(row)'].sum()\n",
    "                            append_s['num_hit_th']=num_hit_th\n",
    "                            append_s['gain_th']=gain_th\n",
    "                            append_s['gain_std_th']=gain_std_th\n",
    "                            append_s['hit_per_th']=hit_per_th\n",
    "                            append_s['hit_std_th']=hit_std_th\n",
    "                            analysis_v_df=analysis_v_df.append(append_s,ignore_index=True)\n",
    "        analysis_v_df['minus_model_per_mean']=((analysis_v_df['st_20200101_minus_per(model)']+analysis_v_df['st_20200401_minus_per(model)']+analysis_v_df['st_20200701_minus_per(model)']+analysis_v_df['st_20201001_minus_per(model)'])/4)        \n",
    "        analysis_v_df['num_plus_com_mean']=((analysis_v_df['st_20200101_num_plus_com']+analysis_v_df['st_20200401_num_plus_com']+analysis_v_df['st_20200701_num_plus_com']+analysis_v_df['st_20201001_num_plus_com'])/4)        \n",
    "        analysis_v_df['num_plus_model_mean']=((analysis_v_df['st_20200101_num_plus_model(row)']+analysis_v_df['st_20200401_num_plus_model(row)']+analysis_v_df['st_20200701_num_plus_model(row)']+analysis_v_df['st_20201001_num_plus_model(row)'])/4)        \n",
    "        csv_path='../../bot_database/{place_name}/model_score_{place_name}/v4_score/{version}/{version}_2_{mode_type}_pM{plus_month}_total_analysis.csv'.format(place_name=place_name,mode_type=mode_type,version=version,plus_month=plus_m_th,num_hit=num_hit_th)\n",
    "        analysis_v_df.to_csv(csv_path)\n",
    "\n",
    "time_end = time.time()\n",
    "# 経過時間（秒）\n",
    "tim = time_end- time_sta\n",
    "\n",
    "print('DONE')\n",
    "print('elapsed time::{}=================================================================================================='.format(tim))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compact-hammer",
   "metadata": {},
   "source": [
    "# 上の総当たり閾値検索に加えて，相関係数も算出する\n",
    "## なぜ？\n",
    "## ＝閾値をクリアした同一comのモデルの中で，最終的に使うモデルを一つに絞るため"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worldwide-witness",
   "metadata": {},
   "source": [
    "### 方針\n",
    "### ＝４つの区間をすべて使う，閾値の検索は無しとして決めのパラメータだけで絞り，その後各変数とfinal_gainとの相関係数を算出して，最終的に標準化した偏差値と組み合わせる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "taken-energy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 芦屋だけでひとまず機能を完成させる\n",
    "#きめのパラメータ\n",
    "place_name='asiya'\n",
    "plus_m_th=3\n",
    "num_hit_th=10\n",
    "versions=['V4_1','V4_2','V4_3']\n",
    "modes=['asiya_model_score_','asiya_model_score_period_']#モードは直近三カ月と，昨年同月の二種類\n",
    "mode_types=['recent','period']#モードは直近三カ月と，昨年同月の二種類,modesと一緒にzipで回す\n",
    "\n",
    "#for version in versions:\n",
    "version='V4_2'\n",
    "version_df=pd.DataFrame()#区間ごとのスコアシートの結合先（バージョンごとのまとめ）\n",
    "for mode,mode_type in zip(modes,mode_types):\n",
    "    for i in range(4):\n",
    "        now_ym=datetime.datetime(year=2020, month=1+(i*3),day=1).strftime('%Y%m%d')\n",
    "        dir_path='../../bot_database/{place_name}/model_score_{place_name}/v4_score/{version}/{mode}st{now_ym}_finalM3_{version}.csv'.format(place_name=place_name,mode=mode,now_ym=now_ym,version=version)\n",
    "        model_score_df=pd.read_csv(dir_path, encoding='utf_8_sig')\n",
    "        model_score_df=model_score_df.drop([\"Unnamed: 0\"],axis=1)\n",
    "         #決めのパラメータでいったん切り落とし\n",
    "        model_score_df=model_score_df[model_score_df['plus_month_num_test']>=plus_m_th].copy()#収益がプラスだった月の数で切り捨てる\n",
    "        model_score_df=model_score_df[model_score_df['num_hit_test']>=num_hit_th].copy()#的中した予測の数で切り捨てる，大体一カ月に一件くらいをイメージ\n",
    "        version_df= pd.concat([version_df, model_score_df], axis=0)#きめのパラメータで切り落としたので結合\n",
    "#相関係数の算出（範囲は-1～1）\n",
    "version_corr_df=version_df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "rotary-destiny",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target_com               0.283059\n",
       "depth                   -0.005746\n",
       "target_per              -0.186508\n",
       "threshold               -0.111219\n",
       "total_get_test           0.084398\n",
       "total_use_test           0.226903\n",
       "num_com_test             0.046510\n",
       "num_pred_test            0.226903\n",
       "gain_test               -0.257171\n",
       "gain_std_test            0.172104\n",
       "num_hit_test            -0.028523\n",
       "buy_hit_per_test        -0.266918\n",
       "buy_hit_per_std_test    -0.259625\n",
       "plus_month_num_test      0.030133\n",
       "diff_mea_med_test       -0.088409\n",
       "total_get_final          0.833576\n",
       "total_use_final          0.201764\n",
       "num_com_final            0.200710\n",
       "num_pred_final           0.201764\n",
       "gain_final               1.000000\n",
       "gain_std_final           0.595621\n",
       "num_hit_final            0.361705\n",
       "buy_hit_per_final        0.403838\n",
       "buy_hit_per_std_final    0.097588\n",
       "plus_month_num_final     0.849329\n",
       "diff_mea_med_final       0.335706\n",
       "Name: gain_final, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "version_corr_df['gain_final']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "primary-ottawa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_score_df.to_csv(\"ex.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valid-pierre",
   "metadata": {},
   "source": [
    "## 仮での機能テスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mexican-crash",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "scheduled-density",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/25 [00:44<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-58-43e0c4669d6c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m                     \u001b[0mnow_ym\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myear\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2020\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmonth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mday\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'%Y%m%d'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m                     \u001b[0mdir_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'../../bot_database/{place_name}/model_score_{place_name}/v4_score/{version}/{mode}st{now_ym}_finalM3_{version}.csv'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplace_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mplace_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnow_ym\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnow_ym\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mversion\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mversion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m                     \u001b[0mmodel_score_df\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdir_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf_8_sig'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m                     \u001b[0mmodel_score_df\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel_score_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Unnamed: 0\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m                     \u001b[1;31m#決めのパラメータでいったん切り落とし\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\takuma\\nabepy\\env\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    603\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    604\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 605\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    606\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    607\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\takuma\\nabepy\\env\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    462\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 463\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    464\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    465\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\takuma\\nabepy\\env\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1050\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1051\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidate_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"nrows\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1052\u001b[1;33m         \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1053\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1054\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\takuma\\nabepy\\env\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   2054\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2055\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2056\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2057\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2058\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'."
     ]
    }
   ],
   "source": [
    "# i=0\n",
    "# version=versions[0]\n",
    "# analysis_v_df=pd.DataFrame(columns=['minus_model_per_mean','num_plus_com_mean','num_plus_model_mean','gain_th','gain_std_th','hit_per_th','hit_std_th'])\n",
    "# mode=modes[0]\n",
    "# now_ym=datetime.datetime(year=2020, month=1+(i*3),day=1).strftime('%Y%m%d')\n",
    "# time_sta = time.time()\n",
    "# #こっから下はバージョン，モードごと\n",
    "# for gain_th in tqdm(gain_ths):\n",
    "#     for gain_std_th in gain_std_ths:\n",
    "#         for hit_per_th in hit_per_ths:\n",
    "#             for hit_std_th in hit_std_ths:\n",
    "#                 append_s=pd.Series(dtype='object')\n",
    "#                 for i in range(4):\n",
    "#                     now_ym=datetime.datetime(year=2020, month=1+(i*3),day=1).strftime('%Y%m%d')\n",
    "#                     dir_path='../../bot_database/{place_name}/model_score_{place_name}/v4_score/{version}/{mode}st{now_ym}_finalM3_{version}.csv'.format(place_name=place_name,mode=mode,now_ym=now_ym,version=version)\n",
    "#                     model_score_df=pd.read_csv(dir_path, encoding='utf_8_sig')\n",
    "#                     model_score_df=model_score_df.drop([\"Unnamed: 0\"],axis=1)\n",
    "#                     #決めのパラメータでいったん切り落とし\n",
    "#                     model_score_df=model_score_df[model_score_df['plus_month_num_test']>=plus_m_th].copy()#収益がプラスだった月の数で切り捨てる\n",
    "#                     model_score_df=model_score_df[model_score_df['num_hit_test']>=num_hit_th].copy()#的中した予測の数で切り捨てる，大体一カ月に一件くらいをイメージ\n",
    "#                     target_df=model_score_df[model_score_df['gain_test']>=gain_th].copy()\n",
    "#                     target_df=target_df[target_df['gain_std_test']<=gain_std_th].copy()\n",
    "#                     target_df=target_df[target_df['buy_hit_per_test']>=hit_per_th].copy()\n",
    "#                     target_df=target_df[target_df['buy_hit_per_std_test']<=hit_std_th].copy()\n",
    "#                     analysis_df=gainth_analysis(target_df,test_type='final')\n",
    "#                     minus_df=analysis_df.loc[:'100以上_110未満'].copy()\n",
    "#                     plus_df=analysis_df.loc['100以上_110未満':].copy()\n",
    "#                     try:\n",
    "#                         minus_model_per=(minus_df['num_model(row)'].sum()/analysis_df['num_model(row)'].sum())*100\n",
    "#                     except ZeroDivisionError:\n",
    "#                         minus_model_per=100\n",
    "#                     append_s['st_{}_minus_per(model)'.format(now_ym)]=minus_model_per\n",
    "#                     append_s['st_{}_num_plus_com'.format(now_ym)]=plus_df['num_com'].sum()\n",
    "#                     append_s['st_{}_num_plus_model(row)'.format(now_ym)]=plus_df['num_model(row)'].sum()\n",
    "#                 append_s['gain_th']=gain_th\n",
    "#                 append_s['gain_std_th']=gain_std_th\n",
    "#                 append_s['hit_per_th']=hit_per_th\n",
    "#                 append_s['hit_std_th']=hit_std_th\n",
    "#                 analysis_v_df=analysis_v_df.append(append_s,ignore_index=True)\n",
    "            \n",
    "# analysis_v_df['minus_model_per_mean']=((analysis_v_df['st_20200101_minus_per(model)']+analysis_v_df['st_20200401_minus_per(model)']+analysis_v_df['st_20200701_minus_per(model)']+analysis_v_df['st_20201001_minus_per(model)'])/4)        \n",
    "# analysis_v_df['num_plus_com_mean']=((analysis_v_df['st_20200101_num_plus_com']+analysis_v_df['st_20200401_num_plus_com']+analysis_v_df['st_20200701_num_plus_com']+analysis_v_df['st_20201001_num_plus_com'])/4)        \n",
    "# analysis_v_df['num_plus_model_mean']=((analysis_v_df['st_20200101_num_plus_model(row)']+analysis_v_df['st_20200401_num_plus_model(row)']+analysis_v_df['st_20200701_num_plus_model(row)']+analysis_v_df['st_20201001_num_plus_model(row)'])/4)        \n",
    "# csv_path='../../bot_database/{place_name}/model_score_{place_name}/v4_score/{version}/{mode_type}_total_analysis.csv'.format(place_name=place_name,mode_type=mode_type,version=version)\n",
    "\n",
    "# analysis_v_df.to_csv(csv_path)\n",
    "\n",
    "# time_end = time.time()\n",
    "# # 経過時間（秒）\n",
    "# tim = time_end- time_sta\n",
    "\n",
    "# print('DONE')\n",
    "# print('elapsed time::{}=================================================================================================='.format(tim))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "dimensional-campbell",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_type='test'\n",
    "analysis_v_df['minus_model_per_mean']=((analysis_v_df['st_20200101_minus_per(model)']+analysis_v_df['st_20200401_minus_per(model)']+analysis_v_df['st_20200701_minus_per(model)']+analysis_v_df['st_20201001_minus_per(model)'])/4)        \n",
    "analysis_v_df['num_plus_com_mean']=((analysis_v_df['st_20200101_num_plus_com']+analysis_v_df['st_20200401_num_plus_com']+analysis_v_df['st_20200701_num_plus_com']+analysis_v_df['st_20201001_num_plus_com'])/4)        \n",
    "analysis_v_df['num_plus_model_mean']=((analysis_v_df['st_20200101_num_plus_model(row)']+analysis_v_df['st_20200401_num_plus_model(row)']+analysis_v_df['st_20200701_num_plus_model(row)']+analysis_v_df['st_20201001_num_plus_model(row)'])/4)        \n",
    "csv_path='../../bot_database/{place_name}/model_score_{place_name}/v4_score/{version}/{mode_type}_total_analysis.csv'.format(place_name=place_name,mode_type=mode_type,version=version)\n",
    "analysis_v_df.to_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "difficult-toilet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'V4_1'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exceptional-kansas",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
