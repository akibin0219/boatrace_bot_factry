{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "patient-efficiency",
   "metadata": {},
   "source": [
    "# V4系列で，バージョンごとに最終的な評価値を出す．(区間５カ月は行わない予定)\n",
    "なんとなくどの　パラメータを可変していけば何が変わるのかの感覚がつかめたので，その感覚を大事にしながら総当たりでパラメータを可変していく．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "caroline-dream",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import seaborn\n",
    "from pandas import DataFrame\n",
    "from tqdm import tqdm\n",
    "from imblearn.under_sampling import RandomUnderSampler #アンダーサンプリング用\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "# 機械学習用\n",
    "from sklearn.cluster import KMeans #クラスタリング用\n",
    "from sklearn.ensemble import RandomForestClassifier#ランダムフォレスト\n",
    "from copy import deepcopy as cp\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import time\n",
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import os #ディレクトリ作成用\n",
    "import xgboost as xgb\n",
    "import sys\n",
    "#自作のモジュールのインポート\n",
    "sys.path.append(\"..\")\n",
    "import module.master as master\n",
    "import module.modeling_scores as modeling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "right-causing",
   "metadata": {},
   "source": [
    "## 関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "hydraulic-cover",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def gainth_analysis(score_df,test_type='final'):\n",
    "    \n",
    "    gainth_arr=[100,110,120,140,160]\n",
    "    index_arr=[0,1,2,3,4]\n",
    "    cols=[\"gain_th\",\"num_com\",\"num_model(row)\"]\n",
    "    gainth_df=pd.DataFrame(columns=cols)\n",
    "    def make_series(target_df):\n",
    "        num_com=len(target_df['target_com'].value_counts().index)\n",
    "        num_model=len(target_df)\n",
    "        return num_com,num_model\n",
    "    for gainth,i in zip(gainth_arr,index_arr):\n",
    "        append_s=pd.Series(index=cols,dtype='object')\n",
    "        if (i==0):\n",
    "            target_df=score_df[score_df[\"gain_{}\".format(test_type)]<gainth]\n",
    "            num_com,num_model=make_series(target_df)\n",
    "            append_s['gain_th']=\"100未満\"\n",
    "            append_s['num_com']=num_com\n",
    "            append_s['num_model(row)']=num_model\n",
    "        elif (i==4):\n",
    "            target_df=score_df[score_df[\"gain_{}\".format(test_type)]>=gainth]\n",
    "            num_com,num_model=make_series(target_df)\n",
    "            append_s['gain_th']=\"150以上\"\n",
    "            append_s['num_com']=num_com\n",
    "            append_s['num_model(row)']=num_model\n",
    "        else:\n",
    "            target_df=score_df[(score_df[\"gain_{}\".format(test_type)]<gainth_arr[i])&(score_df[\"gain_{}\".format(test_type)]>=gainth_arr[i-1])]\n",
    "            num_com,num_model=make_series(target_df)\n",
    "            append_s['gain_th']=\"{}以上_{}未満\".format(gainth_arr[i-1],gainth_arr[i])\n",
    "            append_s['num_com']=num_com\n",
    "            append_s['num_model(row)']=num_model\n",
    "        gainth_df=gainth_df.append(append_s,ignore_index=True)\n",
    "    return gainth_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "communist-authorization",
   "metadata": {},
   "source": [
    "## バージョンごとに1DF 出力する(10会場分,かつV4_2だけで作成する，)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "electoral-terror",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version:V4_2_______mode:recent===================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|███████▌                                                                   | 1/10 [5:31:47<49:46:10, 19907.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version:V4_2_______mode:recent===================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██████████████▊                                                           | 2/10 [11:02:46<44:10:29, 19878.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version:V4_2_______mode:recent===================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|██████████████████████▏                                                   | 3/10 [16:54:25<39:44:11, 20435.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version:V4_2_______mode:recent===================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████▌                                            | 4/10 [22:22:21<33:33:36, 20136.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version:V4_2_______mode:recent===================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████████████████████████████████████                                     | 5/10 [27:52:13<27:47:40, 20012.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version:V4_2_______mode:recent===================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|████████████████████████████████████████████▍                             | 6/10 [33:45:20<22:40:46, 20411.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version:V4_2_______mode:recent===================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████████████████████████████████████████████████▊                      | 7/10 [40:10:33<17:44:44, 21294.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version:V4_2_______mode:recent===================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|███████████████████████████████████████████████████████████▏              | 8/10 [45:55:48<11:43:39, 21109.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version:V4_2_______mode:recent===================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|███████████████████████████████████████████████████████████████████▌       | 9/10 [51:38:43<5:49:02, 20942.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version:V4_2_______mode:recent===================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 10/10 [57:21:44<00:00, 20650.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n",
      "elapsed time::206504.06525063515==================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "plus_m_th=3\n",
    "#versions=['V4_1','V4_2']#,'V4_3']\n",
    "version='V4_2'\n",
    "#modes=['asiya_model_score_','asiya_model_score_period_']#モードは直近三カ月と，昨年同月の二種類\n",
    "mode='model_score_'\n",
    "#mode_types=['recent','period']#モードは直近三カ月と，昨年同月の二種類,modesと一緒にzipで回す\n",
    "mode_type='recent'\n",
    "#きめじゃないパラメータの範囲設定(ループの数に注意！！)\n",
    "gain_ths=np.arange(80, 180,4)\n",
    "gain_std_ths=np.arange(10, 250,15)\n",
    "hit_per_ths=np.arange(0,20,2)\n",
    "hit_std_ths=np.arange(0, 2.0, 0.4)\n",
    "num_hit_ths=[3,5,8,10,13,15]\n",
    "place_master=master.get_place_master()\n",
    "place_names=[place_name for place_name in place_master.values()]#会場名のみを収納した配列\n",
    "version='V4_2'#バージョン\n",
    "time_sta = time.time()\n",
    "\n",
    "\n",
    "\n",
    "#コード本文\n",
    "#for version in versions:\n",
    "#    for mode,mode_type in zip(modes,mode_types):\n",
    "for place_name in tqdm(place_names[:10]):\n",
    "    analysis_v_df=pd.DataFrame(columns=['minus_model_per_mean','num_plus_com_mean','num_plus_model_mean','gain_th','gain_std_th','hit_per_th','hit_std_th'])\n",
    "    print('version:{}_______mode:{}==================================================='.format(version,mode_type))\n",
    "    #こっから下はバージョン，モードごと\n",
    "    for num_hit_th in num_hit_ths:\n",
    "        for gain_th in gain_ths:\n",
    "            for gain_std_th in gain_std_ths:\n",
    "                for hit_per_th in hit_per_ths:\n",
    "                    for hit_std_th in hit_std_ths:\n",
    "                        append_s=pd.Series(dtype='object')\n",
    "                        for i in range(4):\n",
    "                            now_ym=datetime.datetime(year=2020, month=1+(i*3),day=1).strftime('%Y%m%d')\n",
    "                            dir_path='../../bot_database/{place_name}/model_score_{place_name}/v4_score/{version}/{place_name}_{mode}st{now_ym}_finalM3_{version}.csv'.format(place_name=place_name,mode=mode,now_ym=now_ym,version=version)\n",
    "                            model_score_df=pd.read_csv(dir_path, encoding='utf_8_sig')\n",
    "                            model_score_df=model_score_df.drop([\"Unnamed: 0\"],axis=1)\n",
    "                            #決めのパラメータでいったん切り落とし\n",
    "                            model_score_df=model_score_df[model_score_df['plus_month_num_test']>=plus_m_th].copy()#収益がプラスだった月の数で切り捨てる\n",
    "                            model_score_df=model_score_df[model_score_df['num_hit_test']>=num_hit_th].copy()#的中した予測の数で切り捨てる,これも可変していく方針に変更した\n",
    "                            #可変していくパラメータ\n",
    "                            target_df=model_score_df[model_score_df['gain_test']>=gain_th].copy()\n",
    "                            target_df=target_df[target_df['gain_std_test']<=gain_std_th].copy()\n",
    "                            target_df=target_df[target_df['buy_hit_per_test']>=hit_per_th].copy()\n",
    "                            target_df=target_df[target_df['buy_hit_per_std_test']<=hit_std_th].copy()\n",
    "                            analysis_df=gainth_analysis(target_df,test_type='final')\n",
    "                            minus_df=analysis_df.loc[:'100以上_110未満'].copy()\n",
    "                            plus_df=analysis_df.loc['100以上_110未満':].copy()\n",
    "                            try:\n",
    "                                minus_model_per=(minus_df['num_model(row)'].sum()/analysis_df['num_model(row)'].sum())*100\n",
    "                            except ZeroDivisionError:\n",
    "                                minus_model_per=100\n",
    "                            append_s['st_{}_minus_per(model)'.format(now_ym)]=minus_model_per\n",
    "                            append_s['st_{}_num_plus_com'.format(now_ym)]=plus_df['num_com'].sum()\n",
    "                            append_s['st_{}_num_plus_model(row)'.format(now_ym)]=plus_df['num_model(row)'].sum()\n",
    "                        append_s['num_hit_th']=num_hit_th\n",
    "                        append_s['gain_th']=gain_th\n",
    "                        append_s['gain_std_th']=gain_std_th\n",
    "                        append_s['hit_per_th']=hit_per_th\n",
    "                        append_s['hit_std_th']=hit_std_th\n",
    "                        analysis_v_df=analysis_v_df.append(append_s,ignore_index=True)\n",
    "    analysis_v_df['minus_model_per_mean']=((analysis_v_df['st_20200101_minus_per(model)']+analysis_v_df['st_20200401_minus_per(model)']+analysis_v_df['st_20200701_minus_per(model)']+analysis_v_df['st_20201001_minus_per(model)'])/4)        \n",
    "    analysis_v_df['num_plus_com_mean']=((analysis_v_df['st_20200101_num_plus_com']+analysis_v_df['st_20200401_num_plus_com']+analysis_v_df['st_20200701_num_plus_com']+analysis_v_df['st_20201001_num_plus_com'])/4)        \n",
    "    analysis_v_df['num_plus_model_mean']=((analysis_v_df['st_20200101_num_plus_model(row)']+analysis_v_df['st_20200401_num_plus_model(row)']+analysis_v_df['st_20200701_num_plus_model(row)']+analysis_v_df['st_20201001_num_plus_model(row)'])/4)        \n",
    "    csv_path='../../bot_database/{place_name}/model_score_{place_name}/v4_score/{version}/{version}_{mode_type}_TRhit_pM{plus_month}_total_analysis.csv'.format(place_name=place_name,mode_type=mode_type,version=version,plus_month=plus_m_th,num_hit=num_hit_th)\n",
    "    analysis_v_df.to_csv(csv_path)\n",
    "\n",
    "time_end = time.time()\n",
    "# 経過時間（秒）\n",
    "tim = time_end- time_sta\n",
    "\n",
    "print('DONE')\n",
    "print('elapsed time::{}=================================================================================================='.format(tim))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charged-afternoon",
   "metadata": {},
   "source": [
    "## plus_monthも２カ月に減らした"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "incredible-purchase",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version:V4_2_______mode:recent===================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/10 [2:29:56<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-974bd2ea4282>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m                             \u001b[0mnow_ym\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myear\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2020\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmonth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mday\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'%Y%m%d'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m                             \u001b[0mdir_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'../../bot_database/{place_name}/model_score_{place_name}/v4_score/{version}/{place_name}_{mode}st{now_ym}_finalM3_{version}.csv'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplace_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mplace_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnow_ym\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnow_ym\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mversion\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mversion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m                             \u001b[0mmodel_score_df\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdir_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf_8_sig'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m                             \u001b[0mmodel_score_df\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel_score_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Unnamed: 0\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m                             \u001b[1;31m#決めのパラメータでいったん切り落とし\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\takuma\\nabepy\\env\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    603\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    604\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 605\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    606\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    607\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\takuma\\nabepy\\env\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    462\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 463\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    464\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    465\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\takuma\\nabepy\\env\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1050\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1051\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidate_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"nrows\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1052\u001b[1;33m         \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1053\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1054\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\takuma\\nabepy\\env\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   2054\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2055\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2056\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2057\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2058\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'."
     ]
    }
   ],
   "source": [
    "\n",
    "plus_m_th=2\n",
    "#versions=['V4_1','V4_2']#,'V4_3']\n",
    "version='V4_2'\n",
    "#modes=['asiya_model_score_','asiya_model_score_period_']#モードは直近三カ月と，昨年同月の二種類\n",
    "mode='model_score_'\n",
    "#mode_types=['recent','period']#モードは直近三カ月と，昨年同月の二種類,modesと一緒にzipで回す\n",
    "mode_type='recent'\n",
    "#きめじゃないパラメータの範囲設定(ループの数に注意！！)\n",
    "gain_ths=np.arange(80, 180,4)\n",
    "gain_std_ths=np.arange(10, 250,15)\n",
    "hit_per_ths=np.arange(0,20,2)\n",
    "hit_std_ths=np.arange(0, 2.0, 0.4)\n",
    "num_hit_ths=[3,5,8,10,13,15]\n",
    "place_master=master.get_place_master()\n",
    "place_names=[place_name for place_name in place_master.values()]#会場名のみを収納した配列\n",
    "version='V4_2'#バージョン\n",
    "time_sta = time.time()\n",
    "\n",
    "\n",
    "\n",
    "#コード本文\n",
    "#for version in versions:\n",
    "#    for mode,mode_type in zip(modes,mode_types):\n",
    "for place_name in tqdm(place_names[:10]):\n",
    "    analysis_v_df=pd.DataFrame(columns=['minus_model_per_mean','num_plus_com_mean','num_plus_model_mean','gain_th','gain_std_th','hit_per_th','hit_std_th'])\n",
    "    print('version:{}_______mode:{}==================================================='.format(version,mode_type))\n",
    "    #こっから下はバージョン，モードごと\n",
    "    for num_hit_th in num_hit_ths:\n",
    "        for gain_th in gain_ths:\n",
    "            for gain_std_th in gain_std_ths:\n",
    "                for hit_per_th in hit_per_ths:\n",
    "                    for hit_std_th in hit_std_ths:\n",
    "                        append_s=pd.Series(dtype='object')\n",
    "                        for i in range(4):\n",
    "                            now_ym=datetime.datetime(year=2020, month=1+(i*3),day=1).strftime('%Y%m%d')\n",
    "                            dir_path='../../bot_database/{place_name}/model_score_{place_name}/v4_score/{version}/{place_name}_{mode}st{now_ym}_finalM3_{version}.csv'.format(place_name=place_name,mode=mode,now_ym=now_ym,version=version)\n",
    "                            model_score_df=pd.read_csv(dir_path, encoding='utf_8_sig')\n",
    "                            model_score_df=model_score_df.drop([\"Unnamed: 0\"],axis=1)\n",
    "                            #決めのパラメータでいったん切り落とし\n",
    "                            model_score_df=model_score_df[model_score_df['plus_month_num_test']>=plus_m_th].copy()#収益がプラスだった月の数で切り捨てる\n",
    "                            model_score_df=model_score_df[model_score_df['num_hit_test']>=num_hit_th].copy()#的中した予測の数で切り捨てる,これも可変していく方針に変更した\n",
    "                            #可変していくパラメータ\n",
    "                            target_df=model_score_df[model_score_df['gain_test']>=gain_th].copy()\n",
    "                            target_df=target_df[target_df['gain_std_test']<=gain_std_th].copy()\n",
    "                            target_df=target_df[target_df['buy_hit_per_test']>=hit_per_th].copy()\n",
    "                            target_df=target_df[target_df['buy_hit_per_std_test']<=hit_std_th].copy()\n",
    "                            analysis_df=gainth_analysis(target_df,test_type='final')\n",
    "                            minus_df=analysis_df.loc[:'100以上_110未満'].copy()\n",
    "                            plus_df=analysis_df.loc['100以上_110未満':].copy()\n",
    "                            try:\n",
    "                                minus_model_per=(minus_df['num_model(row)'].sum()/analysis_df['num_model(row)'].sum())*100\n",
    "                            except ZeroDivisionError:\n",
    "                                minus_model_per=100\n",
    "                            append_s['st_{}_minus_per(model)'.format(now_ym)]=minus_model_per\n",
    "                            append_s['st_{}_num_plus_com'.format(now_ym)]=plus_df['num_com'].sum()\n",
    "                            append_s['st_{}_num_plus_model(row)'.format(now_ym)]=plus_df['num_model(row)'].sum()\n",
    "                        append_s['num_hit_th']=num_hit_th\n",
    "                        append_s['gain_th']=gain_th\n",
    "                        append_s['gain_std_th']=gain_std_th\n",
    "                        append_s['hit_per_th']=hit_per_th\n",
    "                        append_s['hit_std_th']=hit_std_th\n",
    "                        analysis_v_df=analysis_v_df.append(append_s,ignore_index=True)\n",
    "    analysis_v_df['minus_model_per_mean']=((analysis_v_df['st_20200101_minus_per(model)']+analysis_v_df['st_20200401_minus_per(model)']+analysis_v_df['st_20200701_minus_per(model)']+analysis_v_df['st_20201001_minus_per(model)'])/4)        \n",
    "    analysis_v_df['num_plus_com_mean']=((analysis_v_df['st_20200101_num_plus_com']+analysis_v_df['st_20200401_num_plus_com']+analysis_v_df['st_20200701_num_plus_com']+analysis_v_df['st_20201001_num_plus_com'])/4)        \n",
    "    analysis_v_df['num_plus_model_mean']=((analysis_v_df['st_20200101_num_plus_model(row)']+analysis_v_df['st_20200401_num_plus_model(row)']+analysis_v_df['st_20200701_num_plus_model(row)']+analysis_v_df['st_20201001_num_plus_model(row)'])/4)        \n",
    "    csv_path='../../bot_database/{place_name}/model_score_{place_name}/v4_score/{version}/{version}_{mode_type}_TRhit_pM{plus_month}_total_analysis.csv'.format(place_name=place_name,mode_type=mode_type,version=version,plus_month=plus_m_th,num_hit=num_hit_th)\n",
    "    analysis_v_df.to_csv(csv_path)\n",
    "\n",
    "time_end = time.time()\n",
    "# 経過時間（秒）\n",
    "tim = time_end- time_sta\n",
    "\n",
    "print('DONE')\n",
    "print('elapsed time::{}=================================================================================================='.format(tim))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "centered-spelling",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version:V4_1_______mode:recent===================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 25/25 [54:07<00:00, 129.88s/it]\n",
      "  0%|                                                                                           | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version:V4_1_______mode:period===================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 25/25 [54:33<00:00, 130.94s/it]\n",
      "  0%|                                                                                           | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version:V4_2_______mode:recent===================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 25/25 [54:11<00:00, 130.06s/it]\n",
      "  0%|                                                                                           | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version:V4_2_______mode:period===================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 25/25 [54:49<00:00, 131.59s/it]\n",
      "  0%|                                                                                           | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version:V4_3_______mode:recent===================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 25/25 [3:30:18<00:00, 504.75s/it]\n",
      "  0%|                                                                                           | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version:V4_3_______mode:period===================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 25/25 [3:53:18<00:00, 559.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n",
      "elapsed time::39680.50764346123==================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# #きめのパラメータ\n",
    "# place_name='asiya'\n",
    "# plus_m_th=2\n",
    "# num_hit_th=3\n",
    "# versions=['V4_1','V4_2','V4_3']\n",
    "# modes=['asiya_model_score_','asiya_model_score_period_']#モードは直近三カ月と，昨年同月の二種類\n",
    "# mode_types=['recent','period']#モードは直近三カ月と，昨年同月の二種類,modesと一緒にzipで回す\n",
    "# #きめじゃないパラメータの範囲設定(ループの数に注意！！)\n",
    "# gain_ths=np.arange(80, 180,4)\n",
    "# gain_std_ths=np.arange(10, 250,15)\n",
    "# hit_per_ths=np.arange(0,20,2)\n",
    "# hit_std_ths=np.arange(0, 2.0, 0.4)\n",
    "# time_sta = time.time()\n",
    "\n",
    "\n",
    "\n",
    "# #コード本文\n",
    "# for version in versions:\n",
    "#     for mode,mode_type in zip(modes,mode_types):\n",
    "#         analysis_v_df=pd.DataFrame(columns=['minus_model_per_mean','num_plus_com_mean','num_plus_model_mean','gain_th','gain_std_th','hit_per_th','hit_std_th'])\n",
    "#         print('version:{}_______mode:{}==================================================='.format(version,mode_type))\n",
    "#         #こっから下はバージョン，モードごと\n",
    "#         for gain_th in tqdm(gain_ths):\n",
    "#             for gain_std_th in gain_std_ths:\n",
    "#                 for hit_per_th in hit_per_ths:\n",
    "#                     for hit_std_th in hit_std_ths:\n",
    "#                         append_s=pd.Series(dtype='object')\n",
    "#                         for i in range(4):\n",
    "#                             now_ym=datetime.datetime(year=2020, month=1+(i*3),day=1).strftime('%Y%m%d')\n",
    "#                             dir_path='../../bot_database/{place_name}/model_score_{place_name}/v4_score/{version}/{mode}st{now_ym}_finalM3_{version}.csv'.format(place_name=place_name,mode=mode,now_ym=now_ym,version=version)\n",
    "#                             model_score_df=pd.read_csv(dir_path, encoding='utf_8_sig')\n",
    "#                             model_score_df=model_score_df.drop([\"Unnamed: 0\"],axis=1)\n",
    "#                             #決めのパラメータでいったん切り落とし\n",
    "#                             model_score_df=model_score_df[model_score_df['plus_month_num_test']>=plus_m_th].copy()#収益がプラスだった月の数で切り捨てる\n",
    "#                             model_score_df=model_score_df[model_score_df['num_hit_test']>=num_hit_th].copy()#的中した予測の数で切り捨てる，大体一カ月に一件くらいをイメージ\n",
    "#                             #可変していくパラメータ\n",
    "#                             target_df=model_score_df[model_score_df['gain_test']>=gain_th].copy()\n",
    "#                             target_df=target_df[target_df['gain_std_test']<=gain_std_th].copy()\n",
    "#                             target_df=target_df[target_df['buy_hit_per_test']>=hit_per_th].copy()\n",
    "#                             target_df=target_df[target_df['buy_hit_per_std_test']<=hit_std_th].copy()\n",
    "#                             analysis_df=gainth_analysis(target_df,test_type='final')\n",
    "#                             minus_df=analysis_df.loc[:'100以上_110未満'].copy()\n",
    "#                             plus_df=analysis_df.loc['100以上_110未満':].copy()\n",
    "#                             try:\n",
    "#                                 minus_model_per=(minus_df['num_model(row)'].sum()/analysis_df['num_model(row)'].sum())*100\n",
    "#                             except ZeroDivisionError:\n",
    "#                                 minus_model_per=100\n",
    "#                             append_s['st_{}_minus_per(model)'.format(now_ym)]=minus_model_per\n",
    "#                             append_s['st_{}_num_plus_com'.format(now_ym)]=plus_df['num_com'].sum()\n",
    "#                             append_s['st_{}_num_plus_model(row)'.format(now_ym)]=plus_df['num_model(row)'].sum()\n",
    "#                         append_s['gain_th']=gain_th\n",
    "#                         append_s['gain_std_th']=gain_std_th\n",
    "#                         append_s['hit_per_th']=hit_per_th\n",
    "#                         append_s['hit_std_th']=hit_std_th\n",
    "#                         analysis_v_df=analysis_v_df.append(append_s,ignore_index=True)\n",
    "#         analysis_v_df['minus_model_per_mean']=((analysis_v_df['st_20200101_minus_per(model)']+analysis_v_df['st_20200401_minus_per(model)']+analysis_v_df['st_20200701_minus_per(model)']+analysis_v_df['st_20201001_minus_per(model)'])/4)        \n",
    "#         analysis_v_df['num_plus_com_mean']=((analysis_v_df['st_20200101_num_plus_com']+analysis_v_df['st_20200401_num_plus_com']+analysis_v_df['st_20200701_num_plus_com']+analysis_v_df['st_20201001_num_plus_com'])/4)        \n",
    "#         analysis_v_df['num_plus_model_mean']=((analysis_v_df['st_20200101_num_plus_model(row)']+analysis_v_df['st_20200401_num_plus_model(row)']+analysis_v_df['st_20200701_num_plus_model(row)']+analysis_v_df['st_20201001_num_plus_model(row)'])/4)        \n",
    "#         csv_path='../../bot_database/{place_name}/model_score_{place_name}/v4_score/{version}/{mode_type}_total_analysis.csv'.format(place_name=place_name,mode_type=mode_type,version=version)\n",
    "#         analysis_v_df.to_csv(csv_path)\n",
    "\n",
    "# time_end = time.time()\n",
    "# # 経過時間（秒）\n",
    "# tim = time_end- time_sta\n",
    "\n",
    "# print('DONE')\n",
    "# print('elapsed time::{}=================================================================================================='.format(tim))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "limited-weight",
   "metadata": {},
   "source": [
    "# 芦屋のみで動かし，機能部分を作ってみる"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "congressional-sword",
   "metadata": {},
   "source": [
    "## きめのパラメータの変更"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solved-strain",
   "metadata": {},
   "source": [
    "## hit も可変していく，num_plus_monthに関しては3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "rational-cheese",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version:V4_1_______mode:recent===================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 25/25 [54:20<00:00, 130.43s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 25/25 [53:32<00:00, 128.48s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 25/25 [55:42<00:00, 133.71s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 25/25 [1:04:28<00:00, 154.74s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 25/25 [1:18:48<00:00, 189.15s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 25/25 [1:17:31<00:00, 186.05s/it]\n",
      "  0%|                                                                                           | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version:V4_1_______mode:period===================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 25/25 [58:59<00:00, 141.58s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 25/25 [57:08<00:00, 137.12s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 25/25 [57:26<00:00, 137.85s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 25/25 [1:10:17<00:00, 168.70s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 25/25 [1:13:24<00:00, 176.17s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 25/25 [56:19<00:00, 135.19s/it]\n",
      "  0%|                                                                                           | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version:V4_2_______mode:recent===================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 25/25 [55:09<00:00, 132.37s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 25/25 [55:25<00:00, 133.02s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 25/25 [55:38<00:00, 133.53s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 25/25 [55:57<00:00, 134.32s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 25/25 [55:52<00:00, 134.08s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 25/25 [56:06<00:00, 134.67s/it]\n",
      "  0%|                                                                                           | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version:V4_2_______mode:period===================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 25/25 [55:13<00:00, 132.56s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 25/25 [55:55<00:00, 134.22s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 25/25 [59:12<00:00, 142.12s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 25/25 [59:02<00:00, 141.69s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 25/25 [1:00:16<00:00, 144.66s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 25/25 [1:01:55<00:00, 148.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n",
      "elapsed time::86629.49615955353==================================================================================================\n"
     ]
    }
   ],
   "source": [
    "#きめのパラメータ\n",
    "place_name='asiya'\n",
    "plus_m_th=3\n",
    "versions=['V4_1','V4_2']#,'V4_3']\n",
    "modes=['asiya_model_score_','asiya_model_score_period_']#モードは直近三カ月と，昨年同月の二種類\n",
    "mode_types=['recent','period']#モードは直近三カ月と，昨年同月の二種類,modesと一緒にzipで回す\n",
    "#きめじゃないパラメータの範囲設定(ループの数に注意！！)\n",
    "gain_ths=np.arange(80, 180,4)\n",
    "gain_std_ths=np.arange(10, 250,15)\n",
    "hit_per_ths=np.arange(0,20,2)\n",
    "hit_std_ths=np.arange(0, 2.0, 0.4)\n",
    "num_hit_ths=[3,5,8,10,13,15]\n",
    "time_sta = time.time()\n",
    "\n",
    "\n",
    "\n",
    "#コード本文\n",
    "for version in versions:\n",
    "    for mode,mode_type in zip(modes,mode_types):\n",
    "        analysis_v_df=pd.DataFrame(columns=['minus_model_per_mean','num_plus_com_mean','num_plus_model_mean','gain_th','gain_std_th','hit_per_th','hit_std_th'])\n",
    "        print('version:{}_______mode:{}==================================================='.format(version,mode_type))\n",
    "        #こっから下はバージョン，モードごと\n",
    "        for num_hit_th in num_hit_ths:\n",
    "            for gain_th in tqdm(gain_ths):\n",
    "                for gain_std_th in gain_std_ths:\n",
    "                    for hit_per_th in hit_per_ths:\n",
    "                        for hit_std_th in hit_std_ths:\n",
    "                            append_s=pd.Series(dtype='object')\n",
    "                            for i in range(4):\n",
    "                                now_ym=datetime.datetime(year=2020, month=1+(i*3),day=1).strftime('%Y%m%d')\n",
    "                                dir_path='../../bot_database/{place_name}/model_score_{place_name}/v4_score/{version}/{mode}st{now_ym}_finalM3_{version}.csv'.format(place_name=place_name,mode=mode,now_ym=now_ym,version=version)\n",
    "                                model_score_df=pd.read_csv(dir_path, encoding='utf_8_sig')\n",
    "                                model_score_df=model_score_df.drop([\"Unnamed: 0\"],axis=1)\n",
    "                                #決めのパラメータでいったん切り落とし\n",
    "                                model_score_df=model_score_df[model_score_df['plus_month_num_test']>=plus_m_th].copy()#収益がプラスだった月の数で切り捨てる\n",
    "                                model_score_df=model_score_df[model_score_df['num_hit_test']>=num_hit_th].copy()#的中した予測の数で切り捨てる,これも可変していく方針に変更した\n",
    "                                #可変していくパラメータ\n",
    "                                target_df=model_score_df[model_score_df['gain_test']>=gain_th].copy()\n",
    "                                target_df=target_df[target_df['gain_std_test']<=gain_std_th].copy()\n",
    "                                target_df=target_df[target_df['buy_hit_per_test']>=hit_per_th].copy()\n",
    "                                target_df=target_df[target_df['buy_hit_per_std_test']<=hit_std_th].copy()\n",
    "                                analysis_df=gainth_analysis(target_df,test_type='final')\n",
    "                                minus_df=analysis_df.loc[:'100以上_110未満'].copy()\n",
    "                                plus_df=analysis_df.loc['100以上_110未満':].copy()\n",
    "                                try:\n",
    "                                    minus_model_per=(minus_df['num_model(row)'].sum()/analysis_df['num_model(row)'].sum())*100\n",
    "                                except ZeroDivisionError:\n",
    "                                    minus_model_per=100\n",
    "                                append_s['st_{}_minus_per(model)'.format(now_ym)]=minus_model_per\n",
    "                                append_s['st_{}_num_plus_com'.format(now_ym)]=plus_df['num_com'].sum()\n",
    "                                append_s['st_{}_num_plus_model(row)'.format(now_ym)]=plus_df['num_model(row)'].sum()\n",
    "                            append_s['num_hit_th']=num_hit_th\n",
    "                            append_s['gain_th']=gain_th\n",
    "                            append_s['gain_std_th']=gain_std_th\n",
    "                            append_s['hit_per_th']=hit_per_th\n",
    "                            append_s['hit_std_th']=hit_std_th\n",
    "                            analysis_v_df=analysis_v_df.append(append_s,ignore_index=True)\n",
    "        analysis_v_df['minus_model_per_mean']=((analysis_v_df['st_20200101_minus_per(model)']+analysis_v_df['st_20200401_minus_per(model)']+analysis_v_df['st_20200701_minus_per(model)']+analysis_v_df['st_20201001_minus_per(model)'])/4)        \n",
    "        analysis_v_df['num_plus_com_mean']=((analysis_v_df['st_20200101_num_plus_com']+analysis_v_df['st_20200401_num_plus_com']+analysis_v_df['st_20200701_num_plus_com']+analysis_v_df['st_20201001_num_plus_com'])/4)        \n",
    "        analysis_v_df['num_plus_model_mean']=((analysis_v_df['st_20200101_num_plus_model(row)']+analysis_v_df['st_20200401_num_plus_model(row)']+analysis_v_df['st_20200701_num_plus_model(row)']+analysis_v_df['st_20201001_num_plus_model(row)'])/4)        \n",
    "        csv_path='../../bot_database/{place_name}/model_score_{place_name}/v4_score/{version}/{version}_{mode_type}_TRhit_pM{plus_month}_total_analysis.csv'.format(place_name=place_name,mode_type=mode_type,version=version,plus_month=plus_m_th,num_hit=num_hit_th)\n",
    "        analysis_v_df.to_csv(csv_path)\n",
    "\n",
    "time_end = time.time()\n",
    "# 経過時間（秒）\n",
    "tim = time_end- time_sta\n",
    "\n",
    "print('DONE')\n",
    "print('elapsed time::{}=================================================================================================='.format(tim))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entertaining-praise",
   "metadata": {},
   "source": [
    "## plus_monthを２に減らした"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "overhead-think",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version:V4_1_______mode:recent===================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 25/25 [58:59<00:00, 141.59s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 25/25 [56:52<00:00, 136.51s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 25/25 [59:10<00:00, 142.00s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 25/25 [58:40<00:00, 140.83s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 25/25 [58:07<00:00, 139.50s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 25/25 [1:00:33<00:00, 145.35s/it]\n",
      "  0%|                                                                                           | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version:V4_1_______mode:period===================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 25/25 [1:18:30<00:00, 188.41s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 25/25 [1:19:20<00:00, 190.43s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 25/25 [1:22:22<00:00, 197.70s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 25/25 [1:06:15<00:00, 159.01s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 25/25 [55:10<00:00, 132.42s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 25/25 [55:29<00:00, 133.18s/it]\n",
      "  0%|                                                                                           | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version:V4_2_______mode:recent===================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 25/25 [54:42<00:00, 131.29s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 25/25 [54:58<00:00, 131.94s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 25/25 [55:08<00:00, 132.34s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 25/25 [55:16<00:00, 132.65s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 25/25 [55:32<00:00, 133.30s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 25/25 [55:56<00:00, 134.27s/it]\n",
      "  0%|                                                                                           | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version:V4_2_______mode:period===================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 25/25 [55:57<00:00, 134.29s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 25/25 [55:50<00:00, 134.04s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 25/25 [57:42<00:00, 138.51s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 25/25 [58:23<00:00, 140.16s/it]\n",
      " 20%|████████████████▍                                                                 | 5/25 [13:02<52:09, 156.49s/it]\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-eec1aeeaf318>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m                                 \u001b[0mnow_ym\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myear\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2020\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmonth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mday\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'%Y%m%d'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m                                 \u001b[0mdir_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'../../bot_database/{place_name}/model_score_{place_name}/v4_score/{version}/{mode}st{now_ym}_finalM3_{version}.csv'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplace_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mplace_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnow_ym\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnow_ym\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mversion\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mversion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m                                 \u001b[0mmodel_score_df\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdir_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf_8_sig'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m                                 \u001b[0mmodel_score_df\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel_score_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Unnamed: 0\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m                                 \u001b[1;31m#決めのパラメータでいったん切り落とし\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\takuma\\nabepy\\env\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    603\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    604\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 605\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    606\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    607\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\takuma\\nabepy\\env\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\takuma\\nabepy\\env\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    812\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 814\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    815\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    816\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\takuma\\nabepy\\env\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1043\u001b[0m             )\n\u001b[0;32m   1044\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1045\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1046\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1047\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\takuma\\nabepy\\env\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1891\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1892\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1893\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1894\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1895\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._get_header\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied"
     ]
    }
   ],
   "source": [
    "#きめのパラメータ\n",
    "place_name='asiya'\n",
    "plus_m_th=2\n",
    "versions=['V4_1','V4_2']#,'V4_3']\n",
    "modes=['asiya_model_score_','asiya_model_score_period_']#モードは直近三カ月と，昨年同月の二種類\n",
    "mode_types=['recent','period']#モードは直近三カ月と，昨年同月の二種類,modesと一緒にzipで回す\n",
    "#きめじゃないパラメータの範囲設定(ループの数に注意！！)\n",
    "gain_ths=np.arange(80, 180,4)\n",
    "gain_std_ths=np.arange(10, 250,15)\n",
    "hit_per_ths=np.arange(0,20,2)\n",
    "hit_std_ths=np.arange(0, 2.0, 0.4)\n",
    "num_hit_ths=[3,5,8,10,13,15]\n",
    "time_sta = time.time()\n",
    "\n",
    "\n",
    "\n",
    "#コード本文\n",
    "for version in versions:\n",
    "    for mode,mode_type in zip(modes,mode_types):\n",
    "        analysis_v_df=pd.DataFrame(columns=['minus_model_per_mean','num_plus_com_mean','num_plus_model_mean','gain_th','gain_std_th','hit_per_th','hit_std_th'])\n",
    "        print('version:{}_______mode:{}==================================================='.format(version,mode_type))\n",
    "        #こっから下はバージョン，モードごと\n",
    "        for num_hit_th in num_hit_ths:\n",
    "            for gain_th in tqdm(gain_ths):\n",
    "                for gain_std_th in gain_std_ths:\n",
    "                    for hit_per_th in hit_per_ths:\n",
    "                        for hit_std_th in hit_std_ths:\n",
    "                            append_s=pd.Series(dtype='object')\n",
    "                            for i in range(4):\n",
    "                                now_ym=datetime.datetime(year=2020, month=1+(i*3),day=1).strftime('%Y%m%d')\n",
    "                                dir_path='../../bot_database/{place_name}/model_score_{place_name}/v4_score/{version}/{mode}st{now_ym}_finalM3_{version}.csv'.format(place_name=place_name,mode=mode,now_ym=now_ym,version=version)\n",
    "                                model_score_df=pd.read_csv(dir_path, encoding='utf_8_sig')\n",
    "                                model_score_df=model_score_df.drop([\"Unnamed: 0\"],axis=1)\n",
    "                                #決めのパラメータでいったん切り落とし\n",
    "                                model_score_df=model_score_df[model_score_df['plus_month_num_test']>=plus_m_th].copy()#収益がプラスだった月の数で切り捨てる\n",
    "                                model_score_df=model_score_df[model_score_df['num_hit_test']>=num_hit_th].copy()#的中した予測の数で切り捨てる,これも可変していく方針に変更した\n",
    "                                #可変していくパラメータ\n",
    "                                target_df=model_score_df[model_score_df['gain_test']>=gain_th].copy()\n",
    "                                target_df=target_df[target_df['gain_std_test']<=gain_std_th].copy()\n",
    "                                target_df=target_df[target_df['buy_hit_per_test']>=hit_per_th].copy()\n",
    "                                target_df=target_df[target_df['buy_hit_per_std_test']<=hit_std_th].copy()\n",
    "                                analysis_df=gainth_analysis(target_df,test_type='final')\n",
    "                                minus_df=analysis_df.loc[:'100以上_110未満'].copy()\n",
    "                                plus_df=analysis_df.loc['100以上_110未満':].copy()\n",
    "                                try:\n",
    "                                    minus_model_per=(minus_df['num_model(row)'].sum()/analysis_df['num_model(row)'].sum())*100\n",
    "                                except ZeroDivisionError:\n",
    "                                    minus_model_per=100\n",
    "                                append_s['st_{}_minus_per(model)'.format(now_ym)]=minus_model_per\n",
    "                                append_s['st_{}_num_plus_com'.format(now_ym)]=plus_df['num_com'].sum()\n",
    "                                append_s['st_{}_num_plus_model(row)'.format(now_ym)]=plus_df['num_model(row)'].sum()\n",
    "                            append_s['num_hit_th']=num_hit_th\n",
    "                            append_s['gain_th']=gain_th\n",
    "                            append_s['gain_std_th']=gain_std_th\n",
    "                            append_s['hit_per_th']=hit_per_th\n",
    "                            append_s['hit_std_th']=hit_std_th\n",
    "                            analysis_v_df=analysis_v_df.append(append_s,ignore_index=True)\n",
    "        analysis_v_df['minus_model_per_mean']=((analysis_v_df['st_20200101_minus_per(model)']+analysis_v_df['st_20200401_minus_per(model)']+analysis_v_df['st_20200701_minus_per(model)']+analysis_v_df['st_20201001_minus_per(model)'])/4)        \n",
    "        analysis_v_df['num_plus_com_mean']=((analysis_v_df['st_20200101_num_plus_com']+analysis_v_df['st_20200401_num_plus_com']+analysis_v_df['st_20200701_num_plus_com']+analysis_v_df['st_20201001_num_plus_com'])/4)        \n",
    "        analysis_v_df['num_plus_model_mean']=((analysis_v_df['st_20200101_num_plus_model(row)']+analysis_v_df['st_20200401_num_plus_model(row)']+analysis_v_df['st_20200701_num_plus_model(row)']+analysis_v_df['st_20201001_num_plus_model(row)'])/4)        \n",
    "        csv_path='../../bot_database/{place_name}/model_score_{place_name}/v4_score/{version}/{version}_{mode_type}_TRhit_pM{plus_month}_total_analysis.csv'.format(place_name=place_name,mode_type=mode_type,version=version,plus_month=plus_m_th,num_hit=num_hit_th)\n",
    "        analysis_v_df.to_csv(csv_path)\n",
    "\n",
    "time_end = time.time()\n",
    "# 経過時間（秒）\n",
    "tim = time_end- time_sta\n",
    "\n",
    "print('DONE')\n",
    "print('elapsed time::{}=================================================================================================='.format(tim))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "south-england",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "severe-idaho",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "driving-canberra",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "electrical-scholarship",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target_com               0.283059\n",
       "depth                   -0.005746\n",
       "target_per              -0.186508\n",
       "threshold               -0.111219\n",
       "total_get_test           0.084398\n",
       "total_use_test           0.226903\n",
       "num_com_test             0.046510\n",
       "num_pred_test            0.226903\n",
       "gain_test               -0.257171\n",
       "gain_std_test            0.172104\n",
       "num_hit_test            -0.028523\n",
       "buy_hit_per_test        -0.266918\n",
       "buy_hit_per_std_test    -0.259625\n",
       "plus_month_num_test      0.030133\n",
       "diff_mea_med_test       -0.088409\n",
       "total_get_final          0.833576\n",
       "total_use_final          0.201764\n",
       "num_com_final            0.200710\n",
       "num_pred_final           0.201764\n",
       "gain_final               1.000000\n",
       "gain_std_final           0.595621\n",
       "num_hit_final            0.361705\n",
       "buy_hit_per_final        0.403838\n",
       "buy_hit_per_std_final    0.097588\n",
       "plus_month_num_final     0.849329\n",
       "diff_mea_med_final       0.335706\n",
       "Name: gain_final, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "primary-ottawa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "valid-pierre",
   "metadata": {},
   "source": [
    "## 仮での機能テスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serious-retention",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "scheduled-density",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/25 [00:44<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-58-43e0c4669d6c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m                     \u001b[0mnow_ym\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myear\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2020\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmonth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mday\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'%Y%m%d'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m                     \u001b[0mdir_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'../../bot_database/{place_name}/model_score_{place_name}/v4_score/{version}/{mode}st{now_ym}_finalM3_{version}.csv'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplace_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mplace_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnow_ym\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnow_ym\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mversion\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mversion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m                     \u001b[0mmodel_score_df\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdir_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf_8_sig'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m                     \u001b[0mmodel_score_df\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel_score_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Unnamed: 0\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m                     \u001b[1;31m#決めのパラメータでいったん切り落とし\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\takuma\\nabepy\\env\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    603\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    604\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 605\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    606\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    607\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\takuma\\nabepy\\env\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    462\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 463\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    464\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    465\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\takuma\\nabepy\\env\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1050\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1051\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidate_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"nrows\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1052\u001b[1;33m         \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1053\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1054\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\takuma\\nabepy\\env\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   2054\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2055\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2056\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2057\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2058\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'."
     ]
    }
   ],
   "source": [
    "# i=0\n",
    "# version=versions[0]\n",
    "# analysis_v_df=pd.DataFrame(columns=['minus_model_per_mean','num_plus_com_mean','num_plus_model_mean','gain_th','gain_std_th','hit_per_th','hit_std_th'])\n",
    "# mode=modes[0]\n",
    "# now_ym=datetime.datetime(year=2020, month=1+(i*3),day=1).strftime('%Y%m%d')\n",
    "# time_sta = time.time()\n",
    "# #こっから下はバージョン，モードごと\n",
    "# for gain_th in tqdm(gain_ths):\n",
    "#     for gain_std_th in gain_std_ths:\n",
    "#         for hit_per_th in hit_per_ths:\n",
    "#             for hit_std_th in hit_std_ths:\n",
    "#                 append_s=pd.Series(dtype='object')\n",
    "#                 for i in range(4):\n",
    "#                     now_ym=datetime.datetime(year=2020, month=1+(i*3),day=1).strftime('%Y%m%d')\n",
    "#                     dir_path='../../bot_database/{place_name}/model_score_{place_name}/v4_score/{version}/{mode}st{now_ym}_finalM3_{version}.csv'.format(place_name=place_name,mode=mode,now_ym=now_ym,version=version)\n",
    "#                     model_score_df=pd.read_csv(dir_path, encoding='utf_8_sig')\n",
    "#                     model_score_df=model_score_df.drop([\"Unnamed: 0\"],axis=1)\n",
    "#                     #決めのパラメータでいったん切り落とし\n",
    "#                     model_score_df=model_score_df[model_score_df['plus_month_num_test']>=plus_m_th].copy()#収益がプラスだった月の数で切り捨てる\n",
    "#                     model_score_df=model_score_df[model_score_df['num_hit_test']>=num_hit_th].copy()#的中した予測の数で切り捨てる，大体一カ月に一件くらいをイメージ\n",
    "#                     target_df=model_score_df[model_score_df['gain_test']>=gain_th].copy()\n",
    "#                     target_df=target_df[target_df['gain_std_test']<=gain_std_th].copy()\n",
    "#                     target_df=target_df[target_df['buy_hit_per_test']>=hit_per_th].copy()\n",
    "#                     target_df=target_df[target_df['buy_hit_per_std_test']<=hit_std_th].copy()\n",
    "#                     analysis_df=gainth_analysis(target_df,test_type='final')\n",
    "#                     minus_df=analysis_df.loc[:'100以上_110未満'].copy()\n",
    "#                     plus_df=analysis_df.loc['100以上_110未満':].copy()\n",
    "#                     try:\n",
    "#                         minus_model_per=(minus_df['num_model(row)'].sum()/analysis_df['num_model(row)'].sum())*100\n",
    "#                     except ZeroDivisionError:\n",
    "#                         minus_model_per=100\n",
    "#                     append_s['st_{}_minus_per(model)'.format(now_ym)]=minus_model_per\n",
    "#                     append_s['st_{}_num_plus_com'.format(now_ym)]=plus_df['num_com'].sum()\n",
    "#                     append_s['st_{}_num_plus_model(row)'.format(now_ym)]=plus_df['num_model(row)'].sum()\n",
    "#                 append_s['gain_th']=gain_th\n",
    "#                 append_s['gain_std_th']=gain_std_th\n",
    "#                 append_s['hit_per_th']=hit_per_th\n",
    "#                 append_s['hit_std_th']=hit_std_th\n",
    "#                 analysis_v_df=analysis_v_df.append(append_s,ignore_index=True)\n",
    "            \n",
    "# analysis_v_df['minus_model_per_mean']=((analysis_v_df['st_20200101_minus_per(model)']+analysis_v_df['st_20200401_minus_per(model)']+analysis_v_df['st_20200701_minus_per(model)']+analysis_v_df['st_20201001_minus_per(model)'])/4)        \n",
    "# analysis_v_df['num_plus_com_mean']=((analysis_v_df['st_20200101_num_plus_com']+analysis_v_df['st_20200401_num_plus_com']+analysis_v_df['st_20200701_num_plus_com']+analysis_v_df['st_20201001_num_plus_com'])/4)        \n",
    "# analysis_v_df['num_plus_model_mean']=((analysis_v_df['st_20200101_num_plus_model(row)']+analysis_v_df['st_20200401_num_plus_model(row)']+analysis_v_df['st_20200701_num_plus_model(row)']+analysis_v_df['st_20201001_num_plus_model(row)'])/4)        \n",
    "# csv_path='../../bot_database/{place_name}/model_score_{place_name}/v4_score/{version}/{mode_type}_total_analysis.csv'.format(place_name=place_name,mode_type=mode_type,version=version)\n",
    "\n",
    "# analysis_v_df.to_csv(csv_path)\n",
    "\n",
    "# time_end = time.time()\n",
    "# # 経過時間（秒）\n",
    "# tim = time_end- time_sta\n",
    "\n",
    "# print('DONE')\n",
    "# print('elapsed time::{}=================================================================================================='.format(tim))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "dimensional-campbell",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_type='test'\n",
    "analysis_v_df['minus_model_per_mean']=((analysis_v_df['st_20200101_minus_per(model)']+analysis_v_df['st_20200401_minus_per(model)']+analysis_v_df['st_20200701_minus_per(model)']+analysis_v_df['st_20201001_minus_per(model)'])/4)        \n",
    "analysis_v_df['num_plus_com_mean']=((analysis_v_df['st_20200101_num_plus_com']+analysis_v_df['st_20200401_num_plus_com']+analysis_v_df['st_20200701_num_plus_com']+analysis_v_df['st_20201001_num_plus_com'])/4)        \n",
    "analysis_v_df['num_plus_model_mean']=((analysis_v_df['st_20200101_num_plus_model(row)']+analysis_v_df['st_20200401_num_plus_model(row)']+analysis_v_df['st_20200701_num_plus_model(row)']+analysis_v_df['st_20201001_num_plus_model(row)'])/4)        \n",
    "csv_path='../../bot_database/{place_name}/model_score_{place_name}/v4_score/{version}/{mode_type}_total_analysis.csv'.format(place_name=place_name,mode_type=mode_type,version=version)\n",
    "analysis_v_df.to_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "difficult-toilet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'V4_1'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exceptional-kansas",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
