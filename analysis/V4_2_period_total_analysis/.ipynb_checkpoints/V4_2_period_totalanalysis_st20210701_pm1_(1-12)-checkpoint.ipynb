{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V4_2系列の総合分析(tontal_analysis)スクリプト\n",
    "・今の区間から前４つの区間のfinalありモデリングスコアシートをもとに性能の特性を調べる総合分析を行い，csvを出力する(大まかなパラメータ決めのため)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import seaborn\n",
    "from pandas import DataFrame\n",
    "from tqdm import tqdm\n",
    "from imblearn.under_sampling import RandomUnderSampler #アンダーサンプリング用\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "# 機械学習用\n",
    "from sklearn.cluster import KMeans #クラスタリング用\n",
    "from sklearn.ensemble import RandomForestClassifier#ランダムフォレスト\n",
    "from copy import deepcopy as cp\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import time\n",
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import os #ディレクトリ作成用\n",
    "import xgboost as xgb\n",
    "import sys\n",
    "#自作のモジュールのインポート\n",
    "sys.path.append(\"../..\")\n",
    "import module.master as master\n",
    "import module.modeling_scores as modeling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0,
     16,
     24,
     57,
     116
    ]
   },
   "outputs": [],
   "source": [
    "def get_season_date(now_date):#日付(datetime型)を渡すと，その日付で購買予測を行う際に使用するデータの区間を返す関数\n",
    "    use_data_year=now_date.year\n",
    "    if (now_date.month>=1)and(now_date.month<4):\n",
    "        use_data_month=1\n",
    "    elif (now_date.month>=4)and(now_date.month<7):\n",
    "        use_data_month=4\n",
    "    elif (now_date.month>=7)and(now_date.month<10):\n",
    "        use_data_month=7\n",
    "    elif (now_date.month>=10):\n",
    "        use_data_month=10\n",
    "    else:\n",
    "        print('what???????')\n",
    "    use_data_date=datetime.datetime(year=use_data_year, month=use_data_month,day=1)\n",
    "    return use_data_date\n",
    "\n",
    "\n",
    "def get_4_section_dt(now_date):#今いる区間から直近4区間の開始日をリストで返してくれる関数\n",
    "    now_sec_date=get_season_date(now_date)\n",
    "    diff_sec_stdates=[0]*4\n",
    "    for i in range(len(diff_sec_stdates)):\n",
    "        diff_sec_stdates[3-i]=now_sec_date- relativedelta(months=3*(i+1))#古い順に日付を入れていく\n",
    "    return diff_sec_stdates\n",
    "\n",
    "\n",
    "def gainth_analysis(score_df,test_type='final'):\n",
    "    \n",
    "    gainth_arr=[100,110,120,140,160]\n",
    "    index_arr=[0,1,2,3,4]\n",
    "    cols=[\"gain_th\",\"num_com\",\"num_model(row)\"]\n",
    "    gainth_df=pd.DataFrame(columns=cols)\n",
    "    def make_series(target_df):\n",
    "        num_com=len(target_df['target_com'].value_counts().index)\n",
    "        num_model=len(target_df)\n",
    "        return num_com,num_model\n",
    "    for gainth,i in zip(gainth_arr,index_arr):\n",
    "        append_s=pd.Series(index=cols,dtype='object')\n",
    "        if (i==0):\n",
    "            target_df=score_df[score_df[\"gain_{}\".format(test_type)]<gainth]\n",
    "            num_com,num_model=make_series(target_df)\n",
    "            append_s['gain_th']=\"100未満\"\n",
    "            append_s['num_com']=num_com\n",
    "            append_s['num_model(row)']=num_model\n",
    "        elif (i==4):\n",
    "            target_df=score_df[score_df[\"gain_{}\".format(test_type)]>=gainth]\n",
    "            num_com,num_model=make_series(target_df)\n",
    "            append_s['gain_th']=\"150以上\"\n",
    "            append_s['num_com']=num_com\n",
    "            append_s['num_model(row)']=num_model\n",
    "        else:\n",
    "            target_df=score_df[(score_df[\"gain_{}\".format(test_type)]<gainth_arr[i])&(score_df[\"gain_{}\".format(test_type)]>=gainth_arr[i-1])]\n",
    "            num_com,num_model=make_series(target_df)\n",
    "            append_s['gain_th']=\"{}以上_{}未満\".format(gainth_arr[i-1],gainth_arr[i])\n",
    "            append_s['num_com']=num_com\n",
    "            append_s['num_model(row)']=num_model\n",
    "        gainth_df=gainth_df.append(append_s,ignore_index=True)\n",
    "    return gainth_df\n",
    "\n",
    "def total_analysis_recent(now_date,place_names,version,plus_m_th,gain_ths,gain_std_ths,hit_per_ths,hit_std_ths,num_hit_ths):#直近４区間のモデリングスコアをもとに総合分析を行う関数\n",
    "    mode_type='recent'\n",
    "    mode='model_score_'\n",
    "    \n",
    "    diff_sec_dates=get_4_section_dt(now_date)#直近４区間の開始日をリストで取得\n",
    "    now_date_txt=now_date.strftime('%Y%m%d')\n",
    "    d1_sec_date_txt=diff_sec_dates[0].strftime('%Y%m%d')\n",
    "    d2_sec_date_txt=diff_sec_dates[1].strftime('%Y%m%d')\n",
    "    d3_sec_date_txt=diff_sec_dates[2].strftime('%Y%m%d')\n",
    "    d4_sec_date_txt=diff_sec_dates[3].strftime('%Y%m%d')\n",
    "    print('version:{}_______mode:{}==================================================='.format(version,mode_type))\n",
    "    for place_name in tqdm(place_names):\n",
    "        analysis_v_df=pd.DataFrame(columns=['minus_model_per_mean','num_plus_com_mean','num_plus_model_mean','gain_th','gain_std_th','hit_per_th','hit_std_th'])\n",
    "        #こっから下はバージョン，モードごと\n",
    "        for num_hit_th in num_hit_ths:\n",
    "            for gain_th in gain_ths:\n",
    "                for gain_std_th in gain_std_ths:\n",
    "                    for hit_per_th in hit_per_ths:\n",
    "                        for hit_std_th in hit_std_ths:\n",
    "                            append_s=pd.Series(dtype='object')\n",
    "                            #for i in range(4):\n",
    "                            for sec_date in diff_sec_dates:#区間の日付でfor文を回す\n",
    "                                #now_ym=datetime.datetime(year=2020, month=1+(i*3),day=1).strftime('%Y%m%d')\n",
    "                                sec_date_txt=sec_date.strftime('%Y%m%d')\n",
    "                                dir_path='../../../bot_database/{place_name}/model_score_{place_name}/v4_score/{version}/{place_name}_{mode}st{sec_ym}_finalM3_{version}.csv'.format(place_name=place_name,mode=mode,sec_ym=sec_date_txt,version=version)\n",
    "                                model_score_df=pd.read_csv(dir_path, encoding='utf_8_sig')\n",
    "                                model_score_df=model_score_df.drop([\"Unnamed: 0\"],axis=1)\n",
    "                                #決めのパラメータでいったん切り落とし\n",
    "                                model_score_df=model_score_df[model_score_df['plus_month_num_test']>=plus_m_th].copy()#収益がプラスだった月の数で切り捨てる\n",
    "                                model_score_df=model_score_df[model_score_df['num_hit_test']>=num_hit_th].copy()#的中した予測の数で切り捨てる,これも可変していく方針に変更した\n",
    "                                #可変していくパラメータ\n",
    "                                target_df=model_score_df[model_score_df['gain_test']>=gain_th].copy()\n",
    "                                target_df=target_df[target_df['gain_std_test']<=gain_std_th].copy()\n",
    "                                target_df=target_df[target_df['buy_hit_per_test']>=hit_per_th].copy()\n",
    "                                target_df=target_df[target_df['buy_hit_per_std_test']<=hit_std_th].copy()\n",
    "                                analysis_df=gainth_analysis(target_df,test_type='final')\n",
    "                                minus_df=analysis_df.loc[:'100以上_110未満'].copy()\n",
    "                                plus_df=analysis_df.loc['100以上_110未満':].copy()\n",
    "                                try:\n",
    "                                    minus_model_per=(minus_df['num_model(row)'].sum()/analysis_df['num_model(row)'].sum())*100\n",
    "                                except ZeroDivisionError:\n",
    "                                    minus_model_per=100\n",
    "                                append_s['st_{}_minus_per(model)'.format(sec_date_txt)]=minus_model_per\n",
    "                                append_s['st_{}_num_plus_com'.format(sec_date_txt)]=plus_df['num_com'].sum()\n",
    "                                append_s['st_{}_num_plus_model(row)'.format(sec_date_txt)]=plus_df['num_model(row)'].sum()\n",
    "                            append_s['num_hit_th']=num_hit_th\n",
    "                            append_s['gain_th']=gain_th\n",
    "                            append_s['gain_std_th']=gain_std_th\n",
    "                            append_s['hit_per_th']=hit_per_th\n",
    "                            append_s['hit_std_th']=hit_std_th\n",
    "                            analysis_v_df=analysis_v_df.append(append_s,ignore_index=True)\n",
    "        analysis_v_df['minus_model_per_mean']=((analysis_v_df['st_{}_minus_per(model)'.format(d1_sec_date_txt)]+analysis_v_df['st_{}_minus_per(model)'.format(d2_sec_date_txt)]+analysis_v_df['st_{}_minus_per(model)'.format(d3_sec_date_txt)]+analysis_v_df['st_{}_minus_per(model)'.format(d4_sec_date_txt)])/4)        \n",
    "        analysis_v_df['num_plus_com_mean']=((analysis_v_df['st_{}_num_plus_com'.format(d1_sec_date_txt)]+analysis_v_df['st_{}_num_plus_com'.format(d2_sec_date_txt)]+analysis_v_df['st_{}_num_plus_com'.format(d3_sec_date_txt)]+analysis_v_df['st_{}_num_plus_com'.format(d4_sec_date_txt)])/4)        \n",
    "        analysis_v_df['num_plus_model_mean']=((analysis_v_df['st_{}_num_plus_model(row)'.format(d1_sec_date_txt)]+analysis_v_df['st_{}_num_plus_model(row)'.format(d2_sec_date_txt)]+analysis_v_df['st_{}_num_plus_model(row)'.format(d3_sec_date_txt)]+analysis_v_df['st_{}_num_plus_model(row)'.format(d4_sec_date_txt)])/4)        \n",
    "        #csv_path='../../bot_database/{place_name}/model_score_{place_name}/v4_score/{version}/{version}_{mode_type}_TRhit_pM{plus_month}_st{now_ym}_total_analysis.csv'.format(place_name=place_name,mode_type=mode_type,version=version,plus_month=plus_m_th,num_hit=num_hit_th,now_ym=now_date_txt)\n",
    "        csv_path='../../../bot_database/{place_name}/model_score_{place_name}/v4_score/{version}/{version}_{mode_type}_TRhit_pM{plus_month}_st{now_ym}_total_analysis.csv'.format(place_name=place_name,mode_type=mode_type,version=version,plus_month=plus_m_th,num_hit=num_hit_th,now_ym=now_date_txt)\n",
    "        analysis_v_df.to_csv(csv_path)\n",
    "    return None\n",
    "\n",
    "def total_analysis_period(now_date,place_names,version,plus_m_th,gain_ths,gain_std_ths,hit_per_ths,hit_std_ths,num_hit_ths):#直近４区間のモデリングスコアをもとに総合分析を行う関数\n",
    "    mode_type='period'\n",
    "    mode='model_score_period_'\n",
    "    \n",
    "    diff_sec_dates=get_4_section_dt(now_date)#直近４区間の開始日をリストで取得\n",
    "    now_date_txt=now_date.strftime('%Y%m%d')\n",
    "    d1_sec_date_txt=diff_sec_dates[0].strftime('%Y%m%d')\n",
    "    d2_sec_date_txt=diff_sec_dates[1].strftime('%Y%m%d')\n",
    "    d3_sec_date_txt=diff_sec_dates[2].strftime('%Y%m%d')\n",
    "    d4_sec_date_txt=diff_sec_dates[3].strftime('%Y%m%d')\n",
    "    print('version:{}_______mode:{}==================================================='.format(version,mode_type))\n",
    "    for place_name in tqdm(place_names):\n",
    "        analysis_v_df=pd.DataFrame(columns=['minus_model_per_mean','num_plus_com_mean','num_plus_model_mean','gain_th','gain_std_th','hit_per_th','hit_std_th'])\n",
    "        #こっから下はバージョン，モードごと\n",
    "        for num_hit_th in num_hit_ths:\n",
    "            for gain_th in gain_ths:\n",
    "                for gain_std_th in gain_std_ths:\n",
    "                    for hit_per_th in hit_per_ths:\n",
    "                        for hit_std_th in hit_std_ths:\n",
    "                            append_s=pd.Series(dtype='object')\n",
    "                            #for i in range(4):\n",
    "                            for sec_date in diff_sec_dates:#区間の日付でfor文を回す\n",
    "                                #now_ym=datetime.datetime(year=2020, month=1+(i*3),day=1).strftime('%Y%m%d')\n",
    "                                sec_date_txt=sec_date.strftime('%Y%m%d')\n",
    "                                dir_path='../../../bot_database/{place_name}/model_score_{place_name}/v4_score/{version}/{place_name}_{mode}st{sec_ym}_finalM3_{version}.csv'.format(place_name=place_name,mode=mode,sec_ym=sec_date_txt,version=version)\n",
    "                                model_score_df=pd.read_csv(dir_path, encoding='utf_8_sig')\n",
    "                                model_score_df=model_score_df.drop([\"Unnamed: 0\"],axis=1)\n",
    "                                #決めのパラメータでいったん切り落とし\n",
    "                                model_score_df=model_score_df[model_score_df['plus_month_num_test']>=plus_m_th].copy()#収益がプラスだった月の数で切り捨てる\n",
    "                                model_score_df=model_score_df[model_score_df['num_hit_test']>=num_hit_th].copy()#的中した予測の数で切り捨てる,これも可変していく方針に変更した\n",
    "                                #可変していくパラメータ\n",
    "                                target_df=model_score_df[model_score_df['gain_test']>=gain_th].copy()\n",
    "                                target_df=target_df[target_df['gain_std_test']<=gain_std_th].copy()\n",
    "                                target_df=target_df[target_df['buy_hit_per_test']>=hit_per_th].copy()\n",
    "                                target_df=target_df[target_df['buy_hit_per_std_test']<=hit_std_th].copy()\n",
    "                                analysis_df=gainth_analysis(target_df,test_type='final')\n",
    "                                minus_df=analysis_df.loc[:'100以上_110未満'].copy()\n",
    "                                plus_df=analysis_df.loc['100以上_110未満':].copy()\n",
    "                                try:\n",
    "                                    minus_model_per=(minus_df['num_model(row)'].sum()/analysis_df['num_model(row)'].sum())*100\n",
    "                                except ZeroDivisionError:\n",
    "                                    minus_model_per=100\n",
    "                                append_s['st_{}_minus_per(model)'.format(sec_date_txt)]=minus_model_per\n",
    "                                append_s['st_{}_num_plus_com'.format(sec_date_txt)]=plus_df['num_com'].sum()\n",
    "                                append_s['st_{}_num_plus_model(row)'.format(sec_date_txt)]=plus_df['num_model(row)'].sum()\n",
    "                            append_s['num_hit_th']=num_hit_th\n",
    "                            append_s['gain_th']=gain_th\n",
    "                            append_s['gain_std_th']=gain_std_th\n",
    "                            append_s['hit_per_th']=hit_per_th\n",
    "                            append_s['hit_std_th']=hit_std_th\n",
    "                            analysis_v_df=analysis_v_df.append(append_s,ignore_index=True)\n",
    "        analysis_v_df['minus_model_per_mean']=((analysis_v_df['st_{}_minus_per(model)'.format(d1_sec_date_txt)]+analysis_v_df['st_{}_minus_per(model)'.format(d2_sec_date_txt)]+analysis_v_df['st_{}_minus_per(model)'.format(d3_sec_date_txt)]+analysis_v_df['st_{}_minus_per(model)'.format(d4_sec_date_txt)])/4)        \n",
    "        analysis_v_df['num_plus_com_mean']=((analysis_v_df['st_{}_num_plus_com'.format(d1_sec_date_txt)]+analysis_v_df['st_{}_num_plus_com'.format(d2_sec_date_txt)]+analysis_v_df['st_{}_num_plus_com'.format(d3_sec_date_txt)]+analysis_v_df['st_{}_num_plus_com'.format(d4_sec_date_txt)])/4)        \n",
    "        analysis_v_df['num_plus_model_mean']=((analysis_v_df['st_{}_num_plus_model(row)'.format(d1_sec_date_txt)]+analysis_v_df['st_{}_num_plus_model(row)'.format(d2_sec_date_txt)]+analysis_v_df['st_{}_num_plus_model(row)'.format(d3_sec_date_txt)]+analysis_v_df['st_{}_num_plus_model(row)'.format(d4_sec_date_txt)])/4)        \n",
    "        #csv_path='../../bot_database/{place_name}/model_score_{place_name}/v4_score/{version}/{version}_{mode_type}_TRhit_pM{plus_month}_st{now_ym}_total_analysis.csv'.format(place_name=place_name,mode_type=mode_type,version=version,plus_month=plus_m_th,num_hit=num_hit_th,now_ym=now_date_txt)\n",
    "        csv_path='../../../bot_database/{place_name}/model_score_{place_name}/v4_score/{version}/{version}_{mode_type}_TRhit_pM{plus_month}_st{now_ym}_total_analysis.csv'.format(place_name=place_name,mode_type=mode_type,version=version,plus_month=plus_m_th,num_hit=num_hit_th,now_ym=now_date_txt)\n",
    "        analysis_v_df.to_csv(csv_path)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## total_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### pm=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# #today=datetime.date.today()#今日の日付の取得\n",
    "# today=datetime.datetime(year=2021, month=1,day=1)\n",
    "\n",
    "# diff_sec_dates=get_4_section_dt(today)#直近４区間の開始日をリストで取得\n",
    "# #diff_sec_dates=get_4_section_dt(st_ym)#直近４区間の開始日をリストで取得\n",
    "\n",
    "# place_master=master.get_place_master()\n",
    "# place_names=[place_name for place_name in place_master.values()]#会場名のみを収納した配列\n",
    "# version='V4_2'\n",
    "# #決めパラメータ，（今のところ月のみ）\n",
    "# plus_m_th=3\n",
    "# #きめじゃないパラメータの範囲設定(ループの数に注意！！)\n",
    "# gain_ths=np.arange(80, 180,4)\n",
    "# gain_std_ths=np.arange(10, 250,15)\n",
    "# hit_per_ths=np.arange(0,20,2)\n",
    "# hit_std_ths=np.arange(0, 2.0, 0.4)\n",
    "# num_hit_ths=[3,5,8,10,13,15]\n",
    "\n",
    "\n",
    "\n",
    "# time_sta = time.time()\n",
    "# #========\n",
    "# #総合分析シートの出力\n",
    "# total_analysis_recent(now_date,place_names,version,plus_m_th,gain_ths,gain_std_ths,hit_per_ths,hit_std_ths,num_hit_ths)#直近４区間のモデリングスコアをもとに総合分析を行う関数\n",
    "# #========\n",
    "\n",
    "# time_end = time.time()\n",
    "# # 経過時間（秒）\n",
    "# tim = time_end- time_sta\n",
    "\n",
    "# print('DONE')\n",
    "# print('elapsed time::{}=================================================================================================='.format(tim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pm=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/17 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version:V4_2_______mode:recent===================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|███████████████████████████████████████████████████████████▎            | 14/17 [118:45:34<25:26:54, 30538.20s/it]\n"
     ]
    },
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-24da07a61756>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;31m#========\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;31m#総合分析シートの出力\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[0mtotal_analysis_recent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoday\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mplace_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mversion\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mplus_m_th\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgain_ths\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgain_std_ths\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhit_per_ths\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhit_std_ths\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_hit_ths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#直近４区間のモデリングスコアをもとに総合分析を行う関数\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;31m#========\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-3e148984228b>\u001b[0m in \u001b[0;36mtotal_analysis_recent\u001b[1;34m(now_date, place_names, version, plus_m_th, gain_ths, gain_std_ths, hit_per_ths, hit_std_ths, num_hit_ths)\u001b[0m\n\u001b[0;32m     81\u001b[0m                                 \u001b[0msec_date_txt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msec_date\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'%Y%m%d'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m                                 \u001b[0mdir_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'../../../bot_database/{place_name}/model_score_{place_name}/v4_score/{version}/{place_name}_{mode}st{sec_ym}_finalM3_{version}.csv'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplace_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mplace_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msec_ym\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msec_date_txt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mversion\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mversion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m                                 \u001b[0mmodel_score_df\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdir_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf_8_sig'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m                                 \u001b[0mmodel_score_df\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel_score_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Unnamed: 0\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m                                 \u001b[1;31m#決めのパラメータでいったん切り落とし\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\takuma\\nabepy\\env\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    603\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    604\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 605\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    606\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    607\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\takuma\\nabepy\\env\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    462\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 463\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    464\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    465\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\takuma\\nabepy\\env\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1050\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1051\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidate_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"nrows\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1052\u001b[1;33m         \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1053\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1054\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\takuma\\nabepy\\env\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   2054\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2055\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2056\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2057\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2058\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'."
     ]
    }
   ],
   "source": [
    "#today=datetime.date.today()#今日の日付の取得\n",
    "today=datetime.datetime(year=2021, month=7,day=1)\n",
    "\n",
    "diff_sec_dates=get_4_section_dt(today)#直近４区間の開始日をリストで取得\n",
    "#diff_sec_dates=get_4_section_dt(st_ym)#直近４区間の開始日をリストで取得\n",
    "\n",
    "place_master=master.get_place_master()\n",
    "place_names=[place_name for place_name in place_master.values()]#会場名のみを収納した配列\n",
    "place_names=place_names[:12]\n",
    "version='V4_2'\n",
    "#決めパラメータ，（今のところ月のみ）\n",
    "plus_m_th=1\n",
    "#きめじゃないパラメータの範囲設定(ループの数に注意！！)\n",
    "gain_ths=np.arange(80, 180,5)\n",
    "gain_std_ths=np.arange(10, 250,15)\n",
    "hit_per_ths=np.arange(0,20,2)\n",
    "hit_std_ths=np.arange(0, 2.0, 0.5)\n",
    "num_hit_ths=[3,5,8,10,13]\n",
    "\n",
    "\n",
    "\n",
    "time_sta = time.time()\n",
    "#========\n",
    "#総合分析シートの出力\n",
    "total_analysis_period(today,place_names,version,plus_m_th,gain_ths,gain_std_ths,hit_per_ths,hit_std_ths,num_hit_ths)#直近４区間のモデリングスコアをもとに総合分析を行う関数\n",
    "#========\n",
    "\n",
    "time_end = time.time()\n",
    "# 経過時間（秒）\n",
    "tim = time_end- time_sta\n",
    "\n",
    "print('DONE')\n",
    "print('elapsed time::{}=================================================================================================='.format(tim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# today=datetime.date.today()#今日の日付の取得\n",
    "# diff_sec_dates=get_4_section_dt(today)#直近４区間の開始日をリストで取得\n",
    "# diff_sec_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
